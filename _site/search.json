[
  {
    "objectID": "04-data_visualization.html#processing-numbers-is-hard",
    "href": "04-data_visualization.html#processing-numbers-is-hard",
    "title": "Data Visualization",
    "section": "Processing numbers is hard",
    "text": "Processing numbers is hard\n\nCodelibrary(datasauRus)\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(gt)\nlibrary(stringr)\nlibrary(tidyr)\n\ntab_ds_data &lt;- datasaurus_dozen |&gt;\n  filter(dataset %in% c('dino', 'star')) |&gt;\n  group_by(dataset) |&gt;\n  mutate(id = 1:n()) |&gt;\n  pivot_wider(\n    names_from = dataset, \n    values_from = c(x,y),\n    names_vary = 'slowest'\n  ) |&gt;\n  select(-id) |&gt; \n  head(10) \ntab_ds_data |&gt;  \n  gt() |&gt;\n  cols_label(\n    x_dino = 'x',\n    y_dino = 'y',\n    x_star = 'x',\n    y_star = 'y'\n  ) |&gt;\n  fmt_number() |&gt;\n  tab_spanner(\n    label = \"Dino\",\n    columns = ends_with(\"dino\")\n  ) |&gt;\n  cols_align('center') |&gt; \n  tab_spanner(\n    label = \"Star\",\n    columns = ends_with(\"star\")\n  ) |&gt; \n  tab_options(\n    table.width = pct(85),\n    table.font.size = 35) \n\n\n\n\n\n\nDino\nStar\n\n\nx\ny\nx\ny\n\n\n\n\n55.38\n97.18\n58.21\n91.88\n\n\n51.54\n96.03\n58.20\n92.21\n\n\n46.15\n94.49\n58.72\n90.31\n\n\n42.82\n91.41\n57.28\n89.91\n\n\n40.77\n88.33\n58.08\n92.01\n\n\n38.72\n84.87\n57.49\n88.09\n\n\n35.64\n79.87\n28.09\n63.51\n\n\n33.08\n77.56\n28.09\n63.59\n\n\n28.97\n74.49\n28.09\n63.12\n\n\n26.15\n71.41\n27.58\n62.82"
  },
  {
    "objectID": "04-data_visualization.html#summary-statistics-are-limiting",
    "href": "04-data_visualization.html#summary-statistics-are-limiting",
    "title": "Data Visualization",
    "section": "Summary statistics are limiting",
    "text": "Summary statistics are limiting\n\nCodedatasaurus_dozen |&gt;\n  filter(dataset %in% c('dino', 'star')) |&gt;\n  group_by(dataset) |&gt;\n  summarize(\n    avg_x = round(mean(x), digits = 2), \n    sd_x = round(sd(x), digits = 2),\n    avg_y = round(mean(y), digits = 2),\n    sd_y = round(sd(y), digits = 2),\n    cor_xy = round(cor(x,y), digits = 2)\n    ) |&gt;\n  mutate(dataset = str_to_title(dataset)) |&gt; \n  gt() |&gt;\n  cols_label(\n    avg_x = \"Mean of x\",\n    sd_x = \"Std. Dev. of x\",\n    avg_y = \"Mean of y\",\n    sd_y = \"Std. Dev. of y\",\n    cor_xy = \"Correlation\") |&gt; \n  tab_options(\n    table.width = pct(85),\n    table.font.size = 35) \n\n\n\n\n\ndataset\nMean of x\nStd. Dev. of x\nMean of y\nStd. Dev. of y\nCorrelation\n\n\n\nDino\n54.26\n16.77\n47.83\n26.94\n-0.06\n\n\nStar\n54.27\n16.77\n47.84\n26.93\n-0.06\n\n\n\n\n\n\n\n\nCodedatasaurus_dozen |&gt;\n  filter(dataset %in% c('dino', 'star')) |&gt;\n  mutate(dataset = str_to_title(dataset)) |&gt;\n  ggplot(aes(x = x, y = y)) +\n  geom_point() +\n  facet_wrap(~dataset) +\n  theme_minimal() +\n  theme(\n    panel.grid=element_blank(),\n    strip.text=element_text(size=35),\n    axis.ticks=element_blank(),\n    axis.text=element_blank(),\n    axis.title=element_text(size=30)\n  )"
  },
  {
    "objectID": "04-data_visualization.html#exercise",
    "href": "04-data_visualization.html#exercise",
    "title": "Data Visualization",
    "section": "Exercise",
    "text": "Exercise\n\n\n\nSee beyond summary statistics\n\n\n\nSelect the datasets x_shape & bullseye from the data.frame datasaurus_dozen\n\nCreate a table showing the following statistics for the two datasets:\n\nmean of x and y,\nstandard deviation of x and y, and\ncovariance between x and y\n\n\n\nCreate a plot showing the two datasets\n\n\n\n\nHere is some code to get you started:\n\nCodelibrary(datasauRus)\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(gt)\nlibrary(stringr)\nlibrary(tidyr)\nfilter(datasaurus_dozen, dataset %in% c('x_shape', 'bullseye')) |&gt;\n  str(give.attr = FALSE)\n\ntibble [284 × 3] (S3: tbl_df/tbl/data.frame)\n $ dataset: chr [1:284] \"x_shape\" \"x_shape\" \"x_shape\" \"x_shape\" ...\n $ x      : num [1:284] 38.3 35.8 32.8 33.7 37.2 ...\n $ y      : num [1:284] 92.5 94.1 88.5 88.6 83.7 ..."
  },
  {
    "objectID": "04-data_visualization.html#visualizing-different-magnitudes",
    "href": "04-data_visualization.html#visualizing-different-magnitudes",
    "title": "Data Visualization",
    "section": "Visualizing different magnitudes",
    "text": "Visualizing different magnitudes\n\nWe can express the comparison of numbers in multiple ways\nSome representations can be interpreted (by humans) more accurately\nAccording to Franconeri et al. (2021) from most to least accurate:\n\nPosition\nLength\nArea\nAngle\nIntensity"
  },
  {
    "objectID": "04-data_visualization.html#visualizing-sameness",
    "href": "04-data_visualization.html#visualizing-sameness",
    "title": "Data Visualization",
    "section": "Visualizing “sameness”",
    "text": "Visualizing “sameness”"
  },
  {
    "objectID": "04-data_visualization.html#caution-these-can-create-spurious-interpretations",
    "href": "04-data_visualization.html#caution-these-can-create-spurious-interpretations",
    "title": "Data Visualization",
    "section": "Caution: these can create spurious interpretations",
    "text": "Caution: these can create spurious interpretations\n\nCoderelated_data &lt;- data.frame(\n  x = c(rnorm(100, 0, 0.1), rnorm(100, 0.5, 0.1)), \n  y = c(rnorm(100, 0, 0.1), rnorm(100, 0.5, 0.1)))\nggplot(related_data, aes(x = x , y = y)) +\n  geom_point(size = 1.2) +\n\n  theme_minimal() +\n  theme(\n    plot.title=element_text(size=35),\n    axis.ticks.x=element_blank(),\n    axis.text=element_text(size=30),\n    axis.title=element_text(size=30)\n  )"
  },
  {
    "objectID": "04-data_visualization.html#counteract-by-using-another-principle",
    "href": "04-data_visualization.html#counteract-by-using-another-principle",
    "title": "Data Visualization",
    "section": "Counteract by using another principle",
    "text": "Counteract by using another principle\n\nCoderelated_data$g &lt;- as.factor(ifelse(rbinom(200, 1, prob = 0.5) == 1, 'F', 'M'))\nggplot(related_data, aes(x = x , y = y, color = g, shape = g)) +\n  geom_point(size = 4) +\n  guides(colour = guide_legend(override.aes = list(size=7))) +\n  theme_minimal() +\n  theme(\n    plot.title=element_text(size=35),\n    axis.ticks.x=element_blank(),\n    axis.text=element_text(size=30),\n    axis.title=element_text(size=30),\n    legend.title = element_blank(),\n    legend.position = 'top',\n    legend.text = element_text(size = 25)\n  )"
  },
  {
    "objectID": "04-data_visualization.html#position-is-interpreted-most-accurately",
    "href": "04-data_visualization.html#position-is-interpreted-most-accurately",
    "title": "Data Visualization",
    "section": "Position is interpreted most accurately",
    "text": "Position is interpreted most accurately\n\nCommon y-axis alignment allows for accurate interpretation\nCategories in the x-axis sorted by y-axis value\nPosition should encode the answer to the questions the audience asks\n\n\nCodelibrary(palmerpenguins)\nlibrary(forcats)\nfct_revfreq &lt;- \\(x) fct_rev(fct_infreq(x))\nggplot(penguins, aes(x = fct_revfreq(species))) +\n  geom_bar(stat = \"count\") +\n  scale_y_continuous(\n    expand = expansion(c(0,0.05)),\n    breaks = seq(10,150, by = 20)) + \n  labs(\n    title = \"Number of observations by species\",\n    x = \"Penguin Species\"\n    ) +\n  theme_bw() +\n    theme(\n    plot.title=element_text(size=35),\n    legend.text=element_text(size=25),\n    axis.ticks.x=element_blank(),\n    axis.text=element_text(size=30),\n    axis.title=element_text(size=30)\n  )"
  },
  {
    "objectID": "04-data_visualization.html#lengths-of-unaligned-segments-are-harder-to-compare",
    "href": "04-data_visualization.html#lengths-of-unaligned-segments-are-harder-to-compare",
    "title": "Data Visualization",
    "section": "Lengths of unaligned segments are harder to compare",
    "text": "Lengths of unaligned segments are harder to compare\n\nAre there more female Gentoo or female Adelie penguins?\nAre there more male or female Gentoo penuins?\n\n\nCodeggplot(penguins, aes(x = fct_revfreq(species), color = sex, fill = sex)) +\n  geom_bar(stat = \"count\") +\n  scale_y_continuous(\n    expand = expansion(c(0,0.05)),\n    breaks = seq(10,150, by = 20)) + \n  labs(\n    title = \"Number of observations by species and sex\",\n    x = \"Penguin Species\"\n    ) +\n  theme_bw() +\n    theme(\n    plot.title=element_text(size=35),\n    axis.ticks.x=element_blank(),\n    axis.text=element_text(size=30),\n    axis.title=element_text(size=30),\n    legend.position='top',\n    legend.text=element_text(size=25),\n    legend.title=element_blank()\n  )"
  },
  {
    "objectID": "04-data_visualization.html#if-the-total-number-is-not-important-but-sub-group-numbers-are",
    "href": "04-data_visualization.html#if-the-total-number-is-not-important-but-sub-group-numbers-are",
    "title": "Data Visualization",
    "section": "If the total number is not important but sub-group numbers are…",
    "text": "If the total number is not important but sub-group numbers are…\n\nAre there more female Gentoo or female Adelie penguins?\nAre there more male or female Gentoo penuins?\n\n\nCodeggplot(penguins, aes(x = fct_revfreq(species), color = sex, fill = sex)) +\n  geom_bar(stat = \"count\", position = 'dodge') +\n  scale_y_continuous(\n    expand = expansion(c(0,0.05)),\n    breaks = seq(10,150, by = 20)) + \n  labs(\n    title = \"Number of observations by species and sex\",\n    x = \"Penguin Species\"\n    ) +\n  theme_bw() +\n    theme(\n    plot.title=element_text(size=35),\n    axis.ticks.x=element_blank(),\n    axis.text=element_text(size=30),\n    axis.title=element_text(size=30),\n    legend.position='top',\n    legend.text=element_text(size=25),\n    legend.title=element_blank()\n  )"
  },
  {
    "objectID": "04-data_visualization.html#using-pre-attentive-attributes",
    "href": "04-data_visualization.html#using-pre-attentive-attributes",
    "title": "Data Visualization",
    "section": "Using pre-attentive attributes",
    "text": "Using pre-attentive attributes\n\n\n\nAction potentials are means of communication between neurons in the brain\nThe probability of firing depends on the strength of the stimulus\nThe strength of the stimulus is relative to the background\nAll or nothing process\n\nOnce the threshold is exceeded the neuron fires\n\n\nTakeaway for visualization:\n\nMost important information needs to be “highlighted” relativ to all other information"
  },
  {
    "objectID": "04-data_visualization.html#how-many-bs-are-there",
    "href": "04-data_visualization.html#how-many-bs-are-there",
    "title": "Data Visualization",
    "section": "How many “b”s are there?",
    "text": "How many “b”s are there?\n\ntop-down attention: deliberate & slow\n\n\nCodeset.seed(1)\nxy = expand.grid(seq(0,1, length.out = 5), seq(0,1, length.out = 5))\ntext = sample(c(\"a\", \"b\", \"c\", \"d\", \"e\"), 25, replace = TRUE)\npar(mar = c(0.1,0,0,0))\nplot(c(0, 1), c(0, 1), ann = F, bty = 'n',type = 'n', xaxt = 'n', yaxt = 'n')\ntext(xy[,1], xy[,2], text, cex = 3)"
  },
  {
    "objectID": "04-data_visualization.html#how-many-bs-are-there-1",
    "href": "04-data_visualization.html#how-many-bs-are-there-1",
    "title": "Data Visualization",
    "section": "How many “b”s are there?",
    "text": "How many “b”s are there?\n\nbottom-up attention: unconscious & fast\n\n\nCodepar(mar = c(0,0,0,0))\nplot(c(0, 1), c(0, 1), ann = F, bty = 'n',type = 'n',  xaxt = 'n', yaxt = 'n')\ntext(xy[,1], xy[,2], text, cex = 3, col = ifelse(text == \"b\", \"black\", \"gray\"))"
  },
  {
    "objectID": "04-data_visualization.html#how-many-шs-are-there",
    "href": "04-data_visualization.html#how-many-шs-are-there",
    "title": "Data Visualization",
    "section": "How many “ш”s are there?",
    "text": "How many “ш”s are there?\n\nCodepar(mar = c(0,0,0,0))\ntext_cyr &lt;- sample(c(\"ш\", \"ц\", \"ж\", \"є\", \"ґ\"), 25, replace = TRUE)\nplot(c(0, 1), c(0, 1), ann = F, bty = 'n',type = 'n',  xaxt = 'n', yaxt = 'n')\ntext(xy[,1], xy[,2], text_cyr, cex = 3, col = ifelse(text_cyr == \"ш\", \"black\", \"gray\"))"
  },
  {
    "objectID": "04-data_visualization.html#areas-can-be-useful-to-add-a-third-least-important-variable",
    "href": "04-data_visualization.html#areas-can-be-useful-to-add-a-third-least-important-variable",
    "title": "Data Visualization",
    "section": "Areas can be useful to add a third (least important) variable",
    "text": "Areas can be useful to add a third (least important) variable\n\nCodelibrary(gapminder)\nlibrary(dplyr)\nlibrary(scales)\ngm_last &lt;- gapminder |&gt;\n  group_by(country) |&gt;\n  slice_max(year) |&gt;\n  mutate(hl = as.factor(ifelse(country %in% c(\"China\", \"United States\"), country, 'other')))\nggplot(gm_last, aes(y = lifeExp, x = gdpPercap, size = pop, color = hl)) +\n  geom_point() +\n  scale_size(\n    name = \"Population\",\n    labels = label_number(scale_cut = cut_short_scale()),\n    ) +\n  geom_text(\n    aes(label = country, x = gdpPercap, y = lifeExp),\n    data = filter(gm_last, country %in% c('China', 'United States')),\n    hjust = c(-0.1, 0.5),\n    vjust = c(4, 2),\n    size = 12\n    ) +\n  geom_segment(\n  aes(\n    x = gdpPercap + c(200, 0), \n    y = lifeExp - 1, \n    xend = gdpPercap+c(1000, 0), \n    yend = lifeExp-c(5.5, 2)),\n  data = filter(gm_last, country %in% c('China', 'United States')),\n  size = 0.5\n  ) +\n  scale_x_continuous(labels = label_comma()) +\n  scale_color_manual(values = c('gray20', 'red', 'darkblue')) +\n  guides(colour = 'none') +\n  labs(y = \"Life Expectancy\", x = \"GDP/Capita\") +\n  theme_bw() +\n    theme(\n    plot.title=element_text(size=35),\n    axis.ticks.x=element_blank(),\n    axis.text=element_text(size=30),\n    axis.title=element_text(size=30),\n    legend.position='top',\n    legend.text=element_text(size=25),\n    legend.title=element_text(size=25)\n  )"
  },
  {
    "objectID": "04-data_visualization.html#do-not-use-pie-charts-just-dont",
    "href": "04-data_visualization.html#do-not-use-pie-charts-just-dont",
    "title": "Data Visualization",
    "section": "Do not use pie-charts… just don’t",
    "text": "Do not use pie-charts… just don’t\n\nCodepenguins |&gt;\n  group_by(species) |&gt;\n  summarize(count = n()) |&gt;\nggplot(aes(x = \"\", y = count, fill = species)) +\n  geom_bar(stat = \"identity\") +\n  labs(\n    title = \"Number of observations by species\",\n    ) +\n  theme_bw() +\n    theme(\n    plot.title=element_text(size=35),\n    axis.ticks=element_blank(),\n    axis.text=element_blank(),\n    axis.title=element_blank(),\n    legend.position='top',\n    legend.text=element_text(size=25),\n    legend.title=element_blank()\n  ) +\n  coord_polar(\"y\", start=0)"
  },
  {
    "objectID": "04-data_visualization.html#exercise-1",
    "href": "04-data_visualization.html#exercise-1",
    "title": "Data Visualization",
    "section": "Exercise",
    "text": "Exercise\n\n\n\nPerceptual accuracy\n\n\n\nCreate a graph that shows the population of penguins for the different species per island\nIt is of particular interest which species is the most common on each island\nCreate another graph that shows the analysis separately for the two sexes"
  },
  {
    "objectID": "04-data_visualization.html#visualizing-many-categories-badly",
    "href": "04-data_visualization.html#visualizing-many-categories-badly",
    "title": "Data Visualization",
    "section": "Visualizing many categories (badly!)",
    "text": "Visualizing many categories (badly!)\n\nWhat is the 5th smallest state?\nWhere does MO rank in terms of size?\n\n\nCodelibrary(datasets)\nlibrary(scales)\nggplot(data.frame(abb = state.abb, area = state.area), aes(x = abb, y = area)) +\n  geom_bar(stat = 'identity') +\n  scale_x_discrete(guide = guide_axis(n.dodge = 2)) +\n  scale_y_continuous(\n    expand = expansion(c(0,0.05)),\n    labels = label_comma(suffix = \" sq mi\")) + \n  theme_bw() +\n    theme(\n    plot.title=element_text(size=35),\n    axis.ticks.x=element_blank(),\n    axis.text=element_text(size=20),\n    axis.title=element_text(size=30),\n    axis.title.x=element_blank()\n  )"
  },
  {
    "objectID": "04-data_visualization.html#visualizing-many-categories",
    "href": "04-data_visualization.html#visualizing-many-categories",
    "title": "Data Visualization",
    "section": "Visualizing many categories",
    "text": "Visualizing many categories\n\nWhat is the 5th smallest state?\nWhere does MO rank in terms of size?\n\n\nCodelibrary(colorspace)\nlibrary(forcats)\nstate_areas &lt;- data.frame(abb = state.abb, area = state.area, name = state.name) |&gt;\n  mutate(abb = fct_reorder(abb, area))\nggplot(state_areas, aes(x = abb, y = area, \n  color = abb == 'MO', fill = abb == 'MO')) +\n  geom_bar(stat = 'identity') +\n  scale_y_continuous(\n    expand = expansion(c(0,0.05)), breaks = seq(50000,600000, by = 100000),\n    labels = label_comma(suffix = \" sq mi\")) + \n  scale_color_manual(values = c('gray85', 'red')) +\n  scale_fill_manual(values = c('gray20', 'red')) +\n  geom_text(\n    aes(label=abb, y = area), \n    position=position_dodge(width=0.9), \n    vjust=-0.50, \n    color = ifelse(state_areas$abb=='MO', 'red', 'gray20'),\n    size = 8)+\n  labs(title = \"US state areas\") +\n  theme_bw() +\n    theme(\n    plot.title=element_text(size=45),\n    axis.ticks.x=element_blank(),\n    axis.text=element_text(size=35),\n    axis.text.x=element_blank(),\n    axis.title=element_blank(),\n    legend.position='none'\n  )"
  },
  {
    "objectID": "04-data_visualization.html#color-intensity-provides-less-accurate-encoding",
    "href": "04-data_visualization.html#color-intensity-provides-less-accurate-encoding",
    "title": "Data Visualization",
    "section": "Color intensity provides less accurate encoding",
    "text": "Color intensity provides less accurate encoding\n\nCodelibrary(maps)\nlibrary(sf)\nlibrary(colorspace)\nus_map_data &lt;- map(\"state\", fill=TRUE, plot =FALSE)\n\nusa &lt;- st_as_sf(map(\"state\", fill=TRUE, plot =FALSE))\nusa &lt;- merge(\n  usa, \n  mutate(state_areas, ID = str_to_lower(name)),\n  )\nggplot(usa) +\n  geom_sf(aes(fill = area), color = \"#2b2b2b\", size=0.125) +\n  coord_sf(crs = st_crs(6350)) +\n  geom_sf_text(aes(label = abb, color = abb == 'MO')) +\n  scale_color_manual(values = c('gray20', 'red')) +\n  guides(color = 'none') + \n  ggthemes::theme_map() +\n  scale_fill_binned_sequential(\n    palette = \"Heat\", \n    labels = label_comma(suffix = \" sq mi\") \n    )"
  },
  {
    "objectID": "04-data_visualization.html#colors-are-useful-to-mark-targets-for-preattentive-processing",
    "href": "04-data_visualization.html#colors-are-useful-to-mark-targets-for-preattentive-processing",
    "title": "Data Visualization",
    "section": "Colors are useful to mark targets for preattentive processing",
    "text": "Colors are useful to mark targets for preattentive processing\n\nLarge scale spatial data needs to be “projected” to 2D\nMost well known projection is 4326 measured in degrees latitude and longitude\nHowever, there are more accurate projections for specific regions e.g, 3035 for EU+candidates\n\n\nCode## Example using \"shapefile\"\n### e.g. for EU download here https://ec.europa.eu/eurostat/web/gisco/geodata/reference-data/administrative-units-statistical-units/nuts\neu &lt;- st_read(\"data/NUTS_RG_60M_2021_3035.shp/\", quiet = TRUE)\neu0 &lt;- filter(eu, LEVL_CODE == 0)\n## Transform to longitude and latitude\neu0 &lt;- eu0 |&gt; st_transform(4326)\neu0_box &lt;- eu0 |&gt; st_bbox()\neu0_box &lt;- eu0_box + c(50, 20, 0, -10)\nggplot(st_crop(eu0, eu0_box))+ \n  geom_sf(fill = 'white', lwd = 1) +\n  geom_sf(data = filter(eu0, CNTR_CODE == 'AT'), color = 'red', lwd =1.5) + \n  coord_sf(crs = st_crs(3035)) +\n  geom_sf_text(aes(label = CNTR_CODE, color = CNTR_CODE == 'AT'), size = 15) +\n  scale_color_manual(values = c('gray20', 'red')) +\n  guides(color = 'none') + \n  ggthemes::theme_map(base_size = 12)"
  },
  {
    "objectID": "04-data_visualization.html#exercise-2",
    "href": "04-data_visualization.html#exercise-2",
    "title": "Data Visualization",
    "section": "Exercise",
    "text": "Exercise\n\n\n\nGeospacial data\n\n\n\nObtain the shape (“SHP”) file for the EU + candidates from Eurostat\n\nCrop the data to exclude overseas territories\nHighlight the “DACH” region"
  },
  {
    "objectID": "04-data_visualization.html#connectedness-helps-connecting-the-dots",
    "href": "04-data_visualization.html#connectedness-helps-connecting-the-dots",
    "title": "Data Visualization",
    "section": "“Connectedness” helps connecting the dots",
    "text": "“Connectedness” helps connecting the dots\n\nCodecharts &lt;- arrow::read_parquet(\n    \"data/chart_data/spotify_charts.parquet\")  |&gt; \n    filter(country %in% c(\"de\", \"fr\")) |&gt;\n    group_by(country, date) |&gt;\n    summarize(total_streams = sum(streams)) \ncharts |&gt;\n    ggplot(aes(x = date, y = log(total_streams))) +\n    geom_point(aes(color = country), size = 4) +\n    guides(colour = guide_legend(override.aes = list(size=7))) +\n    scale_color_discrete_qualitative(palette = \"Dark 2\") +\n    theme_classic() +\n    labs(y = \"log(total streams)\", title = \"Total streams 2023/24\", subtitle = \"Top 200 songs\") +\n    theme(\n        legend.text = element_text(size = 35),\n        legend.title = element_blank(),\n        axis.text=element_text(size=35),\n        axis.title=element_text(size=35),\n        axis.title.x=element_blank(),\n        legend.position = 'top',\n        plot.title = element_text(size = 35),\n        plot.subtitle = element_text(size = 35)\n    )"
  },
  {
    "objectID": "04-data_visualization.html#connectedness-helps-connecting-the-dots-1",
    "href": "04-data_visualization.html#connectedness-helps-connecting-the-dots-1",
    "title": "Data Visualization",
    "section": "“Connectedness” helps connecting the dots",
    "text": "“Connectedness” helps connecting the dots\n\nCodecharts &lt;- arrow::read_parquet(\n    \"data/chart_data/spotify_charts.parquet\")  |&gt; \n    filter(country %in% c(\"de\", \"fr\")) |&gt;\n    group_by(country, date) |&gt;\n    summarize(total_streams = sum(streams)) \ncharts |&gt;\n    ggplot(aes(x = date, y = log(total_streams), color = country)) +\n    geom_point(size = 4) +\n    geom_line() +\n    guides(colour = guide_legend(override.aes = list(size=7))) +\n    scale_color_discrete_qualitative(palette = \"Dark 2\") +\n    theme_classic() +\n    labs(y = \"log(total streams)\", title = \"Total streams 2023/24\", subtitle = \"Top 200 songs\") +\n    theme(\n        legend.text = element_text(size = 35),\n        legend.title = element_blank(),\n        axis.text=element_text(size=35),\n        axis.title=element_text(size=35),\n        axis.title.x=element_blank(),\n        legend.position = 'top',\n        plot.title = element_text(size = 35),\n        plot.subtitle = element_text(size = 35)\n    )"
  },
  {
    "objectID": "04-data_visualization.html#use-scatter-plots-to-show-correlation",
    "href": "04-data_visualization.html#use-scatter-plots-to-show-correlation",
    "title": "Data Visualization",
    "section": "Use scatter plots to show correlation",
    "text": "Use scatter plots to show correlation\n\nCodepenguins |&gt;\nggplot(aes(x = bill_length_mm, y = bill_depth_mm, #color = species\n)) +\n    geom_point(size = 4) +\n    geom_smooth(method = 'lm', se = FALSE) +\n    guides(colour = guide_legend(override.aes = list(size=7))) +\n    theme_classic() +\n    labs(y = \"Bill depth\", x = \"Bill length\") +\n    theme(\n        axis.text=element_text(size=35),\n        axis.title=element_text(size=35),\n    )"
  },
  {
    "objectID": "04-data_visualization.html#beware-of-simpsons-paradox",
    "href": "04-data_visualization.html#beware-of-simpsons-paradox",
    "title": "Data Visualization",
    "section": "Beware of “Simpson’s Paradox”",
    "text": "Beware of “Simpson’s Paradox”\n\nWhen between-group correlation is the opposite of within-group correlation\n\n\nCodepenguins |&gt;\nggplot(aes(x = bill_length_mm, y = bill_depth_mm, color = species)) +\n    geom_point(size = 4) +\n    geom_smooth(method = 'lm', se = FALSE) +\n    guides(colour = guide_legend(override.aes = list(size=7))) +\n    theme_classic() +\n    labs(y = \"Bill depth\", x = \"Bill length\") +\n    theme(\n        legend.text = element_text(size = 35),\n        legend.title = element_blank(),\n        axis.text=element_text(size=35),\n        axis.title=element_text(size=35),\n        legend.position = 'top',\n    )"
  },
  {
    "objectID": "04-data_visualization.html#use-boxplots-to-show-distributions",
    "href": "04-data_visualization.html#use-boxplots-to-show-distributions",
    "title": "Data Visualization",
    "section": "Use Boxplots to show distributions",
    "text": "Use Boxplots to show distributions\n\nCodepenguins |&gt;\nggplot(aes(\n  y = bill_length_mm, \n  x = fct_reorder(species, bill_length_mm, .fun = median, .na_rm = TRUE))) +\n    geom_boxplot(na.rm = TRUE) +\n    theme_classic() +\n    labs(y = \"Bill length\") +\n    theme(\n        legend.text = element_text(size = 35),\n        legend.title = element_blank(),\n        axis.text=element_text(size=35),\n        axis.title=element_text(size=35),\n        axis.title.x=element_blank(),\n        legend.position = 'top',\n    )"
  },
  {
    "objectID": "04-data_visualization.html#a-few-notes-on-colors",
    "href": "04-data_visualization.html#a-few-notes-on-colors",
    "title": "Data Visualization",
    "section": "A few notes on colors",
    "text": "A few notes on colors\n\nThe library(colorspace) has convenient functions for picking correct color patterns\n\nPalette type depends on the scaling of the data visualized\n\nIs the data discrete or continuous?\nIs there an ordering?\n\nIs the ordering diverging (i.e., there is a neutral state)?\n\n\n\n\nThere are convenience functions for ggplot\n\n\n\nscale_()\n\n\n\naesthetics: fill, color\n\n\ndatatypes: discrete, continuous, binned\n\n\ncolorscales: qualitative, sequential, diverging"
  },
  {
    "objectID": "04-data_visualization.html#diverging-colors-correlation-matrix",
    "href": "04-data_visualization.html#diverging-colors-correlation-matrix",
    "title": "Data Visualization",
    "section": "Diverging colors: correlation matrix",
    "text": "Diverging colors: correlation matrix\n\nDiverging from -1 to 1 with 0 as a neutral point\n\n\ncorrs &lt;- palmerpenguins::penguins |&gt; \n  drop_na() |&gt; \n  select(bill_length_mm, bill_depth_mm, flipper_length_mm) |&gt;\n  cor()\ncor_df &lt;- data.frame(cor = c(corrs), var1 = factor(col(corrs)), var2 = factor(row(corrs)))\nggplot(cor_df, aes(var1, var2, fill = cor)) + \n  geom_tile() + \n  coord_fixed() +\n  ylab(\"variable\") +\n  scale_x_discrete(position = \"top\", name = \"variable\") +\n  scale_fill_continuous_diverging(\"Blue-Red 3\")"
  },
  {
    "objectID": "04-data_visualization.html#qualitative-colors-unordered-groups",
    "href": "04-data_visualization.html#qualitative-colors-unordered-groups",
    "title": "Data Visualization",
    "section": "Qualitative colors: Unordered groups",
    "text": "Qualitative colors: Unordered groups\n\nRule of thumb: visualize up to 7 groups with colors\nMore become hard to differentiate\n\n\n\nggplot(penguins, \n  aes(x = fct_revfreq(species), \n      color = sex, fill = sex)) +\n  geom_bar(stat = \"count\", position = 'dodge') +\n  scale_fill_discrete_qualitative(\"pastel 1\") +\n  scale_y_continuous(\n    expand = expansion(c(0,0.05)),\n    breaks = seq(10,150, by = 20)) + \n  labs(\n    title = \"Number of observations by species and sex\",\n    x = \"Penguin Species\"\n    ) +\n  theme_bw() +\n    theme(\n    plot.title=element_text(size=35),\n    axis.ticks.x=element_blank(),\n    axis.text=element_text(size=30),\n    axis.title=element_text(size=30),\n    legend.position='top',\n    legend.text=element_text(size=25),\n    legend.title=element_blank()\n  )"
  },
  {
    "objectID": "04-data_visualization.html#color-vision-deficiency",
    "href": "04-data_visualization.html#color-vision-deficiency",
    "title": "Data Visualization",
    "section": "Color Vision Deficiency",
    "text": "Color Vision Deficiency\n\n~8% of men and ~0.5% of women have color vision deficiency (CVD) (“color blindness”)\nWe can simulate CVD using swatchplot(&lt;palette&gt;, cvd = TRUE)\n\n\n\n\nswatchplot(diverging_hcl(7, 'Red-Green'), cvd = TRUE)"
  },
  {
    "objectID": "04-data_visualization.html#references",
    "href": "04-data_visualization.html#references",
    "title": "Data Visualization",
    "section": "References",
    "text": "References\n\n\n\n\nData Literacy\n\n\n\n\nFranconeri, Steven L., Lace M. Padilla, Priti Shah, Jeffrey M. Zacks, and Jessica Hullman. 2021. “The Science of Visual Data Communication: What Works.” Psychological Science in the Public Interest 22 (3): 110–61. https://doi.org/10.1177/15291006211051956."
  },
  {
    "objectID": "04-data_visualization_website.html",
    "href": "04-data_visualization_website.html",
    "title": "Data Visualization",
    "section": "",
    "text": "Code\nlibrary(datasauRus)\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(gt)\nlibrary(stringr)\nlibrary(tidyr)\n\ntab_ds_data &lt;- datasaurus_dozen |&gt;\n  filter(dataset %in% c('dino', 'star')) |&gt;\n  group_by(dataset) |&gt;\n  mutate(id = 1:n()) |&gt;\n  pivot_wider(\n    names_from = dataset, \n    values_from = c(x,y),\n    names_vary = 'slowest'\n  ) |&gt;\n  select(-id) |&gt; \n  head(10) \ntab_ds_data |&gt;  \n  gt() |&gt;\n  cols_label(\n    x_dino = 'x',\n    y_dino = 'y',\n    x_star = 'x',\n    y_star = 'y'\n  ) |&gt;\n  fmt_number() |&gt;\n  tab_spanner(\n    label = \"Dino\",\n    columns = ends_with(\"dino\")\n  ) |&gt;\n  cols_align('center') |&gt; \n  tab_spanner(\n    label = \"Star\",\n    columns = ends_with(\"star\")\n  ) |&gt; \n  tab_options(\n    table.width = pct(85),\n    table.font.size = 35) \n\n\n\n\n\n\n\n\nDino\nStar\n\n\nx\ny\nx\ny\n\n\n\n\n55.38\n97.18\n58.21\n91.88\n\n\n51.54\n96.03\n58.20\n92.21\n\n\n46.15\n94.49\n58.72\n90.31\n\n\n42.82\n91.41\n57.28\n89.91\n\n\n40.77\n88.33\n58.08\n92.01\n\n\n38.72\n84.87\n57.49\n88.09\n\n\n35.64\n79.87\n28.09\n63.51\n\n\n33.08\n77.56\n28.09\n63.59\n\n\n28.97\n74.49\n28.09\n63.12\n\n\n26.15\n71.41\n27.58\n62.82\n\n\n\n\n\n\n\n\n\n\n\n\nCode\ndatasaurus_dozen |&gt;\n  filter(dataset %in% c('dino', 'star')) |&gt;\n  group_by(dataset) |&gt;\n  summarize(\n    avg_x = round(mean(x), digits = 2), \n    sd_x = round(sd(x), digits = 2),\n    avg_y = round(mean(y), digits = 2),\n    sd_y = round(sd(y), digits = 2),\n    cor_xy = round(cor(x,y), digits = 2)\n    ) |&gt;\n  mutate(dataset = str_to_title(dataset)) |&gt; \n  gt() |&gt;\n  cols_label(\n    avg_x = \"Mean of x\",\n    sd_x = \"Std. Dev. of x\",\n    avg_y = \"Mean of y\",\n    sd_y = \"Std. Dev. of y\",\n    cor_xy = \"Correlation\") |&gt; \n  tab_options(\n    table.width = pct(85),\n    table.font.size = 35) \n\n\n\n\n\n\n\n\ndataset\nMean of x\nStd. Dev. of x\nMean of y\nStd. Dev. of y\nCorrelation\n\n\n\n\nDino\n54.26\n16.77\n47.83\n26.94\n-0.06\n\n\nStar\n54.27\n16.77\n47.84\n26.93\n-0.06\n\n\n\n\n\n\n\n\n\n\nCode\ndatasaurus_dozen |&gt;\n  filter(dataset %in% c('dino', 'star')) |&gt;\n  mutate(dataset = str_to_title(dataset)) |&gt;\n  ggplot(aes(x = x, y = y)) +\n  geom_point() +\n  facet_wrap(~dataset) +\n  theme_minimal() +\n  theme(\n    panel.grid=element_blank(),\n    strip.text=element_text(size=35),\n    axis.ticks=element_blank(),\n    axis.text=element_blank(),\n    axis.title=element_text(size=30)\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSee beyond summary statistics\n\n\n\n\nSelect the datasets x_shape & bullseye from the data.frame datasaurus_dozen\nCreate a table showing the following statistics for the two datasets:\n\nmean of x and y,\nstandard deviation of x and y, and\ncovariance between x and y\n\nCreate a plot showing the two datasets\n\n\n\nHere is some code to get you started:\n\n\nCode\nlibrary(datasauRus)\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(gt)\nlibrary(stringr)\nlibrary(tidyr)\nfilter(datasaurus_dozen, dataset %in% c('x_shape', 'bullseye')) |&gt;\n  str(give.attr = FALSE)\n\n\ntibble [284 × 3] (S3: tbl_df/tbl/data.frame)\n $ dataset: chr [1:284] \"x_shape\" \"x_shape\" \"x_shape\" \"x_shape\" ...\n $ x      : num [1:284] 38.3 35.8 32.8 33.7 37.2 ...\n $ y      : num [1:284] 92.5 94.1 88.5 88.6 83.7 ..."
  },
  {
    "objectID": "04-data_visualization_website.html#processing-numbers-is-hard",
    "href": "04-data_visualization_website.html#processing-numbers-is-hard",
    "title": "Data Visualization",
    "section": "",
    "text": "Code\nlibrary(datasauRus)\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(gt)\nlibrary(stringr)\nlibrary(tidyr)\n\ntab_ds_data &lt;- datasaurus_dozen |&gt;\n  filter(dataset %in% c('dino', 'star')) |&gt;\n  group_by(dataset) |&gt;\n  mutate(id = 1:n()) |&gt;\n  pivot_wider(\n    names_from = dataset, \n    values_from = c(x,y),\n    names_vary = 'slowest'\n  ) |&gt;\n  select(-id) |&gt; \n  head(10) \ntab_ds_data |&gt;  \n  gt() |&gt;\n  cols_label(\n    x_dino = 'x',\n    y_dino = 'y',\n    x_star = 'x',\n    y_star = 'y'\n  ) |&gt;\n  fmt_number() |&gt;\n  tab_spanner(\n    label = \"Dino\",\n    columns = ends_with(\"dino\")\n  ) |&gt;\n  cols_align('center') |&gt; \n  tab_spanner(\n    label = \"Star\",\n    columns = ends_with(\"star\")\n  ) |&gt; \n  tab_options(\n    table.width = pct(85),\n    table.font.size = 35) \n\n\n\n\n\n\n\n\nDino\nStar\n\n\nx\ny\nx\ny\n\n\n\n\n55.38\n97.18\n58.21\n91.88\n\n\n51.54\n96.03\n58.20\n92.21\n\n\n46.15\n94.49\n58.72\n90.31\n\n\n42.82\n91.41\n57.28\n89.91\n\n\n40.77\n88.33\n58.08\n92.01\n\n\n38.72\n84.87\n57.49\n88.09\n\n\n35.64\n79.87\n28.09\n63.51\n\n\n33.08\n77.56\n28.09\n63.59\n\n\n28.97\n74.49\n28.09\n63.12\n\n\n26.15\n71.41\n27.58\n62.82"
  },
  {
    "objectID": "04-data_visualization_website.html#summary-statistics-are-limiting",
    "href": "04-data_visualization_website.html#summary-statistics-are-limiting",
    "title": "Data Visualization",
    "section": "",
    "text": "Code\ndatasaurus_dozen |&gt;\n  filter(dataset %in% c('dino', 'star')) |&gt;\n  group_by(dataset) |&gt;\n  summarize(\n    avg_x = round(mean(x), digits = 2), \n    sd_x = round(sd(x), digits = 2),\n    avg_y = round(mean(y), digits = 2),\n    sd_y = round(sd(y), digits = 2),\n    cor_xy = round(cor(x,y), digits = 2)\n    ) |&gt;\n  mutate(dataset = str_to_title(dataset)) |&gt; \n  gt() |&gt;\n  cols_label(\n    avg_x = \"Mean of x\",\n    sd_x = \"Std. Dev. of x\",\n    avg_y = \"Mean of y\",\n    sd_y = \"Std. Dev. of y\",\n    cor_xy = \"Correlation\") |&gt; \n  tab_options(\n    table.width = pct(85),\n    table.font.size = 35) \n\n\n\n\n\n\n\n\ndataset\nMean of x\nStd. Dev. of x\nMean of y\nStd. Dev. of y\nCorrelation\n\n\n\n\nDino\n54.26\n16.77\n47.83\n26.94\n-0.06\n\n\nStar\n54.27\n16.77\n47.84\n26.93\n-0.06\n\n\n\n\n\n\n\n\n\n\nCode\ndatasaurus_dozen |&gt;\n  filter(dataset %in% c('dino', 'star')) |&gt;\n  mutate(dataset = str_to_title(dataset)) |&gt;\n  ggplot(aes(x = x, y = y)) +\n  geom_point() +\n  facet_wrap(~dataset) +\n  theme_minimal() +\n  theme(\n    panel.grid=element_blank(),\n    strip.text=element_text(size=35),\n    axis.ticks=element_blank(),\n    axis.text=element_blank(),\n    axis.title=element_text(size=30)\n  )"
  },
  {
    "objectID": "04-data_visualization_website.html#exercise",
    "href": "04-data_visualization_website.html#exercise",
    "title": "Data Visualization",
    "section": "",
    "text": "See beyond summary statistics\n\n\n\n\nSelect the datasets x_shape & bullseye from the data.frame datasaurus_dozen\nCreate a table showing the following statistics for the two datasets:\n\nmean of x and y,\nstandard deviation of x and y, and\ncovariance between x and y\n\nCreate a plot showing the two datasets\n\n\n\nHere is some code to get you started:\n\n\nCode\nlibrary(datasauRus)\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(gt)\nlibrary(stringr)\nlibrary(tidyr)\nfilter(datasaurus_dozen, dataset %in% c('x_shape', 'bullseye')) |&gt;\n  str(give.attr = FALSE)\n\n\ntibble [284 × 3] (S3: tbl_df/tbl/data.frame)\n $ dataset: chr [1:284] \"x_shape\" \"x_shape\" \"x_shape\" \"x_shape\" ...\n $ x      : num [1:284] 38.3 35.8 32.8 33.7 37.2 ...\n $ y      : num [1:284] 92.5 94.1 88.5 88.6 83.7 ..."
  },
  {
    "objectID": "04-data_visualization_website.html#visualizing-different-magnitudes",
    "href": "04-data_visualization_website.html#visualizing-different-magnitudes",
    "title": "Data Visualization",
    "section": "Visualizing different magnitudes",
    "text": "Visualizing different magnitudes\n\nWe can express the comparison of numbers in multiple ways\nSome representations can be interpreted (by humans) more accurately\nAccording to Franconeri et al. (2021) from most to least accurate:\n\nPosition\nLength\nArea\nAngle\nIntensity"
  },
  {
    "objectID": "04-data_visualization_website.html#visualizing-sameness",
    "href": "04-data_visualization_website.html#visualizing-sameness",
    "title": "Data Visualization",
    "section": "Visualizing “sameness”",
    "text": "Visualizing “sameness”"
  },
  {
    "objectID": "04-data_visualization_website.html#caution-these-can-create-spurious-interpretations",
    "href": "04-data_visualization_website.html#caution-these-can-create-spurious-interpretations",
    "title": "Data Visualization",
    "section": "Caution: these can create spurious interpretations",
    "text": "Caution: these can create spurious interpretations\n\n\nCode\nrelated_data &lt;- data.frame(\n  x = c(rnorm(100, 0, 0.1), rnorm(100, 0.5, 0.1)), \n  y = c(rnorm(100, 0, 0.1), rnorm(100, 0.5, 0.1)))\nggplot(related_data, aes(x = x , y = y)) +\n  geom_point(size = 1.2) +\n\n  theme_minimal() +\n  theme(\n    plot.title=element_text(size=35),\n    axis.ticks.x=element_blank(),\n    axis.text=element_text(size=30),\n    axis.title=element_text(size=30)\n  )"
  },
  {
    "objectID": "04-data_visualization_website.html#counteract-by-using-another-principle",
    "href": "04-data_visualization_website.html#counteract-by-using-another-principle",
    "title": "Data Visualization",
    "section": "Counteract by using another principle",
    "text": "Counteract by using another principle\n\n\nCode\nrelated_data$g &lt;- as.factor(ifelse(rbinom(200, 1, prob = 0.5) == 1, 'F', 'M'))\nggplot(related_data, aes(x = x , y = y, color = g, shape = g)) +\n  geom_point(size = 4) +\n  guides(colour = guide_legend(override.aes = list(size=7))) +\n  theme_minimal() +\n  theme(\n    plot.title=element_text(size=35),\n    axis.ticks.x=element_blank(),\n    axis.text=element_text(size=30),\n    axis.title=element_text(size=30),\n    legend.title = element_blank(),\n    legend.position = 'top',\n    legend.text = element_text(size = 25)\n  )"
  },
  {
    "objectID": "04-data_visualization_website.html#position-is-interpreted-most-accurately",
    "href": "04-data_visualization_website.html#position-is-interpreted-most-accurately",
    "title": "Data Visualization",
    "section": "Position is interpreted most accurately",
    "text": "Position is interpreted most accurately\n\nCommon y-axis alignment allows for accurate interpretation\nCategories in the x-axis sorted by y-axis value\nPosition should encode the answer to the questions the audience asks\n\n\n\nCode\nlibrary(palmerpenguins)\nlibrary(forcats)\nfct_revfreq &lt;- \\(x) fct_rev(fct_infreq(x))\nggplot(penguins, aes(x = fct_revfreq(species))) +\n  geom_bar(stat = \"count\") +\n  scale_y_continuous(\n    expand = expansion(c(0,0.05)),\n    breaks = seq(10,150, by = 20)) + \n  labs(\n    title = \"Number of observations by species\",\n    x = \"Penguin Species\"\n    ) +\n  theme_bw() +\n    theme(\n    plot.title=element_text(size=35),\n    legend.text=element_text(size=25),\n    axis.ticks.x=element_blank(),\n    axis.text=element_text(size=30),\n    axis.title=element_text(size=30)\n  )"
  },
  {
    "objectID": "04-data_visualization_website.html#lengths-of-unaligned-segments-are-harder-to-compare",
    "href": "04-data_visualization_website.html#lengths-of-unaligned-segments-are-harder-to-compare",
    "title": "Data Visualization",
    "section": "Lengths of unaligned segments are harder to compare",
    "text": "Lengths of unaligned segments are harder to compare\n\nAre there more female Gentoo or female Adelie penguins?\nAre there more male or female Gentoo penuins?\n\n\n\nCode\nggplot(penguins, aes(x = fct_revfreq(species), color = sex, fill = sex)) +\n  geom_bar(stat = \"count\") +\n  scale_y_continuous(\n    expand = expansion(c(0,0.05)),\n    breaks = seq(10,150, by = 20)) + \n  labs(\n    title = \"Number of observations by species and sex\",\n    x = \"Penguin Species\"\n    ) +\n  theme_bw() +\n    theme(\n    plot.title=element_text(size=35),\n    axis.ticks.x=element_blank(),\n    axis.text=element_text(size=30),\n    axis.title=element_text(size=30),\n    legend.position='top',\n    legend.text=element_text(size=25),\n    legend.title=element_blank()\n  )"
  },
  {
    "objectID": "04-data_visualization_website.html#if-the-total-number-is-not-important-but-sub-group-numbers-are",
    "href": "04-data_visualization_website.html#if-the-total-number-is-not-important-but-sub-group-numbers-are",
    "title": "Data Visualization",
    "section": "If the total number is not important but sub-group numbers are…",
    "text": "If the total number is not important but sub-group numbers are…\n\nAre there more female Gentoo or female Adelie penguins?\nAre there more male or female Gentoo penuins?\n\n\n\nCode\nggplot(penguins, aes(x = fct_revfreq(species), color = sex, fill = sex)) +\n  geom_bar(stat = \"count\", position = 'dodge') +\n  scale_y_continuous(\n    expand = expansion(c(0,0.05)),\n    breaks = seq(10,150, by = 20)) + \n  labs(\n    title = \"Number of observations by species and sex\",\n    x = \"Penguin Species\"\n    ) +\n  theme_bw() +\n    theme(\n    plot.title=element_text(size=35),\n    axis.ticks.x=element_blank(),\n    axis.text=element_text(size=30),\n    axis.title=element_text(size=30),\n    legend.position='top',\n    legend.text=element_text(size=25),\n    legend.title=element_blank()\n  )"
  },
  {
    "objectID": "04-data_visualization_website.html#using-pre-attentive-attributes",
    "href": "04-data_visualization_website.html#using-pre-attentive-attributes",
    "title": "Data Visualization",
    "section": "Using pre-attentive attributes",
    "text": "Using pre-attentive attributes\n\n\n\nAction potentials are means of communication between neurons in the brain\nThe probability of firing depends on the strength of the stimulus\nThe strength of the stimulus is relative to the background\nAll or nothing process\n\nOnce the threshold is exceeded the neuron fires\n\nTakeaway for visualization:\n\nMost important information needs to be “highlighted” relativ to all other information"
  },
  {
    "objectID": "04-data_visualization_website.html#how-many-bs-are-there",
    "href": "04-data_visualization_website.html#how-many-bs-are-there",
    "title": "Data Visualization",
    "section": "How many “b”s are there?",
    "text": "How many “b”s are there?\n\ntop-down attention: deliberate & slow\n\n\n\nCode\nset.seed(1)\nxy = expand.grid(seq(0,1, length.out = 5), seq(0,1, length.out = 5))\ntext = sample(c(\"a\", \"b\", \"c\", \"d\", \"e\"), 25, replace = TRUE)\npar(mar = c(0.1,0,0,0))\nplot(c(0, 1), c(0, 1), ann = F, bty = 'n',type = 'n', xaxt = 'n', yaxt = 'n')\ntext(xy[,1], xy[,2], text, cex = 3)"
  },
  {
    "objectID": "04-data_visualization_website.html#how-many-bs-are-there-1",
    "href": "04-data_visualization_website.html#how-many-bs-are-there-1",
    "title": "Data Visualization",
    "section": "How many “b”s are there?",
    "text": "How many “b”s are there?\n\nbottom-up attention: unconscious & fast\n\n\n\nCode\npar(mar = c(0,0,0,0))\nplot(c(0, 1), c(0, 1), ann = F, bty = 'n',type = 'n',  xaxt = 'n', yaxt = 'n')\ntext(xy[,1], xy[,2], text, cex = 3, col = ifelse(text == \"b\", \"black\", \"gray\"))"
  },
  {
    "objectID": "04-data_visualization_website.html#how-many-шs-are-there",
    "href": "04-data_visualization_website.html#how-many-шs-are-there",
    "title": "Data Visualization",
    "section": "How many “ш”s are there?",
    "text": "How many “ш”s are there?\n\n\nCode\npar(mar = c(0,0,0,0))\ntext_cyr &lt;- sample(c(\"ш\", \"ц\", \"ж\", \"є\", \"ґ\"), 25, replace = TRUE)\nplot(c(0, 1), c(0, 1), ann = F, bty = 'n',type = 'n',  xaxt = 'n', yaxt = 'n')\ntext(xy[,1], xy[,2], text_cyr, cex = 3, col = ifelse(text_cyr == \"ш\", \"black\", \"gray\"))"
  },
  {
    "objectID": "04-data_visualization_website.html#areas-can-be-useful-to-add-a-third-least-important-variable",
    "href": "04-data_visualization_website.html#areas-can-be-useful-to-add-a-third-least-important-variable",
    "title": "Data Visualization",
    "section": "Areas can be useful to add a third (least important) variable",
    "text": "Areas can be useful to add a third (least important) variable\n\n\nCode\nlibrary(gapminder)\nlibrary(dplyr)\nlibrary(scales)\ngm_last &lt;- gapminder |&gt;\n  group_by(country) |&gt;\n  slice_max(year) |&gt;\n  mutate(hl = as.factor(ifelse(country %in% c(\"China\", \"United States\"), country, 'other')))\nggplot(gm_last, aes(y = lifeExp, x = gdpPercap, size = pop, color = hl)) +\n  geom_point() +\n  scale_size(\n    name = \"Population\",\n    labels = label_number(scale_cut = cut_short_scale()),\n    ) +\n  geom_text(\n    aes(label = country, x = gdpPercap, y = lifeExp),\n    data = filter(gm_last, country %in% c('China', 'United States')),\n    hjust = c(-0.1, 0.5),\n    vjust = c(4, 2),\n    size = 12\n    ) +\n  geom_segment(\n  aes(\n    x = gdpPercap + c(200, 0), \n    y = lifeExp - 1, \n    xend = gdpPercap+c(1000, 0), \n    yend = lifeExp-c(5.5, 2)),\n  data = filter(gm_last, country %in% c('China', 'United States')),\n  size = 0.5\n  ) +\n  scale_x_continuous(labels = label_comma()) +\n  scale_color_manual(values = c('gray20', 'red', 'darkblue')) +\n  guides(colour = 'none') +\n  labs(y = \"Life Expectancy\", x = \"GDP/Capita\") +\n  theme_bw() +\n    theme(\n    plot.title=element_text(size=35),\n    axis.ticks.x=element_blank(),\n    axis.text=element_text(size=30),\n    axis.title=element_text(size=30),\n    legend.position='top',\n    legend.text=element_text(size=25),\n    legend.title=element_text(size=25)\n  )"
  },
  {
    "objectID": "04-data_visualization_website.html#do-not-use-pie-charts-just-dont",
    "href": "04-data_visualization_website.html#do-not-use-pie-charts-just-dont",
    "title": "Data Visualization",
    "section": "Do not use pie-charts… just don’t",
    "text": "Do not use pie-charts… just don’t\n\n\nCode\npenguins |&gt;\n  group_by(species) |&gt;\n  summarize(count = n()) |&gt;\nggplot(aes(x = \"\", y = count, fill = species)) +\n  geom_bar(stat = \"identity\") +\n  labs(\n    title = \"Number of observations by species\",\n    ) +\n  theme_bw() +\n    theme(\n    plot.title=element_text(size=35),\n    axis.ticks=element_blank(),\n    axis.text=element_blank(),\n    axis.title=element_blank(),\n    legend.position='top',\n    legend.text=element_text(size=25),\n    legend.title=element_blank()\n  ) +\n  coord_polar(\"y\", start=0)"
  },
  {
    "objectID": "04-data_visualization_website.html#exercise-1",
    "href": "04-data_visualization_website.html#exercise-1",
    "title": "Data Visualization",
    "section": "Exercise",
    "text": "Exercise\n\n\n\n\n\n\nPerceptual accuracy\n\n\n\n\nCreate a graph that shows the population of penguins for the different species per island\nIt is of particular interest which species is the most common on each island\nCreate another graph that shows the analysis separately for the two sexes"
  },
  {
    "objectID": "04-data_visualization_website.html#visualizing-many-categories-badly",
    "href": "04-data_visualization_website.html#visualizing-many-categories-badly",
    "title": "Data Visualization",
    "section": "Visualizing many categories (badly!)",
    "text": "Visualizing many categories (badly!)\n\nWhat is the 5th smallest state?\nWhere does MO rank in terms of size?\n\n\n\nCode\nlibrary(datasets)\nlibrary(scales)\nggplot(data.frame(abb = state.abb, area = state.area), aes(x = abb, y = area)) +\n  geom_bar(stat = 'identity') +\n  scale_x_discrete(guide = guide_axis(n.dodge = 2)) +\n  scale_y_continuous(\n    expand = expansion(c(0,0.05)),\n    labels = label_comma(suffix = \" sq mi\")) + \n  theme_bw() +\n    theme(\n    plot.title=element_text(size=35),\n    axis.ticks.x=element_blank(),\n    axis.text=element_text(size=20),\n    axis.title=element_text(size=30),\n    axis.title.x=element_blank()\n  )"
  },
  {
    "objectID": "04-data_visualization_website.html#visualizing-many-categories",
    "href": "04-data_visualization_website.html#visualizing-many-categories",
    "title": "Data Visualization",
    "section": "Visualizing many categories",
    "text": "Visualizing many categories\n\nWhat is the 5th smallest state?\nWhere does MO rank in terms of size?\n\n\n\nCode\nlibrary(colorspace)\nlibrary(forcats)\nstate_areas &lt;- data.frame(abb = state.abb, area = state.area, name = state.name) |&gt;\n  mutate(abb = fct_reorder(abb, area))\nggplot(state_areas, aes(x = abb, y = area, \n  color = abb == 'MO', fill = abb == 'MO')) +\n  geom_bar(stat = 'identity') +\n  scale_y_continuous(\n    expand = expansion(c(0,0.05)), breaks = seq(50000,600000, by = 100000),\n    labels = label_comma(suffix = \" sq mi\")) + \n  scale_color_manual(values = c('gray85', 'red')) +\n  scale_fill_manual(values = c('gray20', 'red')) +\n  geom_text(\n    aes(label=abb, y = area), \n    position=position_dodge(width=0.9), \n    vjust=-0.50, \n    color = ifelse(state_areas$abb=='MO', 'red', 'gray20'),\n    size = 8)+\n  labs(title = \"US state areas\") +\n  theme_bw() +\n    theme(\n    plot.title=element_text(size=45),\n    axis.ticks.x=element_blank(),\n    axis.text=element_text(size=35),\n    axis.text.x=element_blank(),\n    axis.title=element_blank(),\n    legend.position='none'\n  )"
  },
  {
    "objectID": "04-data_visualization_website.html#color-intensity-provides-less-accurate-encoding",
    "href": "04-data_visualization_website.html#color-intensity-provides-less-accurate-encoding",
    "title": "Data Visualization",
    "section": "Color intensity provides less accurate encoding",
    "text": "Color intensity provides less accurate encoding\n\n\nCode\nlibrary(maps)\nlibrary(sf)\nlibrary(colorspace)\nus_map_data &lt;- map(\"state\", fill=TRUE, plot =FALSE)\n\nusa &lt;- st_as_sf(map(\"state\", fill=TRUE, plot =FALSE))\nusa &lt;- merge(\n  usa, \n  mutate(state_areas, ID = str_to_lower(name)),\n  )\nggplot(usa) +\n  geom_sf(aes(fill = area), color = \"#2b2b2b\", size=0.125) +\n  coord_sf(crs = st_crs(6350)) +\n  geom_sf_text(aes(label = abb, color = abb == 'MO')) +\n  scale_color_manual(values = c('gray20', 'red')) +\n  guides(color = 'none') + \n  ggthemes::theme_map() +\n  scale_fill_binned_sequential(\n    palette = \"Heat\", \n    labels = label_comma(suffix = \" sq mi\") \n    )"
  },
  {
    "objectID": "04-data_visualization_website.html#colors-are-useful-to-mark-targets-for-preattentive-processing",
    "href": "04-data_visualization_website.html#colors-are-useful-to-mark-targets-for-preattentive-processing",
    "title": "Data Visualization",
    "section": "Colors are useful to mark targets for preattentive processing",
    "text": "Colors are useful to mark targets for preattentive processing\n\nLarge scale spatial data needs to be “projected” to 2D\nMost well known projection is 4326 measured in degrees latitude and longitude\nHowever, there are more accurate projections for specific regions e.g, 3035 for EU+candidates\n\n\n\nCode\n## Example using \"shapefile\"\n### e.g. for EU download here https://ec.europa.eu/eurostat/web/gisco/geodata/reference-data/administrative-units-statistical-units/nuts\neu &lt;- st_read(\"data/NUTS_RG_60M_2021_3035.shp/\", quiet = TRUE)\neu0 &lt;- filter(eu, LEVL_CODE == 0)\n## Transform to longitude and latitude\neu0 &lt;- eu0 |&gt; st_transform(4326)\neu0_box &lt;- eu0 |&gt; st_bbox()\neu0_box &lt;- eu0_box + c(50, 20, 0, -10)\nggplot(st_crop(eu0, eu0_box))+ \n  geom_sf(fill = 'white', lwd = 1) +\n  geom_sf(data = filter(eu0, CNTR_CODE == 'AT'), color = 'red', lwd =1.5) + \n  coord_sf(crs = st_crs(3035)) +\n  geom_sf_text(aes(label = CNTR_CODE, color = CNTR_CODE == 'AT'), size = 15) +\n  scale_color_manual(values = c('gray20', 'red')) +\n  guides(color = 'none') + \n  ggthemes::theme_map(base_size = 12)"
  },
  {
    "objectID": "04-data_visualization_website.html#exercise-2",
    "href": "04-data_visualization_website.html#exercise-2",
    "title": "Data Visualization",
    "section": "Exercise",
    "text": "Exercise\n\n\n\n\n\n\nGeospacial data\n\n\n\n\nObtain the shape (“SHP”) file for the EU + candidates from Eurostat\nCrop the data to exclude overseas territories\nHighlight the “DACH” region"
  },
  {
    "objectID": "04-data_visualization_website.html#connectedness-helps-connecting-the-dots",
    "href": "04-data_visualization_website.html#connectedness-helps-connecting-the-dots",
    "title": "Data Visualization",
    "section": "“Connectedness” helps connecting the dots",
    "text": "“Connectedness” helps connecting the dots\n\n\nCode\ncharts &lt;- arrow::read_parquet(\n    \"data/chart_data/spotify_charts.parquet\")  |&gt; \n    filter(country %in% c(\"de\", \"fr\")) |&gt;\n    group_by(country, date) |&gt;\n    summarize(total_streams = sum(streams)) \ncharts |&gt;\n    ggplot(aes(x = date, y = log(total_streams))) +\n    geom_point(aes(color = country), size = 4) +\n    guides(colour = guide_legend(override.aes = list(size=7))) +\n    scale_color_discrete_qualitative(palette = \"Dark 2\") +\n    theme_classic() +\n    labs(y = \"log(total streams)\", title = \"Total streams 2023/24\", subtitle = \"Top 200 songs\") +\n    theme(\n        legend.text = element_text(size = 35),\n        legend.title = element_blank(),\n        axis.text=element_text(size=35),\n        axis.title=element_text(size=35),\n        axis.title.x=element_blank(),\n        legend.position = 'top',\n        plot.title = element_text(size = 35),\n        plot.subtitle = element_text(size = 35)\n    )"
  },
  {
    "objectID": "04-data_visualization_website.html#connectedness-helps-connecting-the-dots-1",
    "href": "04-data_visualization_website.html#connectedness-helps-connecting-the-dots-1",
    "title": "Data Visualization",
    "section": "“Connectedness” helps connecting the dots",
    "text": "“Connectedness” helps connecting the dots\n\n\nCode\ncharts &lt;- arrow::read_parquet(\n    \"data/chart_data/spotify_charts.parquet\")  |&gt; \n    filter(country %in% c(\"de\", \"fr\")) |&gt;\n    group_by(country, date) |&gt;\n    summarize(total_streams = sum(streams)) \ncharts |&gt;\n    ggplot(aes(x = date, y = log(total_streams), color = country)) +\n    geom_point(size = 4) +\n    geom_line() +\n    guides(colour = guide_legend(override.aes = list(size=7))) +\n    scale_color_discrete_qualitative(palette = \"Dark 2\") +\n    theme_classic() +\n    labs(y = \"log(total streams)\", title = \"Total streams 2023/24\", subtitle = \"Top 200 songs\") +\n    theme(\n        legend.text = element_text(size = 35),\n        legend.title = element_blank(),\n        axis.text=element_text(size=35),\n        axis.title=element_text(size=35),\n        axis.title.x=element_blank(),\n        legend.position = 'top',\n        plot.title = element_text(size = 35),\n        plot.subtitle = element_text(size = 35)\n    )"
  },
  {
    "objectID": "04-data_visualization_website.html#use-scatter-plots-to-show-correlation",
    "href": "04-data_visualization_website.html#use-scatter-plots-to-show-correlation",
    "title": "Data Visualization",
    "section": "Use scatter plots to show correlation",
    "text": "Use scatter plots to show correlation\n\n\nCode\npenguins |&gt;\nggplot(aes(x = bill_length_mm, y = bill_depth_mm, #color = species\n)) +\n    geom_point(size = 4) +\n    geom_smooth(method = 'lm', se = FALSE) +\n    guides(colour = guide_legend(override.aes = list(size=7))) +\n    theme_classic() +\n    labs(y = \"Bill depth\", x = \"Bill length\") +\n    theme(\n        axis.text=element_text(size=35),\n        axis.title=element_text(size=35),\n    )"
  },
  {
    "objectID": "04-data_visualization_website.html#beware-of-simpsons-paradox",
    "href": "04-data_visualization_website.html#beware-of-simpsons-paradox",
    "title": "Data Visualization",
    "section": "Beware of “Simpson’s Paradox”",
    "text": "Beware of “Simpson’s Paradox”\n\nWhen between-group correlation is the opposite of within-group correlation\n\n\n\nCode\npenguins |&gt;\nggplot(aes(x = bill_length_mm, y = bill_depth_mm, color = species)) +\n    geom_point(size = 4) +\n    geom_smooth(method = 'lm', se = FALSE) +\n    guides(colour = guide_legend(override.aes = list(size=7))) +\n    theme_classic() +\n    labs(y = \"Bill depth\", x = \"Bill length\") +\n    theme(\n        legend.text = element_text(size = 35),\n        legend.title = element_blank(),\n        axis.text=element_text(size=35),\n        axis.title=element_text(size=35),\n        legend.position = 'top',\n    )"
  },
  {
    "objectID": "04-data_visualization_website.html#use-boxplots-to-show-distributions",
    "href": "04-data_visualization_website.html#use-boxplots-to-show-distributions",
    "title": "Data Visualization",
    "section": "Use Boxplots to show distributions",
    "text": "Use Boxplots to show distributions\n\n\nCode\npenguins |&gt;\nggplot(aes(\n  y = bill_length_mm, \n  x = fct_reorder(species, bill_length_mm, .fun = median, .na_rm = TRUE))) +\n    geom_boxplot(na.rm = TRUE) +\n    theme_classic() +\n    labs(y = \"Bill length\") +\n    theme(\n        legend.text = element_text(size = 35),\n        legend.title = element_blank(),\n        axis.text=element_text(size=35),\n        axis.title=element_text(size=35),\n        axis.title.x=element_blank(),\n        legend.position = 'top',\n    )"
  },
  {
    "objectID": "04-data_visualization_website.html#a-few-notes-on-colors",
    "href": "04-data_visualization_website.html#a-few-notes-on-colors",
    "title": "Data Visualization",
    "section": "A few notes on colors",
    "text": "A few notes on colors\n\nThe library(colorspace) has convenient functions for picking correct color patterns\nPalette type depends on the scaling of the data visualized\n\nIs the data discrete or continuous?\nIs there an ordering?\n\nIs the ordering diverging (i.e., there is a neutral state)?\n\n\nThere are convenience functions for ggplot\n\n\nscale_()\n\n\naesthetics: fill, color\ndatatypes: discrete, continuous, binned\ncolorscales: qualitative, sequential, diverging"
  },
  {
    "objectID": "04-data_visualization_website.html#diverging-colors-correlation-matrix",
    "href": "04-data_visualization_website.html#diverging-colors-correlation-matrix",
    "title": "Data Visualization",
    "section": "Diverging colors: correlation matrix",
    "text": "Diverging colors: correlation matrix\n\nDiverging from -1 to 1 with 0 as a neutral point\n\n\ncorrs &lt;- palmerpenguins::penguins |&gt; \n  drop_na() |&gt; \n  select(bill_length_mm, bill_depth_mm, flipper_length_mm) |&gt;\n  cor()\ncor_df &lt;- data.frame(cor = c(corrs), var1 = factor(col(corrs)), var2 = factor(row(corrs)))\nggplot(cor_df, aes(var1, var2, fill = cor)) + \n  geom_tile() + \n  coord_fixed() +\n  ylab(\"variable\") +\n  scale_x_discrete(position = \"top\", name = \"variable\") +\n  scale_fill_continuous_diverging(\"Blue-Red 3\")"
  },
  {
    "objectID": "04-data_visualization_website.html#qualitative-colors-unordered-groups",
    "href": "04-data_visualization_website.html#qualitative-colors-unordered-groups",
    "title": "Data Visualization",
    "section": "Qualitative colors: Unordered groups",
    "text": "Qualitative colors: Unordered groups\n\nRule of thumb: visualize up to 7 groups with colors\nMore become hard to differentiate\n\n\nggplot(penguins, \n  aes(x = fct_revfreq(species), \n      color = sex, fill = sex)) +\n  geom_bar(stat = \"count\", position = 'dodge') +\n  scale_fill_discrete_qualitative(\"pastel 1\") +\n  scale_y_continuous(\n    expand = expansion(c(0,0.05)),\n    breaks = seq(10,150, by = 20)) + \n  labs(\n    title = \"Number of observations by species and sex\",\n    x = \"Penguin Species\"\n    ) +\n  theme_bw() +\n    theme(\n    plot.title=element_text(size=35),\n    axis.ticks.x=element_blank(),\n    axis.text=element_text(size=30),\n    axis.title=element_text(size=30),\n    legend.position='top',\n    legend.text=element_text(size=25),\n    legend.title=element_blank()\n  )"
  },
  {
    "objectID": "04-data_visualization_website.html#color-vision-deficiency",
    "href": "04-data_visualization_website.html#color-vision-deficiency",
    "title": "Data Visualization",
    "section": "Color Vision Deficiency",
    "text": "Color Vision Deficiency\n\n~8% of men and ~0.5% of women have color vision deficiency (CVD) (“color blindness”)\nWe can simulate CVD using swatchplot(&lt;palette&gt;, cvd = TRUE)\n\n\nswatchplot(diverging_hcl(7, 'Red-Green'), cvd = TRUE)"
  },
  {
    "objectID": "00-admin.html#who-am-i",
    "href": "00-admin.html#who-am-i",
    "title": "Introduction to the Course",
    "section": "Who am I?",
    "text": "Who am I?\n\n\n\nI’m Daniel 👋\nMasters in Economics with major in Mathematics\nData-driven research in various fields\n\nDissertation: What shapes demand in the music industry?\n\nArtist misconduct (#MeToo) increases demand\nIdentification of playlists important for artist success\n\nOrgan donation\n\nSwitching from opt-in to opt-out does not increase available organs\n\nStatistical software (e.g., shrinkDSM)\nBiomarker analysis for cancer research (e.g., FGF8)\n\nFraud detection for one of the top 5 music markets world-wide\n\nanalysis of \\(\\sim 200\\) billion datapoints\n\n\n\n\n\n\n\nMy Rabbit Georgie"
  },
  {
    "objectID": "00-admin.html#why-am-i-here",
    "href": "00-admin.html#why-am-i-here",
    "title": "Introduction to the Course",
    "section": "Why am I here?",
    "text": "Why am I here?\n\n\n\n\n\n\n\n\nHigh-level Goals\n\n\n\n\nHave fun\nGain confidence in analysis\nBuild a solid foundation for current and future data-based projects\nLearn to transform raw data into (business/economic) insights\nProvide a safe space for exploration\n\n\n\n\n\n\n\n\n\n\n\n\n\nExplicit Goals\n\n\n\n\nSet up a development environment for data-based projects\n\nUse extensible and future-proof tools\n\nGet familiar with R, Quarto, and Git\n\nCreate a flexible, documented, reproducible, and collaborative workflow\n\nGet familiar with concepts to process, visualize, and analyze data\n\nMake conscious decisions about each step\nConfidently choose models and methods appropriate for a given situation\n\nGain practical experience through conducting a short data analysis\nGrading based on engagement\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNon-goals\n\n\n\nLearn a “recipe” for data analysis\n\nGreat for class becaus it’s easy\nNot useful in practice\n\nProvide a formal introduction to statistics/data-science\n\nRequires it’s own course\nFocus here on intuition\n\nHarsh grading\n\nThis is an elective :)\nDiscourages exploration"
  },
  {
    "objectID": "00-admin.html#why-are-you-here",
    "href": "00-admin.html#why-are-you-here",
    "title": "Introduction to the Course",
    "section": "Why are you here?",
    "text": "Why are you here?\n\n\n\n10 minutes\n\n\n\nCreate a name-tag for yourself (preferably A4 so I can read it)\nFind someone in class you have not yet met\nDiscuss the following questions and take notes of your neighbors answers\n\nWho are you?\nWhat are you interested in?\nWhat constitutes a good learning environment for me?\nHave you used R or another statistical software before?\nHow can I measure my success in the course?\n\nFormulate 3 measures (e.g., I learned how to run linear regression in R for my thesis)\n\nWhat can Daniel do in each lecture for me to be successful in the course?\n\nFormulate 3 suggestions (e.g., Provide multiple examples for each concept)\n\nWhat can I do in each lecture to be successful in the course?\n\nFormulate 3 review questions for after the lecture (e.g., Did I ask questions if something was unclear?, Did I party yesterday and showed up hung-over?)\n\n\n\n\n\n\n\nIntroduce your neigbor to the class"
  },
  {
    "objectID": "00-admin.html#whats-next",
    "href": "00-admin.html#whats-next",
    "title": "Introduction to the Course",
    "section": "What’s next?",
    "text": "What’s next?\n\n\n\n\n\n\nGrading\n\n\n\n\n25% class participation\n\nToday: upload 3 suggestions to make your neighbor successful\nEvery lecture: either participate in class directly or upload a short review to Canvas after class\n10% for each Saturday lecture, 5% for Wednesday\n\n\n30% project plan\n\nDiscussion next Wednesday (2024.03.13)\nDue next Friday (2024.03.15)\nUpload to Canvas\nIncludes:\n\nResearch question\nA dataset that can be used to answer the research question\nA target audience\nOptionally: a first idea on how to answer the research question\n\n\n\n45% project presentation\n\nPresentations on Wednesday 11 days from today (2023.03.20)\n\\(\\sim 10 min\\) per presentation\n\\(\\sim 5 min\\) discussion for paired groups\nUpload slides to Canvas\nIncludes:\n\nIntroduction to the research question\nShort literature review\nIntroduction to the data\nModel-free evidence (e.g., visualizations)\nModel-based evidence (e.g., regression analysis)\nConclustion & Recommendation\nOptional: Short discussion of solutions to challenges faced\n\n\n\n\n\n\n\n\n\n\n\nData Literacy"
  },
  {
    "objectID": "00-admin-page.html",
    "href": "00-admin-page.html",
    "title": "Introduction to the Course",
    "section": "",
    "text": "I’m Daniel 👋\nMasters in Economics with major in Mathematics\nData-driven research in various fields\n\nDissertation: What shapes demand in the music industry?\n\nArtist misconduct (#MeToo) increases demand\nIdentification of playlists important for artist success\n\nOrgan donation\n\nSwitching from opt-in to opt-out does not increase available organs\n\nStatistical software (e.g., shrinkDSM)\nBiomarker analysis for cancer research (e.g., FGF8)\n\nFraud detection for one of the top 5 music markets world-wide\n\nanalysis of \\(\\sim 200\\) billion datapoints\n\n\n\n\n\n\n\nMy Rabbit Georgie\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHigh-level Goals\n\n\n\n\n\nHave fun\nGain confidence in analysis\nBuild a solid foundation for current and future data-based projects\nLearn to transform raw data into (business/economic) insights\nProvide a safe space for exploration\n\n\n\n\n\n\n\n\n\n\n\n\nExplicit Goals\n\n\n\n\n\nSet up a development environment for data-based projects\n\nUse extensible and future-proof tools\n\nGet familiar with R, Quarto, and Git\n\nCreate a flexible, documented, reproducible, and collaborative workflow\n\nGet familiar with concepts to process, visualize, and analyze data\n\nMake conscious decisions about each step\nConfidently choose models and methods appropriate for a given situation\n\nGain practical experience through conducting a short data analysis\nGrading based on engagement\n\n\n\n\n\n\n\n\n\n\n\n\n\nNon-goals\n\n\n\n\nLearn a “recipe” for data analysis\n\nGreat for class becaus it’s easy\nNot useful in practice\n\nProvide a formal introduction to statistics/data-science\n\nRequires it’s own course\nFocus here on intuition\n\nHarsh grading\n\nThis is an elective :)\nDiscourages exploration\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n10 minutes\n\n\n\n\nCreate a name-tag for yourself (preferably A4 so I can read it)\nFind someone in class you have not yet met\nDiscuss the following questions and take notes of your neighbors answers\n\nWho are you?\nWhat are you interested in?\nWhat constitutes a good learning environment for me?\nHave you used R or another statistical software before?\nHow can I measure my success in the course?\n\nFormulate 3 measures (e.g., I learned how to run linear regression in R for my thesis)\n\nWhat can Daniel do in each lecture for me to be successful in the course?\n\nFormulate 3 suggestions (e.g., Provide multiple examples for each concept)\n\nWhat can I do in each lecture to be successful in the course?\n\nFormulate 3 review questions for after the lecture (e.g., Did I ask questions if something was unclear?, Did I party yesterday and showed up hung-over?)\n\n\n\n\n\n. . .\nIntroduce your neigbor to the class\n\n\n\n\n\n\n\n\n\nGrading\n\n\n\n\n\n25% class participation\n\nToday: upload 3 suggestions to make your neighbor successful\nEvery lecture: either participate in class directly or upload a short review to Canvas after class\n10% for each Saturday lecture, 5% for Wednesday\n\n\n30% project plan\n\nDiscussion next Wednesday (2024.03.13)\nDue next Friday (2024.03.15)\nUpload to Canvas\nIncludes:\n\nResearch question\nA dataset that can be used to answer the research question\nA target audience\nOptionally: a first idea on how to answer the research question\n\n\n\n45% project presentation\n\nPresentations on Wednesday 11 days from today (2023.03.20)\n\\(\\sim 10 min\\) per presentation\n\\(\\sim 5 min\\) discussion for paired groups\nUpload slides to Canvas\nIncludes:\n\nIntroduction to the research question\nShort literature review\nIntroduction to the data\nModel-free evidence (e.g., visualizations)\nModel-based evidence (e.g., regression analysis)\nConclustion & Recommendation\nOptional: Short discussion of solutions to challenges faced"
  },
  {
    "objectID": "00-admin-page.html#who-am-i",
    "href": "00-admin-page.html#who-am-i",
    "title": "Introduction to the Course",
    "section": "",
    "text": "I’m Daniel 👋\nMasters in Economics with major in Mathematics\nData-driven research in various fields\n\nDissertation: What shapes demand in the music industry?\n\nArtist misconduct (#MeToo) increases demand\nIdentification of playlists important for artist success\n\nOrgan donation\n\nSwitching from opt-in to opt-out does not increase available organs\n\nStatistical software (e.g., shrinkDSM)\nBiomarker analysis for cancer research (e.g., FGF8)\n\nFraud detection for one of the top 5 music markets world-wide\n\nanalysis of \\(\\sim 200\\) billion datapoints\n\n\n\n\n\n\n\nMy Rabbit Georgie"
  },
  {
    "objectID": "00-admin-page.html#why-am-i-here",
    "href": "00-admin-page.html#why-am-i-here",
    "title": "Introduction to the Course",
    "section": "",
    "text": "High-level Goals\n\n\n\n\n\nHave fun\nGain confidence in analysis\nBuild a solid foundation for current and future data-based projects\nLearn to transform raw data into (business/economic) insights\nProvide a safe space for exploration\n\n\n\n\n\n\n\n\n\n\n\n\nExplicit Goals\n\n\n\n\n\nSet up a development environment for data-based projects\n\nUse extensible and future-proof tools\n\nGet familiar with R, Quarto, and Git\n\nCreate a flexible, documented, reproducible, and collaborative workflow\n\nGet familiar with concepts to process, visualize, and analyze data\n\nMake conscious decisions about each step\nConfidently choose models and methods appropriate for a given situation\n\nGain practical experience through conducting a short data analysis\nGrading based on engagement\n\n\n\n\n\n\n\n\n\n\n\n\n\nNon-goals\n\n\n\n\nLearn a “recipe” for data analysis\n\nGreat for class becaus it’s easy\nNot useful in practice\n\nProvide a formal introduction to statistics/data-science\n\nRequires it’s own course\nFocus here on intuition\n\nHarsh grading\n\nThis is an elective :)\nDiscourages exploration"
  },
  {
    "objectID": "00-admin-page.html#why-are-you-here",
    "href": "00-admin-page.html#why-are-you-here",
    "title": "Introduction to the Course",
    "section": "",
    "text": "10 minutes\n\n\n\n\nCreate a name-tag for yourself (preferably A4 so I can read it)\nFind someone in class you have not yet met\nDiscuss the following questions and take notes of your neighbors answers\n\nWho are you?\nWhat are you interested in?\nWhat constitutes a good learning environment for me?\nHave you used R or another statistical software before?\nHow can I measure my success in the course?\n\nFormulate 3 measures (e.g., I learned how to run linear regression in R for my thesis)\n\nWhat can Daniel do in each lecture for me to be successful in the course?\n\nFormulate 3 suggestions (e.g., Provide multiple examples for each concept)\n\nWhat can I do in each lecture to be successful in the course?\n\nFormulate 3 review questions for after the lecture (e.g., Did I ask questions if something was unclear?, Did I party yesterday and showed up hung-over?)\n\n\n\n\n\n. . .\nIntroduce your neigbor to the class"
  },
  {
    "objectID": "00-admin-page.html#whats-next",
    "href": "00-admin-page.html#whats-next",
    "title": "Introduction to the Course",
    "section": "",
    "text": "Grading\n\n\n\n\n\n25% class participation\n\nToday: upload 3 suggestions to make your neighbor successful\nEvery lecture: either participate in class directly or upload a short review to Canvas after class\n10% for each Saturday lecture, 5% for Wednesday\n\n\n30% project plan\n\nDiscussion next Wednesday (2024.03.13)\nDue next Friday (2024.03.15)\nUpload to Canvas\nIncludes:\n\nResearch question\nA dataset that can be used to answer the research question\nA target audience\nOptionally: a first idea on how to answer the research question\n\n\n\n45% project presentation\n\nPresentations on Wednesday 11 days from today (2023.03.20)\n\\(\\sim 10 min\\) per presentation\n\\(\\sim 5 min\\) discussion for paired groups\nUpload slides to Canvas\nIncludes:\n\nIntroduction to the research question\nShort literature review\nIntroduction to the data\nModel-free evidence (e.g., visualizations)\nModel-based evidence (e.g., regression analysis)\nConclustion & Recommendation\nOptional: Short discussion of solutions to challenges faced"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome!",
    "section": "",
    "text": "This website covers the course 6235 Data Literacy (Summer 2024) at WU Vienna (login required for Canvas) created at the Institute for Retailing & Data Science. The main aims of the course are to build a solid foundation for current and future data-based projects and to gain confidence in presenting your analyses through a princpled workflow. This website is updated as more materials are added. The main format of the material is RevealJS and links to the slides can be found on the right-hand side of each page. The pages themselves are automatically generated from the same Quarto files. You will learn how this works as part of this course 😊.\n\nThis course covers\n\nIntroduction to the course\nIntroduction to R\nIntroduction to Quarto\nIntroduction to Git\nPrinciples of Data Visualization\nIntroduction to Causal Modeling\n6.1. Difference-in-Differences Estimation\nIntroduction to Predictive Modeling\n\nBonus: Notes on Logistic Regression"
  },
  {
    "objectID": "99_notes_logistic_regression_interpretation.html",
    "href": "99_notes_logistic_regression_interpretation.html",
    "title": "Logistic Regression Interpretation",
    "section": "",
    "text": "We use logistic regression to estimate models in which the outcome (dependent variable) is binary, i.e., either \\(0\\) or \\(1\\). We can construct such outcomes similar to dummy variables using indicator functions (e.g., Song is in top 10 \\(\\rightarrow\\) \\(1\\), song is not in top 10 \\(\\rightarrow\\) \\(0\\)). In using logistic regression we assume the following functional form\n\\[\nf(\\mathbf{X}) = P(y_i = 1) = \\frac{1}{1 + e^{-(\\beta_0 + \\beta_1 * x_{1,i} + \\beta_2 * x_{2,i} + ... +\\beta_m * x_{m,i})}}\n\\]\nwhere \\(\\beta_k\\) are the coefficients to be estimated, \\(x_{k,i}\\) is the \\(k\\)th variable observed for individual \\(i\\), and \\(P(y_i=1)\\) is the probability of the outcome being \\(1\\) for individual \\(i\\). The non-linear form makes the interpretation of the estimated coefficients more difficult compared to linear regression. We first have to introduce the concept of “odds”.\n\n\n\n\n\n\n\nOdds are the ratio of the number of events that produce the interesting outcome to the number that do not. For example, if you randomly pick a marble from an urn that contains \\(3\\) green, \\(7\\) red, and \\(20\\) blue marbles the odds of picking a blue marble are\n\\[\n\\frac{20}{3+7} = \\frac{20}{10} = \\frac{2}{1}\n\\]\nIn other words, if you pick marbles repeatedly (and put the marble back into the urn), you would, on average, pick \\(2\\) blue marbles for every non-blue marble. Analogously we can define odds in terms of probabilties. In this example \\(2/3\\) or \\(\\sim 66.66\\%\\) of the marbles are blue and \\(1/3\\) or \\(\\sim 33.33\\%\\) of the marbles are not. The odds can be defined as the ratio of the probability of the interesting event occuring to the probability that it does not. In our case:\n\\[\n\\frac{p_{blue}}{1-p_{blue}} = \\frac{0.6666}{0.3333} = \\frac{2}{1}\n\\]\nwhere \\(p_{blue}\\) is the probability of picking a blue marble.\n\n\n\nLet’s take a look at odds in the model we are estimating. In that case we are interested in the ratio of the probability that the interesting event occurs (\\(P(y_i=1)\\)) to the probability that it does not (\\(P(y_i=0) = 1-P(y_i=1)\\)). Plugging in to a simplified version of the model above:\n\\[\n\\begin{aligned}\nP(y_i = 1) &= \\frac{1}{1 + e^{-(\\beta_0 + \\beta_1 * x_{i})}}\\\\\n\\frac{P(y_i = 1)}{1-P(y_i = 1)} &= \\frac{\\frac{1}{1 + e^{-(\\beta_0 + \\beta_1 * x_{i})}}}{1-\\left(\\frac{1}{1 + e^{-(\\beta_0 + \\beta_1 * x_{i})}}\\right)}\\\\\n&= \\frac{1}{\\left(1 + e^{-(\\beta_0 + \\beta_1 * x_{i})}\\right) * \\left(1 - \\frac{1}{1 + e^{-(\\beta_0 + \\beta_1 * x_{i})}}\\right)}\\\\\n&= \\frac{1}{1 + e^{-(\\beta_0 + \\beta_1 * x_{i})} - \\frac{1+e^{-(\\beta_0 + \\beta_1 * x_{i})}}{1+e^{-(\\beta_0 + \\beta_1 * x_{i})}}}\\\\\n&= \\frac{1}{1 + e^{-(\\beta_0 + \\beta_1 * x_{i})} - 1 } \\\\\n&= \\frac{1}{e^{-(\\beta_0 + \\beta_1 * x_{i})}}\\\\\n\\frac{P(y_i = 1)}{1-P(y_i = 1)} &= e^{\\beta_0 + \\beta_1 * x_i}\n\\end{aligned}\n\\]\nThe first takeaway here is that we get a linear expression in terms of the log-odds of the event:\n\\[\nln\\left(\\frac{P(y_i = 1)}{1-P(y_i = 1)}\\right) = \\beta_0 + \\beta_1 * x_i\n\\] It also gets us closer to interpreting the \\(\\beta_k\\) coefficients. Let’s see how the odds change as a result of changing \\(x_i\\) by one unit.\n\n\n\nAn odds ratio is the ratio of the odds of the interesting event given some observed value to the odds of the interesting event in the absence of that value. In our example we could calculate the odds ratio for a situation in which \\(x_i\\) is incremented by one unit vs. a scenario without the increment.\n\\[\n\\begin{aligned}\nOR &= \\frac{\\left(\\frac{P(y_i = 1 | x'_i)}{1-P(y_i = 1|x'_i)}\\right)}{\\left(\\frac{P(y_i = 1 | x_i)}{1-P(y_i = 1|x_i)}\\right)}\\\\\n   &= \\frac{e^{\\beta_0 + \\beta_1 * (x_i + 1)}}{e^{\\beta_0 + \\beta_1 * x_i}} \\\\\n   &= e^{\\beta_0 + \\beta_1 * x_i + \\beta_1 * 1} * e^{-\\beta_0 - \\beta_1 * x_i}\\\\\n   &= e^{\\beta_0 - \\beta_0 + \\beta_1 * x_i - \\beta_1 * x_i + \\beta_1}\\\\\nOR &= e^{\\beta_1}\n\\end{aligned}\n\\]\nwhere \\(x'_i\\) indicates that \\(x_i\\) was increased by one unit. We note that \\(e^{\\beta_1}\\) is the ratio of the odds of the interesting event (i.e., \\(y_i = 1\\)) in the presence of a one unit increase of \\(x_i\\) and the odds in the absence of the increase (short: the odds ratio).\n\n\n\nThe exponent in the estimated model gives us an indication that the marginal effect \\(x_i\\) on \\(P(y_i=1)\\) could depend on the level of \\(x_i\\) and not be constant as we are used to in linear models. It is easy to show that this is indeed the case. First let \\(u=1+e^{-\\beta_0 -\\beta_1 x_i}\\) and \\(v=-\\beta_0 -\\beta_1 x_i\\).\n\\[\n\\begin{aligned}\n\\frac{\\delta}{\\delta x_i}P(y_i = 1) &= \\frac{\\delta}{\\delta x_i} \\frac{1}{1 + e^{-(\\beta_0 + \\beta_1 * x_{i})}}\\\\\n\\text{by chain rule}\\\\\n&= \\frac{\\delta}{\\delta u} \\frac{1}{u} * \\frac{\\delta u}{\\delta x_i}\\\\\n&= - \\frac{1}{u^2} \\frac{\\delta}{\\delta x_i} 1+e^{-\\beta_0 -\\beta_1 x_i}\\\\\n\\text{again using chain rule}\\\\\n&= - \\frac{1}{u^2} \\frac{\\delta}{\\delta v} (1 + e^{v}) * \\frac{\\delta v}{\\delta x_i}\\\\\n&= - \\frac{1}{u^2} e^v * (-\\beta_1) \\\\\n\\frac{\\delta}{\\delta x_i}P(y_i = 1) &= \\beta_1 \\frac{e^{-\\beta_0 - \\beta_1 x_i}}{\\left(1+e^{-\\beta_0 -\\beta_1 x_i}\\right)^2}\n\\end{aligned}\n\\]\nThus, the marginal effect of \\(x_i\\) on the probability of the interesting event depends not only on \\(\\beta_1\\) but also the level of \\(x_i\\) (in the multivariate case it depends on the values of all other \\(x_{k,i}\\) as well. They also remain in the two exponents above).\nFor the univariate case with a binary predictor we can easily calculate the odds ratio and the marginal effect by hand:\n\n\nCode\n## Group 'l' has p = 0.2\n## Group 'h' has p = 0.9\nprob_low &lt;- 0.2\nprob_high &lt;- 0.9\nset.seed(1)\nobs &lt;- factor(c(rep('l',5000),rep('h',5000)),\n              levels = c('h', 'l'))\n## Shuffle obs\nobs &lt;- obs[order(runif(length(obs)))]\n## Get true outcome probalities\nprobs &lt;- ifelse(obs == 'l', prob_low, prob_high)\n## Draw y from Bernoulli with p = true outcome probability\ndf &lt;- data.frame(x = obs, y = rbinom(length(obs),1,probs))\nstr(df)\n\n\n'data.frame':   10000 obs. of  2 variables:\n $ x: Factor w/ 2 levels \"h\",\"l\": 1 1 2 2 2 2 1 1 1 2 ...\n $ y: int  1 1 0 0 0 0 1 1 1 0 ...\n\n\n\n\nCode\ncounts &lt;- table(df$y, df$x)\ncounts\n\n\n   \n       h    l\n  0  529 4005\n  1 4471  995\n\n\nCode\n## Odds ratio for 1 if in group 'l' vs 'h'\nOR &lt;- (counts['1','l']/counts['0','l']) / (counts['1','h']/counts['0','h'])\n\nmod &lt;- glm(y ~ x, data = df, family = binomial(link = 'logit'))\nsummary(mod)\n\n\n\nCall:\nglm(formula = y ~ x, family = binomial(link = \"logit\"), data = df)\n\nCoefficients:\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)  2.13438    0.04598   46.42   &lt;2e-16 ***\nxl          -3.52694    0.05804  -60.77   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 13776.0  on 9999  degrees of freedom\nResidual deviance:  8366.6  on 9998  degrees of freedom\nAIC: 8370.6\n\nNumber of Fisher Scoring iterations: 4\n\n\nCode\nexp(coef(mod))\n\n\n(Intercept)          xl \n 8.45179580  0.02939487 \n\n\nCode\n## Odds ratio by hand:\nOR\n\n\n[1] 0.02939487\n\n\nCode\nlibrary(mfx)\nlogitmfx(y~x, data = df, atmean = FALSE)\n\n\nCall:\nlogitmfx(formula = y ~ x, data = df, atmean = FALSE)\n\nMarginal Effects:\n        dF/dx  Std. Err.      z     P&gt;|z|    \nxl -0.6952000  0.0071274 -97.54 &lt; 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\ndF/dx is for discrete change for the following variables:\n\n[1] \"xl\"\n\n\nCode\n## Marginal effect by hand\nptable &lt;- prop.table(table(df$y, df$x),2)\nptable\n\n\n   \n         h      l\n  0 0.1058 0.8010\n  1 0.8942 0.1990\n\n\nCode\n## Change of probability that y = 1 from 'h' to 'l'\n## should be roughly 0.2 - 0.9 = -0.7\nptable['1','l'] - ptable['1','h'] \n\n\n[1] -0.6952\n\n\nFor a more interesting case with a continuous predictor implement the marginal effects formula (for the univariate case) as follows:\n\nmfx_simple &lt;- function(mod,x){\n  beta_0 &lt;- coef(mod)['(Intercept)']\n  beta_1 &lt;- coef(mod)[2]\n  A &lt;- exp(-beta_0 - beta_1 * x)\n  beta_1 * A / (1+A)^2\n}\n\nThe following data includes a binary outcome whether an individual had an extramarital affair (affair_yn). As a predictor the years the person is already married is used. There are two options to calculate as summary for the marginal effect of another year in marriage on the probability of having an affair. First, one could simply plug in the average number of years married from the sample (default in the mfx library)\n\n\nCode\nlibrary(AER)\ndata(\"Affairs\")\nAffairs$affair_yn &lt;- Affairs$affairs &gt; 0\nmod &lt;- glm(affair_yn ~ yearsmarried, data = Affairs, family = binomial())\nlogitmfx(affair_yn ~ yearsmarried, data = Affairs)\n\n\nCall:\nlogitmfx(formula = affair_yn ~ yearsmarried, data = Affairs)\n\nMarginal Effects:\n                 dF/dx Std. Err.      z     P&gt;|z|    \nyearsmarried 0.0108689 0.0031439 3.4572 0.0005459 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nCode\nmfx_simple(mod, mean(Affairs$yearsmarried))\n\n\nyearsmarried \n  0.01086895 \n\n\nAlternatively we can calculate the marginal effects at each observation and calculate the average of all the effects (atmean = FALSE)\n\n\nCode\nlogitmfx(affair_yn ~ yearsmarried, data = Affairs, atmean = FALSE)\n\n\nCall:\nlogitmfx(formula = affair_yn ~ yearsmarried, data = Affairs, \n    atmean = FALSE)\n\nMarginal Effects:\n                dF/dx Std. Err.     z   P&gt;|z|   \nyearsmarried 0.010799  0.003327 3.246 0.00117 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nCode\nmean(mfx_simple(mod, Affairs$yearsmarried))\n\n\n[1] 0.0107994"
  },
  {
    "objectID": "99_notes_logistic_regression_interpretation.html#odds",
    "href": "99_notes_logistic_regression_interpretation.html#odds",
    "title": "Logistic Regression Interpretation",
    "section": "",
    "text": "Odds are the ratio of the number of events that produce the interesting outcome to the number that do not. For example, if you randomly pick a marble from an urn that contains \\(3\\) green, \\(7\\) red, and \\(20\\) blue marbles the odds of picking a blue marble are\n\\[\n\\frac{20}{3+7} = \\frac{20}{10} = \\frac{2}{1}\n\\]\nIn other words, if you pick marbles repeatedly (and put the marble back into the urn), you would, on average, pick \\(2\\) blue marbles for every non-blue marble. Analogously we can define odds in terms of probabilties. In this example \\(2/3\\) or \\(\\sim 66.66\\%\\) of the marbles are blue and \\(1/3\\) or \\(\\sim 33.33\\%\\) of the marbles are not. The odds can be defined as the ratio of the probability of the interesting event occuring to the probability that it does not. In our case:\n\\[\n\\frac{p_{blue}}{1-p_{blue}} = \\frac{0.6666}{0.3333} = \\frac{2}{1}\n\\]\nwhere \\(p_{blue}\\) is the probability of picking a blue marble."
  },
  {
    "objectID": "99_notes_logistic_regression_interpretation.html#odds-in-logistic-regression",
    "href": "99_notes_logistic_regression_interpretation.html#odds-in-logistic-regression",
    "title": "Logistic Regression Interpretation",
    "section": "",
    "text": "Let’s take a look at odds in the model we are estimating. In that case we are interested in the ratio of the probability that the interesting event occurs (\\(P(y_i=1)\\)) to the probability that it does not (\\(P(y_i=0) = 1-P(y_i=1)\\)). Plugging in to a simplified version of the model above:\n\\[\n\\begin{aligned}\nP(y_i = 1) &= \\frac{1}{1 + e^{-(\\beta_0 + \\beta_1 * x_{i})}}\\\\\n\\frac{P(y_i = 1)}{1-P(y_i = 1)} &= \\frac{\\frac{1}{1 + e^{-(\\beta_0 + \\beta_1 * x_{i})}}}{1-\\left(\\frac{1}{1 + e^{-(\\beta_0 + \\beta_1 * x_{i})}}\\right)}\\\\\n&= \\frac{1}{\\left(1 + e^{-(\\beta_0 + \\beta_1 * x_{i})}\\right) * \\left(1 - \\frac{1}{1 + e^{-(\\beta_0 + \\beta_1 * x_{i})}}\\right)}\\\\\n&= \\frac{1}{1 + e^{-(\\beta_0 + \\beta_1 * x_{i})} - \\frac{1+e^{-(\\beta_0 + \\beta_1 * x_{i})}}{1+e^{-(\\beta_0 + \\beta_1 * x_{i})}}}\\\\\n&= \\frac{1}{1 + e^{-(\\beta_0 + \\beta_1 * x_{i})} - 1 } \\\\\n&= \\frac{1}{e^{-(\\beta_0 + \\beta_1 * x_{i})}}\\\\\n\\frac{P(y_i = 1)}{1-P(y_i = 1)} &= e^{\\beta_0 + \\beta_1 * x_i}\n\\end{aligned}\n\\]\nThe first takeaway here is that we get a linear expression in terms of the log-odds of the event:\n\\[\nln\\left(\\frac{P(y_i = 1)}{1-P(y_i = 1)}\\right) = \\beta_0 + \\beta_1 * x_i\n\\] It also gets us closer to interpreting the \\(\\beta_k\\) coefficients. Let’s see how the odds change as a result of changing \\(x_i\\) by one unit."
  },
  {
    "objectID": "99_notes_logistic_regression_interpretation.html#odds-ratio",
    "href": "99_notes_logistic_regression_interpretation.html#odds-ratio",
    "title": "Logistic Regression Interpretation",
    "section": "",
    "text": "An odds ratio is the ratio of the odds of the interesting event given some observed value to the odds of the interesting event in the absence of that value. In our example we could calculate the odds ratio for a situation in which \\(x_i\\) is incremented by one unit vs. a scenario without the increment.\n\\[\n\\begin{aligned}\nOR &= \\frac{\\left(\\frac{P(y_i = 1 | x'_i)}{1-P(y_i = 1|x'_i)}\\right)}{\\left(\\frac{P(y_i = 1 | x_i)}{1-P(y_i = 1|x_i)}\\right)}\\\\\n   &= \\frac{e^{\\beta_0 + \\beta_1 * (x_i + 1)}}{e^{\\beta_0 + \\beta_1 * x_i}} \\\\\n   &= e^{\\beta_0 + \\beta_1 * x_i + \\beta_1 * 1} * e^{-\\beta_0 - \\beta_1 * x_i}\\\\\n   &= e^{\\beta_0 - \\beta_0 + \\beta_1 * x_i - \\beta_1 * x_i + \\beta_1}\\\\\nOR &= e^{\\beta_1}\n\\end{aligned}\n\\]\nwhere \\(x'_i\\) indicates that \\(x_i\\) was increased by one unit. We note that \\(e^{\\beta_1}\\) is the ratio of the odds of the interesting event (i.e., \\(y_i = 1\\)) in the presence of a one unit increase of \\(x_i\\) and the odds in the absence of the increase (short: the odds ratio)."
  },
  {
    "objectID": "99_notes_logistic_regression_interpretation.html#marginal-effects",
    "href": "99_notes_logistic_regression_interpretation.html#marginal-effects",
    "title": "Logistic Regression Interpretation",
    "section": "",
    "text": "The exponent in the estimated model gives us an indication that the marginal effect \\(x_i\\) on \\(P(y_i=1)\\) could depend on the level of \\(x_i\\) and not be constant as we are used to in linear models. It is easy to show that this is indeed the case. First let \\(u=1+e^{-\\beta_0 -\\beta_1 x_i}\\) and \\(v=-\\beta_0 -\\beta_1 x_i\\).\n\\[\n\\begin{aligned}\n\\frac{\\delta}{\\delta x_i}P(y_i = 1) &= \\frac{\\delta}{\\delta x_i} \\frac{1}{1 + e^{-(\\beta_0 + \\beta_1 * x_{i})}}\\\\\n\\text{by chain rule}\\\\\n&= \\frac{\\delta}{\\delta u} \\frac{1}{u} * \\frac{\\delta u}{\\delta x_i}\\\\\n&= - \\frac{1}{u^2} \\frac{\\delta}{\\delta x_i} 1+e^{-\\beta_0 -\\beta_1 x_i}\\\\\n\\text{again using chain rule}\\\\\n&= - \\frac{1}{u^2} \\frac{\\delta}{\\delta v} (1 + e^{v}) * \\frac{\\delta v}{\\delta x_i}\\\\\n&= - \\frac{1}{u^2} e^v * (-\\beta_1) \\\\\n\\frac{\\delta}{\\delta x_i}P(y_i = 1) &= \\beta_1 \\frac{e^{-\\beta_0 - \\beta_1 x_i}}{\\left(1+e^{-\\beta_0 -\\beta_1 x_i}\\right)^2}\n\\end{aligned}\n\\]\nThus, the marginal effect of \\(x_i\\) on the probability of the interesting event depends not only on \\(\\beta_1\\) but also the level of \\(x_i\\) (in the multivariate case it depends on the values of all other \\(x_{k,i}\\) as well. They also remain in the two exponents above).\nFor the univariate case with a binary predictor we can easily calculate the odds ratio and the marginal effect by hand:\n\n\nCode\n## Group 'l' has p = 0.2\n## Group 'h' has p = 0.9\nprob_low &lt;- 0.2\nprob_high &lt;- 0.9\nset.seed(1)\nobs &lt;- factor(c(rep('l',5000),rep('h',5000)),\n              levels = c('h', 'l'))\n## Shuffle obs\nobs &lt;- obs[order(runif(length(obs)))]\n## Get true outcome probalities\nprobs &lt;- ifelse(obs == 'l', prob_low, prob_high)\n## Draw y from Bernoulli with p = true outcome probability\ndf &lt;- data.frame(x = obs, y = rbinom(length(obs),1,probs))\nstr(df)\n\n\n'data.frame':   10000 obs. of  2 variables:\n $ x: Factor w/ 2 levels \"h\",\"l\": 1 1 2 2 2 2 1 1 1 2 ...\n $ y: int  1 1 0 0 0 0 1 1 1 0 ...\n\n\n\n\nCode\ncounts &lt;- table(df$y, df$x)\ncounts\n\n\n   \n       h    l\n  0  529 4005\n  1 4471  995\n\n\nCode\n## Odds ratio for 1 if in group 'l' vs 'h'\nOR &lt;- (counts['1','l']/counts['0','l']) / (counts['1','h']/counts['0','h'])\n\nmod &lt;- glm(y ~ x, data = df, family = binomial(link = 'logit'))\nsummary(mod)\n\n\n\nCall:\nglm(formula = y ~ x, family = binomial(link = \"logit\"), data = df)\n\nCoefficients:\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)  2.13438    0.04598   46.42   &lt;2e-16 ***\nxl          -3.52694    0.05804  -60.77   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 13776.0  on 9999  degrees of freedom\nResidual deviance:  8366.6  on 9998  degrees of freedom\nAIC: 8370.6\n\nNumber of Fisher Scoring iterations: 4\n\n\nCode\nexp(coef(mod))\n\n\n(Intercept)          xl \n 8.45179580  0.02939487 \n\n\nCode\n## Odds ratio by hand:\nOR\n\n\n[1] 0.02939487\n\n\nCode\nlibrary(mfx)\nlogitmfx(y~x, data = df, atmean = FALSE)\n\n\nCall:\nlogitmfx(formula = y ~ x, data = df, atmean = FALSE)\n\nMarginal Effects:\n        dF/dx  Std. Err.      z     P&gt;|z|    \nxl -0.6952000  0.0071274 -97.54 &lt; 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\ndF/dx is for discrete change for the following variables:\n\n[1] \"xl\"\n\n\nCode\n## Marginal effect by hand\nptable &lt;- prop.table(table(df$y, df$x),2)\nptable\n\n\n   \n         h      l\n  0 0.1058 0.8010\n  1 0.8942 0.1990\n\n\nCode\n## Change of probability that y = 1 from 'h' to 'l'\n## should be roughly 0.2 - 0.9 = -0.7\nptable['1','l'] - ptable['1','h'] \n\n\n[1] -0.6952\n\n\nFor a more interesting case with a continuous predictor implement the marginal effects formula (for the univariate case) as follows:\n\nmfx_simple &lt;- function(mod,x){\n  beta_0 &lt;- coef(mod)['(Intercept)']\n  beta_1 &lt;- coef(mod)[2]\n  A &lt;- exp(-beta_0 - beta_1 * x)\n  beta_1 * A / (1+A)^2\n}\n\nThe following data includes a binary outcome whether an individual had an extramarital affair (affair_yn). As a predictor the years the person is already married is used. There are two options to calculate as summary for the marginal effect of another year in marriage on the probability of having an affair. First, one could simply plug in the average number of years married from the sample (default in the mfx library)\n\n\nCode\nlibrary(AER)\ndata(\"Affairs\")\nAffairs$affair_yn &lt;- Affairs$affairs &gt; 0\nmod &lt;- glm(affair_yn ~ yearsmarried, data = Affairs, family = binomial())\nlogitmfx(affair_yn ~ yearsmarried, data = Affairs)\n\n\nCall:\nlogitmfx(formula = affair_yn ~ yearsmarried, data = Affairs)\n\nMarginal Effects:\n                 dF/dx Std. Err.      z     P&gt;|z|    \nyearsmarried 0.0108689 0.0031439 3.4572 0.0005459 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nCode\nmfx_simple(mod, mean(Affairs$yearsmarried))\n\n\nyearsmarried \n  0.01086895 \n\n\nAlternatively we can calculate the marginal effects at each observation and calculate the average of all the effects (atmean = FALSE)\n\n\nCode\nlogitmfx(affair_yn ~ yearsmarried, data = Affairs, atmean = FALSE)\n\n\nCall:\nlogitmfx(formula = affair_yn ~ yearsmarried, data = Affairs, \n    atmean = FALSE)\n\nMarginal Effects:\n                dF/dx Std. Err.     z   P&gt;|z|   \nyearsmarried 0.010799  0.003327 3.246 0.00117 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nCode\nmean(mfx_simple(mod, Affairs$yearsmarried))\n\n\n[1] 0.0107994"
  },
  {
    "objectID": "00-introduction_to_r-page.html",
    "href": "00-introduction_to_r-page.html",
    "title": "Introduction to R",
    "section": "",
    "text": "Well established in business and scientific computing\nVery powerful language\n\nExpress any operation in terms of\nOften complex functions are already implemented\n\nVery good package manager and ecosystem\n\nWe will use many tools created by companies, universities, and other R community members\n\nVery good for reproducibility\n\nCode documents the process\nShould run the same on my and your machine\nShould be easily adaptable to changing data\n\nOpen source\n\nAll packages can be inspected\nFree to install and use on any computer\n\nDeveloped (partly) and hosted at WU 😋\n\n\n\n\n\n\n\n\nThe R interpreter\n\nThe program that “interprets” R code and runs it\nVery bare-bones, essentially just a text field\nDoes not store code files for reproducibility\n\n\n\nprint(\"Hello, WU!\")\n\n[1] \"Hello, WU!\"\n\npaste0(\"One plus two is: \", 1 + 2)\n\n[1] \"One plus two is: 3\"\n\nc &lt;- data.frame(p = seq(0, 2 * pi, by = 0.001))\nc$h_x &lt;- 16 * sin(c$p)^3\nc$h_y &lt;- 13 * cos(c$p) - 5 * cos(2 * c$p) - 2 * cos(3 * c$p) - cos(4 * c$p)\nplot(c$h_x, c$h_y, type = \"l\", main = \"I &lt;3 R\", frame = F, xlab = NA, ylab = NA)\n\n\n\n\n\n\n\n\n\n\nAn Integrated Development Environment (IDE)\n\nMakes writing and storing R code easier (more fun!)\nThree options compatible with this course:\n\nR Studio Desktop (Recommended)\n\nFocused on R\nEasiest option\n\nVS Code\n\nRecommended if you (plan to) use other languages (Python, C++, Julia, etc.)\nNeeds extension for R but works well\n\nJupyterLab\n\n“Notebooks” for R, Python, and Julia\nOutput generated directly under code “cells”\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMy favorite R package\n\n\n\n\nDownload the presentation template my_favorite_r_package.qmd and the bibliography file data_literacy.bib from Canvas\nSelect a package that was useful to you in the past\nPrepare a short presentation about the package\n\nInclude examples of how to use the package\nShow in which situations that is useful\n\n\n\n\n\n\n\n\nCtrl + Enter to run current line of code (any cursor position)\n\n\n\n\n\n\nCtrl + Enter to run current line of code (any cursor position)\n\n\n\n\n\n\n# This is a comment\nprint(\"Hi\") # also a comment\n\n[1] \"Hi\"\n\n## Assignment of varibale names\nx &lt;- 1\nx\n\n[1] 1\n\n## Missing values\nNA\n\n[1] NA\n\n## Vectors\ny &lt;- c(1, 2, 3, NA)\ny\n\n[1]  1  2  3 NA\n\n\n\n\n\n\n## built-in\nsum(y)\n\n[1] NA\n\nsum(y, na.rm = FALSE)\n\n[1] NA\n\nsum(y, na.rm = TRUE)\n\n[1] 6\n\n## User functions\na_plus_b &lt;- function(a, b = 1) {\n    return(a + b)\n}\na_plus_b(y)\n\n[1]  2  3  4 NA\n\na_plus_b(y, 2)\n\n[1]  3  4  5 NA\n\na_plus_b(b = 2, a = y)\n\n[1]  3  4  5 NA\n\n## Functions provided by packages\n## Installation\n#install.packages(\"ineq\")\nineq::Gini(y)\n\n[1] 0.2222222\n\n## or\nlibrary(ineq)\nGini(y)\n\n[1] 0.2222222\n\n## Help \n?Gini\n\n\n\n\n\ny[1]\n\n[1] 1\n\ny[-1]\n\n[1]  2  3 NA\n\ny[2:3]\n\n[1] 2 3\n\ny[c(1, 3, 4)]\n\n[1]  1  3 NA\n\nset.seed(1)\nx &lt;- y / 2 + rnorm(length(y))\ncbind(y, x)\n\n      y          x\n[1,]  1 -0.1264538\n[2,]  2  1.1836433\n[3,]  3  0.6643714\n[4,] NA         NA\n\ny &gt; 2\n\n[1] FALSE FALSE  TRUE    NA\n\ny &gt; 2 & x &gt; 0\n\n[1] FALSE FALSE  TRUE    NA\n\ny &gt; 2 | x &gt; 0\n\n[1] FALSE  TRUE  TRUE    NA\n\ny[y &gt; 2 | x &gt; 0]\n\n[1]  2  3 NA\n\n\n\n\n\n\n## 'elem' is a temporary variable\nfor (elem in y) {\n    print(paste(\"Current y value is:\", elem))\n}\n\n[1] \"Current y value is: 1\"\n[1] \"Current y value is: 2\"\n[1] \"Current y value is: 3\"\n[1] \"Current y value is: NA\"\n\n## 'seq_along' returns a vector which indexes the argument\nfor (i in seq_along(y)) {\n    print(paste(\"Current y value is:\", y[i]))\n}\n\n[1] \"Current y value is: 1\"\n[1] \"Current y value is: 2\"\n[1] \"Current y value is: 3\"\n[1] \"Current y value is: NA\"\n\n## set.seed guarantees the same random numbers every time\nset.seed(1)\ntotal &lt;- 0\nwhile (total &lt; 1) {\n    ## runif generates random numbers between 0 and 1\n    total &lt;- total + runif(1)\n    print(paste(\"Current total value is:\", total))\n}\n\n[1] \"Current total value is: 0.2655086631421\"\n[1] \"Current total value is: 0.63763256277889\"\n[1] \"Current total value is: 1.21048592613079\"\n\n## ranges\n1:3\n\n[1] 1 2 3\n\n10:3\n\n[1] 10  9  8  7  6  5  4  3\n\nseq(3, 11, by = 2)\n\n[1]  3  5  7  9 11\n\n\n\n\n\n\nz &lt;- -2:3\nfor (x in z) {\n  print(paste(\"x =\", x))\n    if (x &gt; 0) {\n        print(\"x is positive\")\n    } else if (x &gt; 2) {\n        print(\"x is greater than 2\")\n    } else if (x &lt; 0) {\n        print(\"x is negative\")\n    } else if (x == 0) {\n        print(\"x is zero\")\n    }\n}\n\n[1] \"x = -2\"\n[1] \"x is negative\"\n[1] \"x = -1\"\n[1] \"x is negative\"\n[1] \"x = 0\"\n[1] \"x is zero\"\n[1] \"x = 1\"\n[1] \"x is positive\"\n[1] \"x = 2\"\n[1] \"x is positive\"\n[1] \"x = 3\"\n[1] \"x is positive\"\n\nz[z &lt;= 0]\n\n[1] -2 -1  0\n\nz[z &gt;= 0]\n\n[1] 0 1 2 3\n\nz[z != 0]\n\n[1] -2 -1  1  2  3\n\nz[! z &lt; 0]\n\n[1] 0 1 2 3\n\n\n\n\n\n\n\n\n\n\n\nWrite your own function\n\n\n\n\nThe function should take two arguments a and b\nFirst, check if a and b have the same number of elements (see ?length)\n\nIf they have a different number of elements, return NA\n\nIterate over the elements of a and b and check which vector’s element is larger (or if they are equal)\nIf they are equal print the index of the element and “equal”\nIf the element in a is larger print the index of the elemnt and “a larger”\nIf the element in b is larger print the index of the elemnt and “b larger”\n\n\n\n\n\n\na &lt;- c(1, 2, 3)\nb &lt;- c(1, 2, 3, 4)\ncat(\"a is:\", a, \"\\n\")\n\na is: 1 2 3 \n\ncat(\"b is:\", b, \"\\n\")\n\nb is: 1 2 3 4 \n\ncat(\"Result:\\n\")\n\nResult:\n\nNA\n\n[1] NA\n\n\n\n\n\n\na &lt;- c(1, 2, 3)\nb &lt;- c(0, 2, 4)\ncat(\"a is:\", a, \"\\n\")\n\na is: 1 2 3 \n\ncat(\"b is:\", b, \"\\n\")\n\nb is: 0 2 4 \n\ncat(\"Result:\\n\")\n\nResult:\n\nprint(\"1 a larger\")\n\n[1] \"1 a larger\"\n\nprint(\"2 equal\")\n\n[1] \"2 equal\"\n\nprint(\"3 b larger\")\n\n[1] \"3 b larger\"\n\n\n\n\n\n\n\ndata &lt;- data.frame(x = -1:1, y = 3:1, z = c(\"a\", \"b\", NA))\ndata\n\n   x y    z\n1 -1 3    a\n2  0 2    b\n3  1 1 &lt;NA&gt;\n\nclass(data)\n\n[1] \"data.frame\"\n\n## Variable access\ndata$x\n\n[1] -1  0  1\n\ndata$x + data$y\n\n[1] 2 2 2\n\nrow_summaries &lt;- with(data, \n  data.frame(\n    rsum = x + y,\n    rdiff = x - y\n  ))\nrow_summaries\n\n  rsum rdiff\n1    2    -4\n2    2    -2\n3    2     0\n\n\n\n\n\n\nstr(data)\n\n'data.frame':   3 obs. of  3 variables:\n $ x: int  -1 0 1\n $ y: int  3 2 1\n $ z: chr  \"a\" \"b\" NA\n\nsummary(data)\n\n       x              y            z            \n Min.   :-1.0   Min.   :1.0   Length:3          \n 1st Qu.:-0.5   1st Qu.:1.5   Class :character  \n Median : 0.0   Median :2.0   Mode  :character  \n Mean   : 0.0   Mean   :2.0                     \n 3rd Qu.: 0.5   3rd Qu.:2.5                     \n Max.   : 1.0   Max.   :3.0                     \n\nhead(data)\n\n   x y    z\n1 -1 3    a\n2  0 2    b\n3  1 1 &lt;NA&gt;\n\n\n\n\n\n\n## 2D structure of data\n## Empty argument means \"all\"#| \ndata[, c(\"x\", \"y\")]\n\n   x y\n1 -1 3\n2  0 2\n3  1 1\n\ndata[1:3, c(\"x\", \"y\")]\n\n   x y\n1 -1 3\n2  0 2\n3  1 1\n\ndata[1, ]\n\n   x y z\n1 -1 3 a\n\ndata[c(1, 3), c(\"x\", \"z\")]\n\n   x    z\n1 -1    a\n3  1 &lt;NA&gt;\n\ndata[data$x &lt; 3,]\n\n   x y    z\n1 -1 3    a\n2  0 2    b\n3  1 1 &lt;NA&gt;\n\n\n\n\n\n\n## new data has to have the same number of elements\ndata$a &lt;- 2 * data$x\ndata\n\n   x y    z  a\n1 -1 3    a -2\n2  0 2    b  0\n3  1 1 &lt;NA&gt;  2\n\ndata$b &lt;- c(\"one\", \"two\", \"three\")\ndata\n\n   x y    z  a     b\n1 -1 3    a -2   one\n2  0 2    b  0   two\n3  1 1 &lt;NA&gt;  2 three\n\ndata$x &lt;- NULL\ndata\n\n  y    z  a     b\n1 3    a -2   one\n2 2    b  0   two\n3 1 &lt;NA&gt;  2 three\n\ndata$a &lt;- log(data$a)\n\nWarning in log(data$a): NaNs produced\n\ndata\n\n  y    z         a     b\n1 3    a       NaN   one\n2 2    b      -Inf   two\n3 1 &lt;NA&gt; 0.6931472 three\n\ndata$b[data$b == \"two\"] &lt;- \"TWO!\"\ndata$z[is.na(data$z)] &lt;- \"c\"\ndata$a[is.nan(data$a)] &lt;- 0\ndata\n\n  y z         a     b\n1 3 a 0.0000000   one\n2 2 b      -Inf  TWO!\n3 1 c 0.6931472 three\n\n\n\n\n\n\n\n\n\n\n\nGenerate your own data\n\n\n\n\nLook at the helpfiles of rnorm, runif, and ifelse\nCreate a data.frame with 10 rows and variables x, generated using runif and y, generated using rnorm\nAdd variable z which takes the value 1 if x is larger than y and 0 otherwise\nCreate a second data.frame that holds the rows of the original one for which z == 1 is TRUE.\nRemove column z from the second data.frame\nWhat happens if you try to create a data.frame when x and y have a differnent number of elements?\nWhat happens if you run the code you wrote for this exercise again (and again)?\nHow can you ensure that each run yields the same results?\n\n\n\n\n\n\n\nPlease download & unzip the folder found in “data” in Canvas\nWe will first use the “penguins” folder which includes the penguins_raw data set in multiple file formats\n\n\n## CSV\npenguins_raw &lt;- readr::read_csv(\"data/penguins/penguins_raw.csv\")\n\nNew names:\n• `` -&gt; `...1`\n\n\nWarning: One or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\n\n\nRows: 345 Columns: 18\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (10): ...1, studyName, Species, Region, Island, Stage, Individual ID, C...\ndbl   (7): Sample Number, Culmen Length (mm), Culmen Depth (mm), Flipper Len...\ndate  (1): Date Egg\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nhead(penguins_raw, 2)\n\n# A tibble: 2 × 18\n  ...1     studyName `Sample Number` Species Region Island Stage `Individual ID`\n  &lt;chr&gt;    &lt;chr&gt;               &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;  &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt;          \n1 # this … &lt;NA&gt;                   NA &lt;NA&gt;    &lt;NA&gt;   &lt;NA&gt;   &lt;NA&gt;  &lt;NA&gt;           \n2 1        PAL0708                 1 Adelie… Anvers Torge… Adul… N1A1           \n# ℹ 10 more variables: `Clutch Completion` &lt;chr&gt;, `Date Egg` &lt;date&gt;,\n#   `Culmen Length (mm)` &lt;dbl&gt;, `Culmen Depth (mm)` &lt;dbl&gt;,\n#   `Flipper Length (mm)` &lt;dbl&gt;, `Body Mass (g)` &lt;dbl&gt;, Sex &lt;chr&gt;,\n#   `Delta 15 N (o/oo)` &lt;dbl&gt;, `Delta 13 C (o/oo)` &lt;dbl&gt;, Comments &lt;chr&gt;\n\n\n. . .\n\npenguins_raw[1,1]\n\n# A tibble: 1 × 1\n  ...1                                              \n  &lt;chr&gt;                                             \n1 # this is a comment making the data harder to read\n\n\n\n\n\n\n\n\nFix the data\n\n\n\n\nThe second row (after the column names) in the penguins_raw.csv file is a comment\nLook at the help file for the readr::read_csv function (?readr::read_csv)\nHow can we ignore the comment row?\n\n\n\n\n\n\n\n## CSV\npenguins_raw &lt;- readr::read_csv(\n  \"data/penguins/penguins_raw.csv\",\n  comment = \"#\")\n\nNew names:\nRows: 344 Columns: 18\n── Column specification\n──────────────────────────────────────────────────────── Delimiter: \",\" chr\n(9): studyName, Species, Region, Island, Stage, Individual ID, Clutch C... dbl\n(8): ...1, Sample Number, Culmen Length (mm), Culmen Depth (mm), Flippe... date\n(1): Date Egg\nℹ Use `spec()` to retrieve the full column specification for this data. ℹ\nSpecify the column types or set `show_col_types = FALSE` to quiet this message.\n• `` -&gt; `...1`\n\nhead(penguins_raw, 2)\n\n# A tibble: 2 × 18\n   ...1 studyName `Sample Number` Species    Region Island Stage `Individual ID`\n  &lt;dbl&gt; &lt;chr&gt;               &lt;dbl&gt; &lt;chr&gt;      &lt;chr&gt;  &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt;          \n1     1 PAL0708                 1 Adelie Pe… Anvers Torge… Adul… N1A1           \n2     2 PAL0708                 2 Adelie Pe… Anvers Torge… Adul… N1A2           \n# ℹ 10 more variables: `Clutch Completion` &lt;chr&gt;, `Date Egg` &lt;date&gt;,\n#   `Culmen Length (mm)` &lt;dbl&gt;, `Culmen Depth (mm)` &lt;dbl&gt;,\n#   `Flipper Length (mm)` &lt;dbl&gt;, `Body Mass (g)` &lt;dbl&gt;, Sex &lt;chr&gt;,\n#   `Delta 15 N (o/oo)` &lt;dbl&gt;, `Delta 13 C (o/oo)` &lt;dbl&gt;, Comments &lt;chr&gt;\n\npenguins_raw[1,1]\n\n# A tibble: 1 × 1\n   ...1\n  &lt;dbl&gt;\n1     1\n\nstr(penguins_raw)\n\nspc_tbl_ [344 × 18] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n $ ...1               : num [1:344] 1 2 3 4 5 6 7 8 9 10 ...\n $ studyName          : chr [1:344] \"PAL0708\" \"PAL0708\" \"PAL0708\" \"PAL0708\" ...\n $ Sample Number      : num [1:344] 1 2 3 4 5 6 7 8 9 10 ...\n $ Species            : chr [1:344] \"Adelie Penguin (Pygoscelis adeliae)\" \"Adelie Penguin (Pygoscelis adeliae)\" \"Adelie Penguin (Pygoscelis adeliae)\" \"Adelie Penguin (Pygoscelis adeliae)\" ...\n $ Region             : chr [1:344] \"Anvers\" \"Anvers\" \"Anvers\" \"Anvers\" ...\n $ Island             : chr [1:344] \"Torgersen\" \"Torgersen\" \"Torgersen\" \"Torgersen\" ...\n $ Stage              : chr [1:344] \"Adult, 1 Egg Stage\" \"Adult, 1 Egg Stage\" \"Adult, 1 Egg Stage\" \"Adult, 1 Egg Stage\" ...\n $ Individual ID      : chr [1:344] \"N1A1\" \"N1A2\" \"N2A1\" \"N2A2\" ...\n $ Clutch Completion  : chr [1:344] \"Yes\" \"Yes\" \"Yes\" \"Yes\" ...\n $ Date Egg           : Date[1:344], format: \"2007-11-11\" \"2007-11-11\" ...\n $ Culmen Length (mm) : num [1:344] 39.1 39.5 40.3 NA 36.7 39.3 38.9 39.2 34.1 42 ...\n $ Culmen Depth (mm)  : num [1:344] 18.7 17.4 18 NA 19.3 20.6 17.8 19.6 18.1 20.2 ...\n $ Flipper Length (mm): num [1:344] 181 186 195 NA 193 190 181 195 193 190 ...\n $ Body Mass (g)      : num [1:344] 3750 3800 3250 NA 3450 ...\n $ Sex                : chr [1:344] \"MALE\" \"FEMALE\" \"FEMALE\" NA ...\n $ Delta 15 N (o/oo)  : num [1:344] NA 8.95 8.37 NA 8.77 ...\n $ Delta 13 C (o/oo)  : num [1:344] NA -24.7 -25.3 NA -25.3 ...\n $ Comments           : chr [1:344] \"Not enough blood for isotopes.\" NA NA \"Adult not sampled.\" ...\n - attr(*, \"spec\")=\n  .. cols(\n  ..   ...1 = col_double(),\n  ..   studyName = col_character(),\n  ..   `Sample Number` = col_double(),\n  ..   Species = col_character(),\n  ..   Region = col_character(),\n  ..   Island = col_character(),\n  ..   Stage = col_character(),\n  ..   `Individual ID` = col_character(),\n  ..   `Clutch Completion` = col_character(),\n  ..   `Date Egg` = col_date(format = \"\"),\n  ..   `Culmen Length (mm)` = col_double(),\n  ..   `Culmen Depth (mm)` = col_double(),\n  ..   `Flipper Length (mm)` = col_double(),\n  ..   `Body Mass (g)` = col_double(),\n  ..   Sex = col_character(),\n  ..   `Delta 15 N (o/oo)` = col_double(),\n  ..   `Delta 13 C (o/oo)` = col_double(),\n  ..   Comments = col_character()\n  .. )\n - attr(*, \"problems\")=&lt;externalptr&gt; \n\n\n\n\n\n\nThe readxl package provides functions for reading Excel files\n\n\npenguins_raw &lt;- readxl::read_excel(\"data/penguins/penguins_raw.xlsx\")\n\nNew names:\n• `` -&gt; `...1`\n\nhead(penguins_raw, 2)\n\n# A tibble: 2 × 18\n  ...1  studyName `Sample Number` Species    Region Island Stage `Individual ID`\n  &lt;chr&gt; &lt;chr&gt;               &lt;dbl&gt; &lt;chr&gt;      &lt;chr&gt;  &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt;          \n1 1     PAL0708                 1 Adelie Pe… Anvers Torge… Adul… N1A1           \n2 2     PAL0708                 2 Adelie Pe… Anvers Torge… Adul… N1A2           \n# ℹ 10 more variables: `Clutch Completion` &lt;chr&gt;, `Date Egg` &lt;dttm&gt;,\n#   `Culmen Length (mm)` &lt;dbl&gt;, `Culmen Depth (mm)` &lt;dbl&gt;,\n#   `Flipper Length (mm)` &lt;dbl&gt;, `Body Mass (g)` &lt;dbl&gt;, Sex &lt;chr&gt;,\n#   `Delta 15 N (o/oo)` &lt;dbl&gt;, `Delta 13 C (o/oo)` &lt;dbl&gt;, Comments &lt;chr&gt;\n\n## Read a subset \npenguins_subset &lt;- readxl::read_excel(\"data/penguins/penguins_raw.xlsx\", sheet = \"Sheet1\", range = \"B1:O345\")\nhead(penguins_subset, 2)\n\n# A tibble: 2 × 14\n  studyName `Sample Number` Species          Region Island Stage `Individual ID`\n  &lt;chr&gt;               &lt;dbl&gt; &lt;chr&gt;            &lt;chr&gt;  &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt;          \n1 PAL0708                 1 Adelie Penguin … Anvers Torge… Adul… N1A1           \n2 PAL0708                 2 Adelie Penguin … Anvers Torge… Adul… N1A2           \n# ℹ 7 more variables: `Clutch Completion` &lt;chr&gt;, `Date Egg` &lt;dttm&gt;,\n#   `Culmen Length (mm)` &lt;dbl&gt;, `Culmen Depth (mm)` &lt;dbl&gt;,\n#   `Flipper Length (mm)` &lt;dbl&gt;, `Body Mass (g)` &lt;dbl&gt;, Sex &lt;chr&gt;\n\n\n\n\n\n\nThe haven package provides functions for reading SPSS, Stata, and SAS files\nIt looks like SPSS does not support spaces in column names so this is slightly different\n\n\npenguins_raw &lt;- haven::read_sav(\"data/penguins/penguins_raw.sav\")\nhead(penguins_raw, 2)\n\n# A tibble: 2 × 17\n  study_name sample_number species             region island stage individual_id\n  &lt;chr&gt;              &lt;dbl&gt; &lt;chr&gt;               &lt;chr&gt;  &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt;        \n1 PAL0708                1 Adelie Penguin (Py… Anvers Torge… Adul… N1A1         \n2 PAL0708                2 Adelie Penguin (Py… Anvers Torge… Adul… N1A2         \n# ℹ 10 more variables: clutch_completion &lt;chr&gt;, date_egg &lt;date&gt;,\n#   culmen_length_mm &lt;dbl&gt;, culmen_depth_mm &lt;dbl&gt;, flipper_length_mm &lt;dbl&gt;,\n#   body_mass_g &lt;dbl&gt;, sex &lt;chr&gt;, delta_15_n_o_oo &lt;dbl&gt;, delta_13_c_o_oo &lt;dbl&gt;,\n#   comments &lt;chr&gt;\n\n\n\n\n\n\nThe arrow package provides functions for reading Parquet and Feather files\nOptimized formats used in many data science projects\nProvides facility to read from “object storage” (e.g., Amazon S3)\n\n\nThe major benefits of object storage are the virtually unlimited scalability and the lower cost of storing large volumes of data for use cases such as data lakes, cloud native applications, analytics, log files, and machine learning (ML). 1\n\n\nRule of thumb:\n\nuse parquet for large files and long term storage\n\noptimized file size\n\nuse feather for optimized reading and short term storage\n\nmemory layout the same as in the process\n\n\n\n\n\n\n\npenguins_raw &lt;- arrow::read_parquet(\"data/penguins/penguins_raw.parquet\")\npenguins_raw &lt;- arrow::read_feather(\"data/penguins/penguins_raw.feather\")\nhead(penguins_raw, 2)\n\n# A tibble: 2 × 17\n  studyName `Sample Number` Species          Region Island Stage `Individual ID`\n  &lt;chr&gt;               &lt;dbl&gt; &lt;chr&gt;            &lt;chr&gt;  &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt;          \n1 PAL0708                 1 Adelie Penguin … Anvers Torge… Adul… N1A1           \n2 PAL0708                 2 Adelie Penguin … Anvers Torge… Adul… N1A2           \n# ℹ 10 more variables: `Clutch Completion` &lt;chr&gt;, `Date Egg` &lt;date&gt;,\n#   `Culmen Length (mm)` &lt;dbl&gt;, `Culmen Depth (mm)` &lt;dbl&gt;,\n#   `Flipper Length (mm)` &lt;dbl&gt;, `Body Mass (g)` &lt;dbl&gt;, Sex &lt;chr&gt;,\n#   `Delta 15 N (o/oo)` &lt;dbl&gt;, `Delta 13 C (o/oo)` &lt;dbl&gt;, Comments &lt;chr&gt;\n\n\n\nSupport for complex data structures\n\n\npenguin_species_island &lt;- arrow::read_parquet('data/penguins/penguin_species_nested.parquet')\nhead(penguin_species_island, 2)\n\n# A tibble: 2 × 2\n  Island                                 data\n  &lt;chr&gt;     &lt;list&lt;tbl_df&lt;Species:character&gt;&gt;&gt;\n1 Torgersen                          [52 × 1]\n2 Biscoe                            [168 × 1]\n\nhead(tidyr::unnest(penguin_species_island), 2)\n\nWarning: `cols` is now required when using `unnest()`.\nℹ Please use `cols = c(data)`.\n\n\n# A tibble: 2 × 2\n  Island    Species                            \n  &lt;chr&gt;     &lt;chr&gt;                              \n1 Torgersen Adelie Penguin (Pygoscelis adeliae)\n2 Torgersen Adelie Penguin (Pygoscelis adeliae)\n\n\n\n\n\n\nlibrary(microbenchmark)\nmicrobenchmark(\n  csv = readr::read_csv(\"data/penguins/penguins_raw.csv\", \n   show_col_types = FALSE, name_repair = 'minimal'),\n  parquet = arrow::read_parquet(\"data/penguins/penguins_raw.parquet\"),\n  feather = arrow::read_feather(\"data/penguins/penguins_raw.feather\")\n) \n\nWarning in microbenchmark(csv =\nreadr::read_csv(\"data/penguins/penguins_raw.csv\", : less accurate nanosecond\ntimes to avoid potential integer overflows\n\n\nWarning: One or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\nOne or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\nOne or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\nOne or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\nOne or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\nOne or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\nOne or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\nOne or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\nOne or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\nOne or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\nOne or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\nOne or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\nOne or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\nOne or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\nOne or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\nOne or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\nOne or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\nOne or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\nOne or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\nOne or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\nOne or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\nOne or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\nOne or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\nOne or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\nOne or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\nOne or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\nOne or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\nOne or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\nOne or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\nOne or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\nOne or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\nOne or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\nOne or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\nOne or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\nOne or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\nOne or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\nOne or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\nOne or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\nOne or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\nOne or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\nOne or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\nOne or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\nOne or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\nOne or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\nOne or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\nOne or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\nOne or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\nOne or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\nOne or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\nOne or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\nOne or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\nOne or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\nOne or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\nOne or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\nOne or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\nOne or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\nOne or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\nOne or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\nOne or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\nOne or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\nOne or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\nOne or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\nOne or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\nOne or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\nOne or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\nOne or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\nOne or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\nOne or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\nOne or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\nOne or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\nOne or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\nOne or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\nOne or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\nOne or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\nOne or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\nOne or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\nOne or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\nOne or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\nOne or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\nOne or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\nOne or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\nOne or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\nOne or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\nOne or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\nOne or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\nOne or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\nOne or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\nOne or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\nOne or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\nOne or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\nOne or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\nOne or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\nOne or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\nOne or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\nOne or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\nOne or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\nOne or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\nOne or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\nOne or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\nOne or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\n\n\nUnit: milliseconds\n    expr      min       lq     mean   median       uq       max neval cld\n     csv 7.450479 8.018514 8.811865 8.410371 9.001222 15.026582   100 a  \n parquet 1.748691 1.976405 2.097041 2.054654 2.156395  4.799583   100  b \n feather 1.263825 1.468579 1.641316 1.561362 1.669643  4.158835   100   c\n\n\n\n\n\nThe most important types of data are:\n\n\n\n\n\n\n\nData type\nDescription\n\n\n\n\nNumeric\nApproximations of the real numbers, \\(\\normalsize\\mathbb{R}\\) (e.g., mileage a car gets: 23.6, 20.9, etc.)\n\n\nInteger\nWhole numbers, \\(\\normalsize\\mathbb{Z}\\) (e.g., number of sales: 7, 0, 120, 63, etc.)\n\n\nCharacter\nText data (strings, e.g., product names)\n\n\nFactor\nCategorical data for classification (e.g., product groups)\n\n\nLogical\nTRUE, FALSE\n\n\nDate\nDate variables (e.g., sales dates: 21-06-2015, 06-21-15, 21-Jun-2015, etc.)\n\n\n\nVariables can be converted from one type to another using the appropriate functions (e.g., as.numeric(), as.integer(), as.character(), as.factor(), as.logical(), as.Date()).\n\n\n\n\nstr(penguins_raw)\n\ntibble [344 × 17] (S3: tbl_df/tbl/data.frame)\n $ studyName          : chr [1:344] \"PAL0708\" \"PAL0708\" \"PAL0708\" \"PAL0708\" ...\n $ Sample Number      : num [1:344] 1 2 3 4 5 6 7 8 9 10 ...\n $ Species            : chr [1:344] \"Adelie Penguin (Pygoscelis adeliae)\" \"Adelie Penguin (Pygoscelis adeliae)\" \"Adelie Penguin (Pygoscelis adeliae)\" \"Adelie Penguin (Pygoscelis adeliae)\" ...\n $ Region             : chr [1:344] \"Anvers\" \"Anvers\" \"Anvers\" \"Anvers\" ...\n $ Island             : chr [1:344] \"Torgersen\" \"Torgersen\" \"Torgersen\" \"Torgersen\" ...\n $ Stage              : chr [1:344] \"Adult, 1 Egg Stage\" \"Adult, 1 Egg Stage\" \"Adult, 1 Egg Stage\" \"Adult, 1 Egg Stage\" ...\n $ Individual ID      : chr [1:344] \"N1A1\" \"N1A2\" \"N2A1\" \"N2A2\" ...\n $ Clutch Completion  : chr [1:344] \"Yes\" \"Yes\" \"Yes\" \"Yes\" ...\n $ Date Egg           : Date[1:344], format: \"2007-11-11\" \"2007-11-11\" ...\n $ Culmen Length (mm) : num [1:344] 39.1 39.5 40.3 NA 36.7 39.3 38.9 39.2 34.1 42 ...\n $ Culmen Depth (mm)  : num [1:344] 18.7 17.4 18 NA 19.3 20.6 17.8 19.6 18.1 20.2 ...\n $ Flipper Length (mm): num [1:344] 181 186 195 NA 193 190 181 195 193 190 ...\n $ Body Mass (g)      : num [1:344] 3750 3800 3250 NA 3450 ...\n $ Sex                : chr [1:344] \"MALE\" \"FEMALE\" \"FEMALE\" NA ...\n $ Delta 15 N (o/oo)  : num [1:344] NA 8.95 8.37 NA 8.77 ...\n $ Delta 13 C (o/oo)  : num [1:344] NA -24.7 -25.3 NA -25.3 ...\n $ Comments           : chr [1:344] \"Not enough blood for isotopes.\" NA NA \"Adult not sampled.\" ...\n - attr(*, \"spec\")=\n  .. cols(\n  ..   studyName = col_character(),\n  ..   `Sample Number` = col_double(),\n  ..   Species = col_character(),\n  ..   Region = col_character(),\n  ..   Island = col_character(),\n  ..   Stage = col_character(),\n  ..   `Individual ID` = col_character(),\n  ..   `Clutch Completion` = col_character(),\n  ..   `Date Egg` = col_date(format = \"\"),\n  ..   `Culmen Length (mm)` = col_double(),\n  ..   `Culmen Depth (mm)` = col_double(),\n  ..   `Flipper Length (mm)` = col_double(),\n  ..   `Body Mass (g)` = col_double(),\n  ..   Sex = col_character(),\n  ..   `Delta 15 N (o/oo)` = col_double(),\n  ..   `Delta 13 C (o/oo)` = col_double(),\n  ..   Comments = col_character()\n  .. )\n\n\n\nClean the column names\n\n\npenguins &lt;- janitor::clean_names(penguins_raw)\nstr(penguins)\n\ntibble [344 × 17] (S3: tbl_df/tbl/data.frame)\n $ study_name       : chr [1:344] \"PAL0708\" \"PAL0708\" \"PAL0708\" \"PAL0708\" ...\n $ sample_number    : num [1:344] 1 2 3 4 5 6 7 8 9 10 ...\n $ species          : chr [1:344] \"Adelie Penguin (Pygoscelis adeliae)\" \"Adelie Penguin (Pygoscelis adeliae)\" \"Adelie Penguin (Pygoscelis adeliae)\" \"Adelie Penguin (Pygoscelis adeliae)\" ...\n $ region           : chr [1:344] \"Anvers\" \"Anvers\" \"Anvers\" \"Anvers\" ...\n $ island           : chr [1:344] \"Torgersen\" \"Torgersen\" \"Torgersen\" \"Torgersen\" ...\n $ stage            : chr [1:344] \"Adult, 1 Egg Stage\" \"Adult, 1 Egg Stage\" \"Adult, 1 Egg Stage\" \"Adult, 1 Egg Stage\" ...\n $ individual_id    : chr [1:344] \"N1A1\" \"N1A2\" \"N2A1\" \"N2A2\" ...\n $ clutch_completion: chr [1:344] \"Yes\" \"Yes\" \"Yes\" \"Yes\" ...\n $ date_egg         : Date[1:344], format: \"2007-11-11\" \"2007-11-11\" ...\n $ culmen_length_mm : num [1:344] 39.1 39.5 40.3 NA 36.7 39.3 38.9 39.2 34.1 42 ...\n $ culmen_depth_mm  : num [1:344] 18.7 17.4 18 NA 19.3 20.6 17.8 19.6 18.1 20.2 ...\n $ flipper_length_mm: num [1:344] 181 186 195 NA 193 190 181 195 193 190 ...\n $ body_mass_g      : num [1:344] 3750 3800 3250 NA 3450 ...\n $ sex              : chr [1:344] \"MALE\" \"FEMALE\" \"FEMALE\" NA ...\n $ delta_15_n_o_oo  : num [1:344] NA 8.95 8.37 NA 8.77 ...\n $ delta_13_c_o_oo  : num [1:344] NA -24.7 -25.3 NA -25.3 ...\n $ comments         : chr [1:344] \"Not enough blood for isotopes.\" NA NA \"Adult not sampled.\" ...\n - attr(*, \"spec\")=\n  .. cols(\n  ..   studyName = col_character(),\n  ..   `Sample Number` = col_double(),\n  ..   Species = col_character(),\n  ..   Region = col_character(),\n  ..   Island = col_character(),\n  ..   Stage = col_character(),\n  ..   `Individual ID` = col_character(),\n  ..   `Clutch Completion` = col_character(),\n  ..   `Date Egg` = col_date(format = \"\"),\n  ..   `Culmen Length (mm)` = col_double(),\n  ..   `Culmen Depth (mm)` = col_double(),\n  ..   `Flipper Length (mm)` = col_double(),\n  ..   `Body Mass (g)` = col_double(),\n  ..   Sex = col_character(),\n  ..   `Delta 15 N (o/oo)` = col_double(),\n  ..   `Delta 13 C (o/oo)` = col_double(),\n  ..   Comments = col_character()\n  .. )\n\n\n\n\n\n\n|&gt; is the “pipe” operator\n\nIt takes the result of the left side and passes it to the right side as the first argument\nVery useful when “chaining” multiple operations\n\n\n\npenguins |&gt;\n  head(2)\n\n# A tibble: 2 × 17\n  study_name sample_number species             region island stage individual_id\n  &lt;chr&gt;              &lt;dbl&gt; &lt;chr&gt;               &lt;chr&gt;  &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt;        \n1 PAL0708                1 Adelie Penguin (Py… Anvers Torge… Adul… N1A1         \n2 PAL0708                2 Adelie Penguin (Py… Anvers Torge… Adul… N1A2         \n# ℹ 10 more variables: clutch_completion &lt;chr&gt;, date_egg &lt;date&gt;,\n#   culmen_length_mm &lt;dbl&gt;, culmen_depth_mm &lt;dbl&gt;, flipper_length_mm &lt;dbl&gt;,\n#   body_mass_g &lt;dbl&gt;, sex &lt;chr&gt;, delta_15_n_o_oo &lt;dbl&gt;, delta_13_c_o_oo &lt;dbl&gt;,\n#   comments &lt;chr&gt;\n\nhead(penguins, 2)\n\n# A tibble: 2 × 17\n  study_name sample_number species             region island stage individual_id\n  &lt;chr&gt;              &lt;dbl&gt; &lt;chr&gt;               &lt;chr&gt;  &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt;        \n1 PAL0708                1 Adelie Penguin (Py… Anvers Torge… Adul… N1A1         \n2 PAL0708                2 Adelie Penguin (Py… Anvers Torge… Adul… N1A2         \n# ℹ 10 more variables: clutch_completion &lt;chr&gt;, date_egg &lt;date&gt;,\n#   culmen_length_mm &lt;dbl&gt;, culmen_depth_mm &lt;dbl&gt;, flipper_length_mm &lt;dbl&gt;,\n#   body_mass_g &lt;dbl&gt;, sex &lt;chr&gt;, delta_15_n_o_oo &lt;dbl&gt;, delta_13_c_o_oo &lt;dbl&gt;,\n#   comments &lt;chr&gt;\n\n\n\n\n\n\nPkg: dplyr provides function for data.frame manipulation\nPkg: stringr provides functions to manipulate strings (characters)\nfn: mutate takes each row and applies a function to create a new (or overwrite a) column\nfn: select selects columns\n\n\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(stringr)\npenguins_subset &lt;- penguins |&gt;\n  mutate(\n    species = str_split(species, \" \", n = 2, simplify = TRUE)[,1],\n    is_adult = str_detect(str_to_lower(stage), \"adult\"),\n    is_female = str_detect(str_to_lower(sex), \"female\"),\n    sex = str_to_lower(sex)) |&gt;\n  select(species, island, sex, is_adult,  culmen_length_mm, culmen_depth_mm, is_female)\npenguins_subset |&gt; head(2)\n\n# A tibble: 2 × 7\n  species island    sex    is_adult culmen_length_mm culmen_depth_mm is_female\n  &lt;chr&gt;   &lt;chr&gt;     &lt;chr&gt;  &lt;lgl&gt;               &lt;dbl&gt;           &lt;dbl&gt; &lt;lgl&gt;    \n1 Adelie  Torgersen male   TRUE                 39.1            18.7 FALSE    \n2 Adelie  Torgersen female TRUE                 39.5            17.4 TRUE     \n\n\n\n\n\n\n#penguins_subset &lt;- \npenguins_subset &lt;- penguins_subset |&gt;\n  mutate(\n    across(starts_with('culmen'), \\(x) x / 10),\n    across(species:sex, as.factor),\n    across(c('is_adult', 'is_female'), as.numeric)\n    ) |&gt;\n  mutate_if(is.numeric,\n    list(scaled = \\(x) (x - mean(x, na.rm=TRUE)) / sd(x, na.rm=TRUE))\n  ) |&gt;\n  rename_with(\n    \\(name) str_replace(name, \"mm\", \"cm\"),\n    starts_with('culmen'))\npenguins_subset |&gt; select(-starts_with('is')) |&gt; str()\n\ntibble [344 × 6] (S3: tbl_df/tbl/data.frame)\n $ species                : Factor w/ 3 levels \"Adelie\",\"Chinstrap\",..: 1 1 1 1 1 1 1 1 1 1 ...\n $ sex                    : Factor w/ 2 levels \"female\",\"male\": 2 1 1 NA 1 2 1 2 NA NA ...\n $ culmen_length_cm       : num [1:344] 3.91 3.95 4.03 NA 3.67 3.93 3.89 3.92 3.41 4.2 ...\n $ culmen_depth_cm        : num [1:344] 1.87 1.74 1.8 NA 1.93 2.06 1.78 1.96 1.81 2.02 ...\n $ culmen_length_cm_scaled: num [1:344] -0.883 -0.81 -0.663 NA -1.323 ...\n $ culmen_depth_cm_scaled : num [1:344] 0.784 0.126 0.43 NA 1.088 ...\n - attr(*, \"spec\")=\n  .. cols(\n  ..   studyName = col_character(),\n  ..   `Sample Number` = col_double(),\n  ..   Species = col_character(),\n  ..   Region = col_character(),\n  ..   Island = col_character(),\n  ..   Stage = col_character(),\n  ..   `Individual ID` = col_character(),\n  ..   `Clutch Completion` = col_character(),\n  ..   `Date Egg` = col_date(format = \"\"),\n  ..   `Culmen Length (mm)` = col_double(),\n  ..   `Culmen Depth (mm)` = col_double(),\n  ..   `Flipper Length (mm)` = col_double(),\n  ..   `Body Mass (g)` = col_double(),\n  ..   Sex = col_character(),\n  ..   `Delta 15 N (o/oo)` = col_double(),\n  ..   `Delta 13 C (o/oo)` = col_double(),\n  ..   Comments = col_character()\n  .. )\n\n\n\n\n\n\nSplit the problem into smaller pieces\n\n\n\\(name) str_replace(name, \"mm\", \"cm\")\n\n\\(name) str_replace(name, \"mm\", \"cm\")\n\nstr_replace(\"ammm\", \"mm\", \"cm\")\n\n[1] \"acmm\"\n\n\n\nCheck help files\n\n\n?str_replace\n\n\nCheck typeof() and class()\n\n\ntypeof(\\(name) str_replace(name, \"mm\", \"cm\"))\n\n[1] \"closure\"\n\n\n\\(\\rightarrow\\) closures are functions\n\nSee if you can produce some outcome on the reduced problem\n\n\nmy_function &lt;- \\(name) str_replace(name, \"mm\", \"cm\")\nmy_function('here are some mms')\n\n[1] \"here are some cms\"\n\n\n\n\n\n\nThis is only useful if a function is pure R code\n\n\nstr_replace\n\nfunction (string, pattern, replacement) \n{\n    if (!missing(replacement) && is_replacement_fun(replacement)) {\n        replacement &lt;- as_function(replacement)\n        return(str_transform(string, pattern, replacement))\n    }\n    check_lengths(string, pattern, replacement)\n    switch(type(pattern), empty = no_empty(), bound = no_boundary(), \n        fixed = stri_replace_first_fixed(string, pattern, replacement, \n            opts_fixed = opts(pattern)), coll = stri_replace_first_coll(string, \n            pattern, replacement, opts_collator = opts(pattern)), \n        regex = stri_replace_first_regex(string, pattern, fix_replacement(replacement), \n            opts_regex = opts(pattern)))\n}\n&lt;bytecode: 0x11ada4390&gt;\n&lt;environment: namespace:stringr&gt;\n\n\n\n\n\n\nCommon mistake that leads to cryptic error:\n\n\nmeans &lt;- c(4,5,6)\nmean[1]\n\nError in mean[1]: object of type 'closure' is not subsettable\n\n\n\n\n\n\n\n\n\n\n\nCreate different subsets of data\n“Filter in” (not out) \\(\\rightarrow\\) TRUE rows remain\n\n\nadelies &lt;- penguins_subset |&gt;\n  filter(species == \"Adelie\")\nunique(adelies$species)\n\n[1] Adelie\nLevels: Adelie Chinstrap Gentoo\n\nfemale_adelies &lt;- penguins_subset |&gt;\n  filter(species == \"Adelie\", is_female == 1)\nfemale_adelies |&gt; select(species, sex) |&gt; summary()\n\n      species       sex    \n Adelie   :73   female:73  \n Chinstrap: 0   male  : 0  \n Gentoo   : 0              \n\n\n\n\n\n\nCalculate any appropriate summary for a variable\n\n\nlibrary(tidyr)\npenguins |&gt;\n  drop_na(body_mass_g) |&gt;\n  summarize(avg_weight = mean(body_mass_g))\n\n# A tibble: 1 × 1\n  avg_weight\n       &lt;dbl&gt;\n1      4202.\n\n\n\nCalculate the summary for each group\n\n\npenguins_summary &lt;- penguins_subset |&gt;\n  drop_na(culmen_length_cm) |&gt;\n  group_by(species, sex) |&gt;\n  summarize(avg_clength = mean(culmen_length_cm))\n\n`summarise()` has grouped output by 'species'. You can override using the\n`.groups` argument.\n\npenguins_summary\n\n# A tibble: 8 × 3\n# Groups:   species [3]\n  species   sex    avg_clength\n  &lt;fct&gt;     &lt;fct&gt;        &lt;dbl&gt;\n1 Adelie    female        3.73\n2 Adelie    male          4.04\n3 Adelie    &lt;NA&gt;          3.78\n4 Chinstrap female        4.66\n5 Chinstrap male          5.11\n6 Gentoo    female        4.56\n7 Gentoo    male          4.95\n8 Gentoo    &lt;NA&gt;          4.56\n\n\n\n\n\n\npenguins_summary |&gt;\n  pivot_wider(names_from = species, values_from = avg_clength) \n\n# A tibble: 3 × 4\n  sex    Adelie Chinstrap Gentoo\n  &lt;fct&gt;   &lt;dbl&gt;     &lt;dbl&gt;  &lt;dbl&gt;\n1 female   3.73      4.66   4.56\n2 male     4.04      5.11   4.95\n3 &lt;NA&gt;     3.78     NA      4.56\n\npenguins_wide &lt;- penguins_subset |&gt;\n  drop_na(culmen_length_cm) |&gt;\n  select(culmen_length_cm, species, sex) |&gt;\n  pivot_wider(values_from = culmen_length_cm, names_from = species, values_fn = mean) |&gt;\n  arrange(sex) |&gt;\n  select(sex, Adelie, Chinstrap, Gentoo)\npenguins_wide\n\n# A tibble: 3 × 4\n  sex    Adelie Chinstrap Gentoo\n  &lt;fct&gt;   &lt;dbl&gt;     &lt;dbl&gt;  &lt;dbl&gt;\n1 female   3.73      4.66   4.56\n2 male     4.04      5.11   4.95\n3 &lt;NA&gt;     3.78     NA      4.56\n\npivot_longer(penguins_wide, cols = -sex, names_to = \"species\", values_to = \"avg_clength\")\n\n# A tibble: 9 × 3\n  sex    species   avg_clength\n  &lt;fct&gt;  &lt;chr&gt;           &lt;dbl&gt;\n1 female Adelie           3.73\n2 female Chinstrap        4.66\n3 female Gentoo           4.56\n4 male   Adelie           4.04\n5 male   Chinstrap        5.11\n6 male   Gentoo           4.95\n7 &lt;NA&gt;   Adelie           3.78\n8 &lt;NA&gt;   Chinstrap       NA   \n9 &lt;NA&gt;   Gentoo           4.56\n\n\n\n\n\n\n\n\n\n\n\nBecome the Ornithologist\n\n\n\n\nRead the penguins_raw.feather file\nRemove all whitespace and special characters from the column names\nCalculate the body mass for each penguin in kg\nCreate a pivot-table with the median (?median) body mass for each species on each island\n\nthe island names should be in the first column\nthe species names should be the remaining columns\n\nRepeat the analysis but only for female penguins\n\n\n\n\n\n\n\n\n\nBecome the music manager\n\n\n\n\nRead the top10_charts.csv in chart_data\nWhat is the range of dates in this dataset? (Hint: ?min, ?max)\nWhat is the top region in terms of streams overall? (Hint: ?slice_max)\nCreate a pivot-table of the total streams (in this dataset) within a region on a given day (1st column day, remaining columns region names, values total streams)\n\n\n\n\n\n\n\nOften we have two separate datasets with corresponding groups of rows\n\nStreams, trackID in top10_charts.csv and Song metadata, trackID in top10_meta.csv\npurchaseid, customerid in noahs-orders.csv and productid, purchaseid in noahs-orders_items.csv and customerid, customer metadata in noahs-customers.csv\n\nCombine data using joins\n\n\ncharts &lt;- readr::read_csv(\"data/chart_data/top10_charts.csv\")\n\nRows: 7320 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (3): trackID, region, isrc\ndbl  (3): rank, streams, dayNumber\ndate (1): day\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nsongs &lt;- readr::read_csv(\"data/chart_data/top10_meta.csv\")\n\nRows: 347 Columns: 29\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (12): trackID, trackName, artistName, artistIds, isrc, primary_artistNa...\ndbl  (16): explicit, trackPopularity, n_available_markets, danceability, ene...\ndate  (1): releaseDate\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nstr(charts, give.attr=FALSE)\n\nspc_tbl_ [7,320 × 7] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n $ trackID  : chr [1:7320] \"012iHyRvQQquWQGUTYvDxy\" \"017PF4Q3l4DBUiWoXk4OWT\" \"017PF4Q3l4DBUiWoXk4OWT\" \"017PF4Q3l4DBUiWoXk4OWT\" ...\n $ rank     : num [1:7320] 7 6 7 7 7 8 9 9 10 10 ...\n $ streams  : num [1:7320] 26234 4276985 3688979 3255639 3478044 ...\n $ day      : Date[1:7320], format: \"2020-08-14\" \"2020-03-27\" ...\n $ dayNumber: num [1:7320] 1318 1178 1179 1180 1181 ...\n $ region   : chr [1:7320] \"at\" \"global\" \"global\" \"global\" ...\n $ isrc     : chr [1:7320] \"DEUM72004523\" \"GBAHT1901303\" \"GBAHT1901303\" \"GBAHT1901303\" ...\n\nstr(songs, give.attr=FALSE)\n\nspc_tbl_ [347 × 29] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n $ trackID              : chr [1:347] \"012iHyRvQQquWQGUTYvDxy\" \"017PF4Q3l4DBUiWoXk4OWT\" \"01I9AEz658sQnQzCL3K3QG\" \"033if6Adj8fwBYsQzHOfQ8\" ...\n $ trackName            : chr [1:347] \"Fall Auf\" \"Break My Heart\" \"HOES UP G'S DOWN\" \"100k Cash\" ...\n $ artistName           : chr [1:347] \"Cro feat. badchieff\" \"Dua Lipa\" \"Shirin David\" \"Capital Bra feat. Samra\" ...\n $ artistIds            : chr [1:347] \"3utZ2yeQk0Z3BCOBWP7Vlu,6GoNVmYCl0yUm4pEp80vn6\" \"6M2wZ9GZgrQXHCFfjv46we\" \"0JBdTCGs111JKKYfLqOEBa\" \"4WZGDpNwrC0vNQyl9QzF7d,6h1s4i4XKIYv4ErDelLDN0\" ...\n $ isrc                 : chr [1:347] \"DEUM72004523\" \"GBAHT1901303\" \"DECE72000379\" \"DECE72000176\" ...\n $ explicit             : num [1:347] 0 0 1 0 0 0 0 1 0 0 ...\n $ trackPopularity      : num [1:347] 64 83 75 71 69 82 70 74 89 79 ...\n $ primary_artistName   : chr [1:347] \"Cro\" \"Dua Lipa\" \"Shirin David\" \"Capital Bra\" ...\n $ primary_artistID     : chr [1:347] \"3utZ2yeQk0Z3BCOBWP7Vlu\" \"6M2wZ9GZgrQXHCFfjv46we\" \"0JBdTCGs111JKKYfLqOEBa\" \"4WZGDpNwrC0vNQyl9QzF7d\" ...\n $ artistIDs            : chr [1:347] \"3utZ2yeQk0Z3BCOBWP7Vlu,6GoNVmYCl0yUm4pEp80vn6\" \"6M2wZ9GZgrQXHCFfjv46we\" \"0JBdTCGs111JKKYfLqOEBa\" \"4WZGDpNwrC0vNQyl9QzF7d,6h1s4i4XKIYv4ErDelLDN0\" ...\n $ albumName            : chr [1:347] \"Fall Auf\" \"Future Nostalgia\" \"HOES UP G'S DOWN\" \"100k Cash\" ...\n $ albumID              : chr [1:347] \"1qdHQo41Vkkgs8HtMk5b96\" \"7fJJK56U9fHixgO0HQkhtI\" \"15Njx2PcwnNsI65fnbM7Pw\" \"5cqwoGrjFr3VKYZ9ZC0eL2\" ...\n $ available_markets    : chr [1:347] \"AD, AE, AL, AR, AT, AU, BA, BE, BG, BH, BO, BR, BY, CA, CH, CL, CO, CR, CY, CZ, DE, DK, DO, DZ, EC, EE, EG, ES,\"| __truncated__ \"AD, AE, AR, AU, BE, BG, BH, BO, BR, CA, CL, CO, CR, CY, CZ, DK, DO, DZ, EC, EE, EG, ES, FI, FR, GB, GR, GT, HK,\"| __truncated__ \"AD, AE, AR, AT, AU, BE, BG, BH, BO, BR, CA, CH, CL, CO, CR, CY, CZ, DE, DK, DO, DZ, EC, EE, EG, ES, FI, FR, GB,\"| __truncated__ \"AD, AE, AR, AT, AU, BE, BG, BH, BO, BR, CA, CH, CL, CO, CR, CY, CZ, DE, DK, DO, DZ, EC, EE, EG, ES, FI, FR, GB,\"| __truncated__ ...\n $ n_available_markets  : num [1:347] 92 76 79 79 87 79 3 79 92 92 ...\n $ releaseDate          : Date[1:347], format: \"2020-08-13\" \"2020-03-27\" ...\n $ releaseDate_precision: chr [1:347] \"day\" \"day\" \"day\" \"day\" ...\n $ danceability         : num [1:347] 0.5 0.73 0.73 0.701 0.84 0.795 0.814 0.774 0.641 0.571 ...\n $ energy               : num [1:347] 0.743 0.729 0.777 0.714 0.648 0.607 0.794 0.805 0.324 0.693 ...\n $ key                  : num [1:347] 2 4 1 10 10 7 7 11 11 6 ...\n $ loudness             : num [1:347] -6.65 -3.43 -6.38 -5.91 -5.54 ...\n $ mode                 : num [1:347] 1 0 0 1 0 1 1 0 1 0 ...\n $ speechiness          : num [1:347] 0.0373 0.0886 0.29 0.524 0.0489 0.23 0.0887 0.302 0.0299 0.0545 ...\n $ acousticness         : num [1:347] 0.307 0.167 0.0455 0.289 0.101 0.128 0.119 0.0509 0.698 0.0054 ...\n $ instrumentalness     : num [1:347] 0.00 1.39e-06 1.10e-03 0.00 1.00e-04 1.90e-01 9.00e-04 0.00 0.00 0.00 ...\n $ liveness             : num [1:347] 0.133 0.349 0.0759 0.0883 0.0996 0.111 0.348 0.149 0.328 0.173 ...\n $ valence              : num [1:347] 0.332 0.467 0.578 0.604 0.431 0.25 0.647 0.261 0.273 0.393 ...\n $ tempo                : num [1:347] 166.3 113 177.9 86.9 103 ...\n $ duration_ms          : num [1:347] 191827 221820 130307 173353 124690 ...\n $ time_signature       : num [1:347] 4 4 4 4 4 4 4 4 4 4 ...\n\n\n\n\n\n\nThe name of the join determines which “ids” are kept\nleft_join keeps all rows that have an id in the left dataset\ninner_join only keeps rows with ids in both datasets\n\n\ndata1 &lt;- data.frame(group = c('a', 'a', 'b','c'), value = c(1,2,3,4)) # missing group 'd'\ndata2 &lt;- data.frame(group2 = c('a', 'c', 'd'), value2 = factor(c(\"abc\", \"def\", \"ghi\"))) # missing group 'b'\n\nleft_join(data1, data2, by = c(\"group\" = \"group2\"))\n\n  group value value2\n1     a     1    abc\n2     a     2    abc\n3     b     3   &lt;NA&gt;\n4     c     4    def\n\nright_join(data1, data2, by = c(\"group\" = \"group2\"))\n\n  group value value2\n1     a     1    abc\n2     a     2    abc\n3     c     4    def\n4     d    NA    ghi\n\ninner_join(data1, data2, by = c(\"group\" = \"group2\"))\n\n  group value value2\n1     a     1    abc\n2     a     2    abc\n3     c     4    def\n\n\n\n\n\n\nfull_join returns all rows from both datasets\nsemi_join returns only the columns of the left dataset and filters rows with id in the right dataset\nanti_join keeps only rows that do not have an id in the right table\n\n\nfull_join(data1, data2, by = c(\"group\" = \"group2\"))\n\n  group value value2\n1     a     1    abc\n2     a     2    abc\n3     b     3   &lt;NA&gt;\n4     c     4    def\n5     d    NA    ghi\n\nsemi_join(data1, data2, by = c(\"group\" = \"group2\"))\n\n  group value\n1     a     1\n2     a     2\n3     c     4\n\nfilter(data1, group %in% data2$group2)\n\n  group value\n1     a     1\n2     a     2\n3     c     4\n\nanti_join(data1, data2, by = c(\"group\" = \"group2\"))\n\n  group value\n1     b     3\n\n\n\n\n\n\n\n\n\n\n\nBE the music manager\n\n\n\n\nWho are the top 10 artists in terms of total global streams?\nWhat is their most succesful song?\nFor how many songs are do we not have meta data?\nHow many songs are there in the data? (Hint: ?n_distinct, or ?length, ?unique)\nSave the combined data as top10_all.parquet\n\n\n\n\n\n\nLinks\n\nR Logo\nNoah’s Database\n\nBibliography\n\n\nHorst, Allison Marie, Alison Presmanes Hill, and Kristen B Gorman. 2020. Palmerpenguins: Palmer Archipelago (Antarctica) Penguin Data. https://doi.org/10.5281/zenodo.3960218."
  },
  {
    "objectID": "00-introduction_to_r-page.html#why-r",
    "href": "00-introduction_to_r-page.html#why-r",
    "title": "Introduction to R",
    "section": "",
    "text": "Well established in business and scientific computing\nVery powerful language\n\nExpress any operation in terms of\nOften complex functions are already implemented\n\nVery good package manager and ecosystem\n\nWe will use many tools created by companies, universities, and other R community members\n\nVery good for reproducibility\n\nCode documents the process\nShould run the same on my and your machine\nShould be easily adaptable to changing data\n\nOpen source\n\nAll packages can be inspected\nFree to install and use on any computer\n\nDeveloped (partly) and hosted at WU 😋"
  },
  {
    "objectID": "00-introduction_to_r-page.html#what-do-we-need",
    "href": "00-introduction_to_r-page.html#what-do-we-need",
    "title": "Introduction to R",
    "section": "",
    "text": "The R interpreter\n\nThe program that “interprets” R code and runs it\nVery bare-bones, essentially just a text field\nDoes not store code files for reproducibility\n\n\n\nprint(\"Hello, WU!\")\n\n[1] \"Hello, WU!\"\n\npaste0(\"One plus two is: \", 1 + 2)\n\n[1] \"One plus two is: 3\"\n\nc &lt;- data.frame(p = seq(0, 2 * pi, by = 0.001))\nc$h_x &lt;- 16 * sin(c$p)^3\nc$h_y &lt;- 13 * cos(c$p) - 5 * cos(2 * c$p) - 2 * cos(3 * c$p) - cos(4 * c$p)\nplot(c$h_x, c$h_y, type = \"l\", main = \"I &lt;3 R\", frame = F, xlab = NA, ylab = NA)\n\n\n\n\n\n\n\n\n\n\nAn Integrated Development Environment (IDE)\n\nMakes writing and storing R code easier (more fun!)\nThree options compatible with this course:\n\nR Studio Desktop (Recommended)\n\nFocused on R\nEasiest option\n\nVS Code\n\nRecommended if you (plan to) use other languages (Python, C++, Julia, etc.)\nNeeds extension for R but works well\n\nJupyterLab\n\n“Notebooks” for R, Python, and Julia\nOutput generated directly under code “cells”"
  },
  {
    "objectID": "00-introduction_to_r-page.html#if-you-already-know-r",
    "href": "00-introduction_to_r-page.html#if-you-already-know-r",
    "title": "Introduction to R",
    "section": "",
    "text": "My favorite R package\n\n\n\n\nDownload the presentation template my_favorite_r_package.qmd and the bibliography file data_literacy.bib from Canvas\nSelect a package that was useful to you in the past\nPrepare a short presentation about the package\n\nInclude examples of how to use the package\nShow in which situations that is useful"
  },
  {
    "objectID": "00-introduction_to_r-page.html#basic-workflow-r-studio",
    "href": "00-introduction_to_r-page.html#basic-workflow-r-studio",
    "title": "Introduction to R",
    "section": "",
    "text": "Ctrl + Enter to run current line of code (any cursor position)"
  },
  {
    "objectID": "00-introduction_to_r-page.html#basic-workflow-vs-code",
    "href": "00-introduction_to_r-page.html#basic-workflow-vs-code",
    "title": "Introduction to R",
    "section": "",
    "text": "Ctrl + Enter to run current line of code (any cursor position)"
  },
  {
    "objectID": "00-introduction_to_r-page.html#r-syntax-comments-assignment",
    "href": "00-introduction_to_r-page.html#r-syntax-comments-assignment",
    "title": "Introduction to R",
    "section": "",
    "text": "# This is a comment\nprint(\"Hi\") # also a comment\n\n[1] \"Hi\"\n\n## Assignment of varibale names\nx &lt;- 1\nx\n\n[1] 1\n\n## Missing values\nNA\n\n[1] NA\n\n## Vectors\ny &lt;- c(1, 2, 3, NA)\ny\n\n[1]  1  2  3 NA"
  },
  {
    "objectID": "00-introduction_to_r-page.html#functions",
    "href": "00-introduction_to_r-page.html#functions",
    "title": "Introduction to R",
    "section": "",
    "text": "## built-in\nsum(y)\n\n[1] NA\n\nsum(y, na.rm = FALSE)\n\n[1] NA\n\nsum(y, na.rm = TRUE)\n\n[1] 6\n\n## User functions\na_plus_b &lt;- function(a, b = 1) {\n    return(a + b)\n}\na_plus_b(y)\n\n[1]  2  3  4 NA\n\na_plus_b(y, 2)\n\n[1]  3  4  5 NA\n\na_plus_b(b = 2, a = y)\n\n[1]  3  4  5 NA\n\n## Functions provided by packages\n## Installation\n#install.packages(\"ineq\")\nineq::Gini(y)\n\n[1] 0.2222222\n\n## or\nlibrary(ineq)\nGini(y)\n\n[1] 0.2222222\n\n## Help \n?Gini"
  },
  {
    "objectID": "00-introduction_to_r-page.html#r-syntax-indexing-logic",
    "href": "00-introduction_to_r-page.html#r-syntax-indexing-logic",
    "title": "Introduction to R",
    "section": "",
    "text": "y[1]\n\n[1] 1\n\ny[-1]\n\n[1]  2  3 NA\n\ny[2:3]\n\n[1] 2 3\n\ny[c(1, 3, 4)]\n\n[1]  1  3 NA\n\nset.seed(1)\nx &lt;- y / 2 + rnorm(length(y))\ncbind(y, x)\n\n      y          x\n[1,]  1 -0.1264538\n[2,]  2  1.1836433\n[3,]  3  0.6643714\n[4,] NA         NA\n\ny &gt; 2\n\n[1] FALSE FALSE  TRUE    NA\n\ny &gt; 2 & x &gt; 0\n\n[1] FALSE FALSE  TRUE    NA\n\ny &gt; 2 | x &gt; 0\n\n[1] FALSE  TRUE  TRUE    NA\n\ny[y &gt; 2 | x &gt; 0]\n\n[1]  2  3 NA"
  },
  {
    "objectID": "00-introduction_to_r-page.html#r-syntax-loops-ranges",
    "href": "00-introduction_to_r-page.html#r-syntax-loops-ranges",
    "title": "Introduction to R",
    "section": "",
    "text": "## 'elem' is a temporary variable\nfor (elem in y) {\n    print(paste(\"Current y value is:\", elem))\n}\n\n[1] \"Current y value is: 1\"\n[1] \"Current y value is: 2\"\n[1] \"Current y value is: 3\"\n[1] \"Current y value is: NA\"\n\n## 'seq_along' returns a vector which indexes the argument\nfor (i in seq_along(y)) {\n    print(paste(\"Current y value is:\", y[i]))\n}\n\n[1] \"Current y value is: 1\"\n[1] \"Current y value is: 2\"\n[1] \"Current y value is: 3\"\n[1] \"Current y value is: NA\"\n\n## set.seed guarantees the same random numbers every time\nset.seed(1)\ntotal &lt;- 0\nwhile (total &lt; 1) {\n    ## runif generates random numbers between 0 and 1\n    total &lt;- total + runif(1)\n    print(paste(\"Current total value is:\", total))\n}\n\n[1] \"Current total value is: 0.2655086631421\"\n[1] \"Current total value is: 0.63763256277889\"\n[1] \"Current total value is: 1.21048592613079\"\n\n## ranges\n1:3\n\n[1] 1 2 3\n\n10:3\n\n[1] 10  9  8  7  6  5  4  3\n\nseq(3, 11, by = 2)\n\n[1]  3  5  7  9 11"
  },
  {
    "objectID": "00-introduction_to_r-page.html#r-syntax-conditional-logic",
    "href": "00-introduction_to_r-page.html#r-syntax-conditional-logic",
    "title": "Introduction to R",
    "section": "",
    "text": "z &lt;- -2:3\nfor (x in z) {\n  print(paste(\"x =\", x))\n    if (x &gt; 0) {\n        print(\"x is positive\")\n    } else if (x &gt; 2) {\n        print(\"x is greater than 2\")\n    } else if (x &lt; 0) {\n        print(\"x is negative\")\n    } else if (x == 0) {\n        print(\"x is zero\")\n    }\n}\n\n[1] \"x = -2\"\n[1] \"x is negative\"\n[1] \"x = -1\"\n[1] \"x is negative\"\n[1] \"x = 0\"\n[1] \"x is zero\"\n[1] \"x = 1\"\n[1] \"x is positive\"\n[1] \"x = 2\"\n[1] \"x is positive\"\n[1] \"x = 3\"\n[1] \"x is positive\"\n\nz[z &lt;= 0]\n\n[1] -2 -1  0\n\nz[z &gt;= 0]\n\n[1] 0 1 2 3\n\nz[z != 0]\n\n[1] -2 -1  1  2  3\n\nz[! z &lt; 0]\n\n[1] 0 1 2 3"
  },
  {
    "objectID": "00-introduction_to_r-page.html#exercise",
    "href": "00-introduction_to_r-page.html#exercise",
    "title": "Introduction to R",
    "section": "",
    "text": "Write your own function\n\n\n\n\nThe function should take two arguments a and b\nFirst, check if a and b have the same number of elements (see ?length)\n\nIf they have a different number of elements, return NA\n\nIterate over the elements of a and b and check which vector’s element is larger (or if they are equal)\nIf they are equal print the index of the element and “equal”\nIf the element in a is larger print the index of the elemnt and “a larger”\nIf the element in b is larger print the index of the elemnt and “b larger”\n\n\n\n\n\n\na &lt;- c(1, 2, 3)\nb &lt;- c(1, 2, 3, 4)\ncat(\"a is:\", a, \"\\n\")\n\na is: 1 2 3 \n\ncat(\"b is:\", b, \"\\n\")\n\nb is: 1 2 3 4 \n\ncat(\"Result:\\n\")\n\nResult:\n\nNA\n\n[1] NA\n\n\n\n\n\n\na &lt;- c(1, 2, 3)\nb &lt;- c(0, 2, 4)\ncat(\"a is:\", a, \"\\n\")\n\na is: 1 2 3 \n\ncat(\"b is:\", b, \"\\n\")\n\nb is: 0 2 4 \n\ncat(\"Result:\\n\")\n\nResult:\n\nprint(\"1 a larger\")\n\n[1] \"1 a larger\"\n\nprint(\"2 equal\")\n\n[1] \"2 equal\"\n\nprint(\"3 b larger\")\n\n[1] \"3 b larger\""
  },
  {
    "objectID": "00-introduction_to_r-page.html#rectangular-data-frames-creation-and-access",
    "href": "00-introduction_to_r-page.html#rectangular-data-frames-creation-and-access",
    "title": "Introduction to R",
    "section": "",
    "text": "data &lt;- data.frame(x = -1:1, y = 3:1, z = c(\"a\", \"b\", NA))\ndata\n\n   x y    z\n1 -1 3    a\n2  0 2    b\n3  1 1 &lt;NA&gt;\n\nclass(data)\n\n[1] \"data.frame\"\n\n## Variable access\ndata$x\n\n[1] -1  0  1\n\ndata$x + data$y\n\n[1] 2 2 2\n\nrow_summaries &lt;- with(data, \n  data.frame(\n    rsum = x + y,\n    rdiff = x - y\n  ))\nrow_summaries\n\n  rsum rdiff\n1    2    -4\n2    2    -2\n3    2     0"
  },
  {
    "objectID": "00-introduction_to_r-page.html#rectangular-data-frames-overview",
    "href": "00-introduction_to_r-page.html#rectangular-data-frames-overview",
    "title": "Introduction to R",
    "section": "",
    "text": "str(data)\n\n'data.frame':   3 obs. of  3 variables:\n $ x: int  -1 0 1\n $ y: int  3 2 1\n $ z: chr  \"a\" \"b\" NA\n\nsummary(data)\n\n       x              y            z            \n Min.   :-1.0   Min.   :1.0   Length:3          \n 1st Qu.:-0.5   1st Qu.:1.5   Class :character  \n Median : 0.0   Median :2.0   Mode  :character  \n Mean   : 0.0   Mean   :2.0                     \n 3rd Qu.: 0.5   3rd Qu.:2.5                     \n Max.   : 1.0   Max.   :3.0                     \n\nhead(data)\n\n   x y    z\n1 -1 3    a\n2  0 2    b\n3  1 1 &lt;NA&gt;"
  },
  {
    "objectID": "00-introduction_to_r-page.html#rectangular-data-frames-indexing",
    "href": "00-introduction_to_r-page.html#rectangular-data-frames-indexing",
    "title": "Introduction to R",
    "section": "",
    "text": "## 2D structure of data\n## Empty argument means \"all\"#| \ndata[, c(\"x\", \"y\")]\n\n   x y\n1 -1 3\n2  0 2\n3  1 1\n\ndata[1:3, c(\"x\", \"y\")]\n\n   x y\n1 -1 3\n2  0 2\n3  1 1\n\ndata[1, ]\n\n   x y z\n1 -1 3 a\n\ndata[c(1, 3), c(\"x\", \"z\")]\n\n   x    z\n1 -1    a\n3  1 &lt;NA&gt;\n\ndata[data$x &lt; 3,]\n\n   x y    z\n1 -1 3    a\n2  0 2    b\n3  1 1 &lt;NA&gt;"
  },
  {
    "objectID": "00-introduction_to_r-page.html#rectangular-data-adding-and-removing-variables",
    "href": "00-introduction_to_r-page.html#rectangular-data-adding-and-removing-variables",
    "title": "Introduction to R",
    "section": "",
    "text": "## new data has to have the same number of elements\ndata$a &lt;- 2 * data$x\ndata\n\n   x y    z  a\n1 -1 3    a -2\n2  0 2    b  0\n3  1 1 &lt;NA&gt;  2\n\ndata$b &lt;- c(\"one\", \"two\", \"three\")\ndata\n\n   x y    z  a     b\n1 -1 3    a -2   one\n2  0 2    b  0   two\n3  1 1 &lt;NA&gt;  2 three\n\ndata$x &lt;- NULL\ndata\n\n  y    z  a     b\n1 3    a -2   one\n2 2    b  0   two\n3 1 &lt;NA&gt;  2 three\n\ndata$a &lt;- log(data$a)\n\nWarning in log(data$a): NaNs produced\n\ndata\n\n  y    z         a     b\n1 3    a       NaN   one\n2 2    b      -Inf   two\n3 1 &lt;NA&gt; 0.6931472 three\n\ndata$b[data$b == \"two\"] &lt;- \"TWO!\"\ndata$z[is.na(data$z)] &lt;- \"c\"\ndata$a[is.nan(data$a)] &lt;- 0\ndata\n\n  y z         a     b\n1 3 a 0.0000000   one\n2 2 b      -Inf  TWO!\n3 1 c 0.6931472 three"
  },
  {
    "objectID": "00-introduction_to_r-page.html#exercise-1",
    "href": "00-introduction_to_r-page.html#exercise-1",
    "title": "Introduction to R",
    "section": "",
    "text": "Generate your own data\n\n\n\n\nLook at the helpfiles of rnorm, runif, and ifelse\nCreate a data.frame with 10 rows and variables x, generated using runif and y, generated using rnorm\nAdd variable z which takes the value 1 if x is larger than y and 0 otherwise\nCreate a second data.frame that holds the rows of the original one for which z == 1 is TRUE.\nRemove column z from the second data.frame\nWhat happens if you try to create a data.frame when x and y have a differnent number of elements?\nWhat happens if you run the code you wrote for this exercise again (and again)?\nHow can you ensure that each run yields the same results?"
  },
  {
    "objectID": "00-introduction_to_r-page.html#reading-data",
    "href": "00-introduction_to_r-page.html#reading-data",
    "title": "Introduction to R",
    "section": "",
    "text": "Please download & unzip the folder found in “data” in Canvas\nWe will first use the “penguins” folder which includes the penguins_raw data set in multiple file formats\n\n\n## CSV\npenguins_raw &lt;- readr::read_csv(\"data/penguins/penguins_raw.csv\")\n\nNew names:\n• `` -&gt; `...1`\n\n\nWarning: One or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\n\n\nRows: 345 Columns: 18\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (10): ...1, studyName, Species, Region, Island, Stage, Individual ID, C...\ndbl   (7): Sample Number, Culmen Length (mm), Culmen Depth (mm), Flipper Len...\ndate  (1): Date Egg\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nhead(penguins_raw, 2)\n\n# A tibble: 2 × 18\n  ...1     studyName `Sample Number` Species Region Island Stage `Individual ID`\n  &lt;chr&gt;    &lt;chr&gt;               &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;  &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt;          \n1 # this … &lt;NA&gt;                   NA &lt;NA&gt;    &lt;NA&gt;   &lt;NA&gt;   &lt;NA&gt;  &lt;NA&gt;           \n2 1        PAL0708                 1 Adelie… Anvers Torge… Adul… N1A1           \n# ℹ 10 more variables: `Clutch Completion` &lt;chr&gt;, `Date Egg` &lt;date&gt;,\n#   `Culmen Length (mm)` &lt;dbl&gt;, `Culmen Depth (mm)` &lt;dbl&gt;,\n#   `Flipper Length (mm)` &lt;dbl&gt;, `Body Mass (g)` &lt;dbl&gt;, Sex &lt;chr&gt;,\n#   `Delta 15 N (o/oo)` &lt;dbl&gt;, `Delta 13 C (o/oo)` &lt;dbl&gt;, Comments &lt;chr&gt;\n\n\n. . .\n\npenguins_raw[1,1]\n\n# A tibble: 1 × 1\n  ...1                                              \n  &lt;chr&gt;                                             \n1 # this is a comment making the data harder to read\n\n\n\n\n\n\n\n\nFix the data\n\n\n\n\nThe second row (after the column names) in the penguins_raw.csv file is a comment\nLook at the help file for the readr::read_csv function (?readr::read_csv)\nHow can we ignore the comment row?"
  },
  {
    "objectID": "00-introduction_to_r-page.html#reading-data-solution",
    "href": "00-introduction_to_r-page.html#reading-data-solution",
    "title": "Introduction to R",
    "section": "",
    "text": "## CSV\npenguins_raw &lt;- readr::read_csv(\n  \"data/penguins/penguins_raw.csv\",\n  comment = \"#\")\n\nNew names:\nRows: 344 Columns: 18\n── Column specification\n──────────────────────────────────────────────────────── Delimiter: \",\" chr\n(9): studyName, Species, Region, Island, Stage, Individual ID, Clutch C... dbl\n(8): ...1, Sample Number, Culmen Length (mm), Culmen Depth (mm), Flippe... date\n(1): Date Egg\nℹ Use `spec()` to retrieve the full column specification for this data. ℹ\nSpecify the column types or set `show_col_types = FALSE` to quiet this message.\n• `` -&gt; `...1`\n\nhead(penguins_raw, 2)\n\n# A tibble: 2 × 18\n   ...1 studyName `Sample Number` Species    Region Island Stage `Individual ID`\n  &lt;dbl&gt; &lt;chr&gt;               &lt;dbl&gt; &lt;chr&gt;      &lt;chr&gt;  &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt;          \n1     1 PAL0708                 1 Adelie Pe… Anvers Torge… Adul… N1A1           \n2     2 PAL0708                 2 Adelie Pe… Anvers Torge… Adul… N1A2           \n# ℹ 10 more variables: `Clutch Completion` &lt;chr&gt;, `Date Egg` &lt;date&gt;,\n#   `Culmen Length (mm)` &lt;dbl&gt;, `Culmen Depth (mm)` &lt;dbl&gt;,\n#   `Flipper Length (mm)` &lt;dbl&gt;, `Body Mass (g)` &lt;dbl&gt;, Sex &lt;chr&gt;,\n#   `Delta 15 N (o/oo)` &lt;dbl&gt;, `Delta 13 C (o/oo)` &lt;dbl&gt;, Comments &lt;chr&gt;\n\npenguins_raw[1,1]\n\n# A tibble: 1 × 1\n   ...1\n  &lt;dbl&gt;\n1     1\n\nstr(penguins_raw)\n\nspc_tbl_ [344 × 18] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n $ ...1               : num [1:344] 1 2 3 4 5 6 7 8 9 10 ...\n $ studyName          : chr [1:344] \"PAL0708\" \"PAL0708\" \"PAL0708\" \"PAL0708\" ...\n $ Sample Number      : num [1:344] 1 2 3 4 5 6 7 8 9 10 ...\n $ Species            : chr [1:344] \"Adelie Penguin (Pygoscelis adeliae)\" \"Adelie Penguin (Pygoscelis adeliae)\" \"Adelie Penguin (Pygoscelis adeliae)\" \"Adelie Penguin (Pygoscelis adeliae)\" ...\n $ Region             : chr [1:344] \"Anvers\" \"Anvers\" \"Anvers\" \"Anvers\" ...\n $ Island             : chr [1:344] \"Torgersen\" \"Torgersen\" \"Torgersen\" \"Torgersen\" ...\n $ Stage              : chr [1:344] \"Adult, 1 Egg Stage\" \"Adult, 1 Egg Stage\" \"Adult, 1 Egg Stage\" \"Adult, 1 Egg Stage\" ...\n $ Individual ID      : chr [1:344] \"N1A1\" \"N1A2\" \"N2A1\" \"N2A2\" ...\n $ Clutch Completion  : chr [1:344] \"Yes\" \"Yes\" \"Yes\" \"Yes\" ...\n $ Date Egg           : Date[1:344], format: \"2007-11-11\" \"2007-11-11\" ...\n $ Culmen Length (mm) : num [1:344] 39.1 39.5 40.3 NA 36.7 39.3 38.9 39.2 34.1 42 ...\n $ Culmen Depth (mm)  : num [1:344] 18.7 17.4 18 NA 19.3 20.6 17.8 19.6 18.1 20.2 ...\n $ Flipper Length (mm): num [1:344] 181 186 195 NA 193 190 181 195 193 190 ...\n $ Body Mass (g)      : num [1:344] 3750 3800 3250 NA 3450 ...\n $ Sex                : chr [1:344] \"MALE\" \"FEMALE\" \"FEMALE\" NA ...\n $ Delta 15 N (o/oo)  : num [1:344] NA 8.95 8.37 NA 8.77 ...\n $ Delta 13 C (o/oo)  : num [1:344] NA -24.7 -25.3 NA -25.3 ...\n $ Comments           : chr [1:344] \"Not enough blood for isotopes.\" NA NA \"Adult not sampled.\" ...\n - attr(*, \"spec\")=\n  .. cols(\n  ..   ...1 = col_double(),\n  ..   studyName = col_character(),\n  ..   `Sample Number` = col_double(),\n  ..   Species = col_character(),\n  ..   Region = col_character(),\n  ..   Island = col_character(),\n  ..   Stage = col_character(),\n  ..   `Individual ID` = col_character(),\n  ..   `Clutch Completion` = col_character(),\n  ..   `Date Egg` = col_date(format = \"\"),\n  ..   `Culmen Length (mm)` = col_double(),\n  ..   `Culmen Depth (mm)` = col_double(),\n  ..   `Flipper Length (mm)` = col_double(),\n  ..   `Body Mass (g)` = col_double(),\n  ..   Sex = col_character(),\n  ..   `Delta 15 N (o/oo)` = col_double(),\n  ..   `Delta 13 C (o/oo)` = col_double(),\n  ..   Comments = col_character()\n  .. )\n - attr(*, \"problems\")=&lt;externalptr&gt;"
  },
  {
    "objectID": "00-introduction_to_r-page.html#reading-data-other-file-formats",
    "href": "00-introduction_to_r-page.html#reading-data-other-file-formats",
    "title": "Introduction to R",
    "section": "",
    "text": "The readxl package provides functions for reading Excel files\n\n\npenguins_raw &lt;- readxl::read_excel(\"data/penguins/penguins_raw.xlsx\")\n\nNew names:\n• `` -&gt; `...1`\n\nhead(penguins_raw, 2)\n\n# A tibble: 2 × 18\n  ...1  studyName `Sample Number` Species    Region Island Stage `Individual ID`\n  &lt;chr&gt; &lt;chr&gt;               &lt;dbl&gt; &lt;chr&gt;      &lt;chr&gt;  &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt;          \n1 1     PAL0708                 1 Adelie Pe… Anvers Torge… Adul… N1A1           \n2 2     PAL0708                 2 Adelie Pe… Anvers Torge… Adul… N1A2           \n# ℹ 10 more variables: `Clutch Completion` &lt;chr&gt;, `Date Egg` &lt;dttm&gt;,\n#   `Culmen Length (mm)` &lt;dbl&gt;, `Culmen Depth (mm)` &lt;dbl&gt;,\n#   `Flipper Length (mm)` &lt;dbl&gt;, `Body Mass (g)` &lt;dbl&gt;, Sex &lt;chr&gt;,\n#   `Delta 15 N (o/oo)` &lt;dbl&gt;, `Delta 13 C (o/oo)` &lt;dbl&gt;, Comments &lt;chr&gt;\n\n## Read a subset \npenguins_subset &lt;- readxl::read_excel(\"data/penguins/penguins_raw.xlsx\", sheet = \"Sheet1\", range = \"B1:O345\")\nhead(penguins_subset, 2)\n\n# A tibble: 2 × 14\n  studyName `Sample Number` Species          Region Island Stage `Individual ID`\n  &lt;chr&gt;               &lt;dbl&gt; &lt;chr&gt;            &lt;chr&gt;  &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt;          \n1 PAL0708                 1 Adelie Penguin … Anvers Torge… Adul… N1A1           \n2 PAL0708                 2 Adelie Penguin … Anvers Torge… Adul… N1A2           \n# ℹ 7 more variables: `Clutch Completion` &lt;chr&gt;, `Date Egg` &lt;dttm&gt;,\n#   `Culmen Length (mm)` &lt;dbl&gt;, `Culmen Depth (mm)` &lt;dbl&gt;,\n#   `Flipper Length (mm)` &lt;dbl&gt;, `Body Mass (g)` &lt;dbl&gt;, Sex &lt;chr&gt;"
  },
  {
    "objectID": "00-introduction_to_r-page.html#reading-data-other-file-formats-1",
    "href": "00-introduction_to_r-page.html#reading-data-other-file-formats-1",
    "title": "Introduction to R",
    "section": "",
    "text": "The haven package provides functions for reading SPSS, Stata, and SAS files\nIt looks like SPSS does not support spaces in column names so this is slightly different\n\n\npenguins_raw &lt;- haven::read_sav(\"data/penguins/penguins_raw.sav\")\nhead(penguins_raw, 2)\n\n# A tibble: 2 × 17\n  study_name sample_number species             region island stage individual_id\n  &lt;chr&gt;              &lt;dbl&gt; &lt;chr&gt;               &lt;chr&gt;  &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt;        \n1 PAL0708                1 Adelie Penguin (Py… Anvers Torge… Adul… N1A1         \n2 PAL0708                2 Adelie Penguin (Py… Anvers Torge… Adul… N1A2         \n# ℹ 10 more variables: clutch_completion &lt;chr&gt;, date_egg &lt;date&gt;,\n#   culmen_length_mm &lt;dbl&gt;, culmen_depth_mm &lt;dbl&gt;, flipper_length_mm &lt;dbl&gt;,\n#   body_mass_g &lt;dbl&gt;, sex &lt;chr&gt;, delta_15_n_o_oo &lt;dbl&gt;, delta_13_c_o_oo &lt;dbl&gt;,\n#   comments &lt;chr&gt;"
  },
  {
    "objectID": "00-introduction_to_r-page.html#reading-big-data-the-arrow-package",
    "href": "00-introduction_to_r-page.html#reading-big-data-the-arrow-package",
    "title": "Introduction to R",
    "section": "",
    "text": "The arrow package provides functions for reading Parquet and Feather files\nOptimized formats used in many data science projects\nProvides facility to read from “object storage” (e.g., Amazon S3)\n\n\nThe major benefits of object storage are the virtually unlimited scalability and the lower cost of storing large volumes of data for use cases such as data lakes, cloud native applications, analytics, log files, and machine learning (ML). 1\n\n\nRule of thumb:\n\nuse parquet for large files and long term storage\n\noptimized file size\n\nuse feather for optimized reading and short term storage\n\nmemory layout the same as in the process"
  },
  {
    "objectID": "00-introduction_to_r-page.html#reading-big-data-the-arrow-package-1",
    "href": "00-introduction_to_r-page.html#reading-big-data-the-arrow-package-1",
    "title": "Introduction to R",
    "section": "",
    "text": "penguins_raw &lt;- arrow::read_parquet(\"data/penguins/penguins_raw.parquet\")\npenguins_raw &lt;- arrow::read_feather(\"data/penguins/penguins_raw.feather\")\nhead(penguins_raw, 2)\n\n# A tibble: 2 × 17\n  studyName `Sample Number` Species          Region Island Stage `Individual ID`\n  &lt;chr&gt;               &lt;dbl&gt; &lt;chr&gt;            &lt;chr&gt;  &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt;          \n1 PAL0708                 1 Adelie Penguin … Anvers Torge… Adul… N1A1           \n2 PAL0708                 2 Adelie Penguin … Anvers Torge… Adul… N1A2           \n# ℹ 10 more variables: `Clutch Completion` &lt;chr&gt;, `Date Egg` &lt;date&gt;,\n#   `Culmen Length (mm)` &lt;dbl&gt;, `Culmen Depth (mm)` &lt;dbl&gt;,\n#   `Flipper Length (mm)` &lt;dbl&gt;, `Body Mass (g)` &lt;dbl&gt;, Sex &lt;chr&gt;,\n#   `Delta 15 N (o/oo)` &lt;dbl&gt;, `Delta 13 C (o/oo)` &lt;dbl&gt;, Comments &lt;chr&gt;\n\n\n\nSupport for complex data structures\n\n\npenguin_species_island &lt;- arrow::read_parquet('data/penguins/penguin_species_nested.parquet')\nhead(penguin_species_island, 2)\n\n# A tibble: 2 × 2\n  Island                                 data\n  &lt;chr&gt;     &lt;list&lt;tbl_df&lt;Species:character&gt;&gt;&gt;\n1 Torgersen                          [52 × 1]\n2 Biscoe                            [168 × 1]\n\nhead(tidyr::unnest(penguin_species_island), 2)\n\nWarning: `cols` is now required when using `unnest()`.\nℹ Please use `cols = c(data)`.\n\n\n# A tibble: 2 × 2\n  Island    Species                            \n  &lt;chr&gt;     &lt;chr&gt;                              \n1 Torgersen Adelie Penguin (Pygoscelis adeliae)\n2 Torgersen Adelie Penguin (Pygoscelis adeliae)"
  },
  {
    "objectID": "00-introduction_to_r-page.html#benchmarks",
    "href": "00-introduction_to_r-page.html#benchmarks",
    "title": "Introduction to R",
    "section": "",
    "text": "library(microbenchmark)\nmicrobenchmark(\n  csv = readr::read_csv(\"data/penguins/penguins_raw.csv\", \n   show_col_types = FALSE, name_repair = 'minimal'),\n  parquet = arrow::read_parquet(\"data/penguins/penguins_raw.parquet\"),\n  feather = arrow::read_feather(\"data/penguins/penguins_raw.feather\")\n) \n\nWarning in microbenchmark(csv =\nreadr::read_csv(\"data/penguins/penguins_raw.csv\", : less accurate nanosecond\ntimes to avoid potential integer overflows\n\n\nWarning: One or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\nOne or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\nOne or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\nOne or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\nOne or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\nOne or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\nOne or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\nOne or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\nOne or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\nOne or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\nOne or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\nOne or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\nOne or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\nOne or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\nOne or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\nOne or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\nOne or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\nOne or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\nOne or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\nOne or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\nOne or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\nOne or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\nOne or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\nOne or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\nOne or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\nOne or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\nOne or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\nOne or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\nOne or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\nOne or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\nOne or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\nOne or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\nOne or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\nOne or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\nOne or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\nOne or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\nOne or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\nOne or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\nOne or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\nOne or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\nOne or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\nOne or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\nOne or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\nOne or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\nOne or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\nOne or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\nOne or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\nOne or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\nOne or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\nOne or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\nOne or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\nOne or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\nOne or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\nOne or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\nOne or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\nOne or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\nOne or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\nOne or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\nOne or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\nOne or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\nOne or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\nOne or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\nOne or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\nOne or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\nOne or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\nOne or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\nOne or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\nOne or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\nOne or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\nOne or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\nOne or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\nOne or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\nOne or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\nOne or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\nOne or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\nOne or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\nOne or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\nOne or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\nOne or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\nOne or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\nOne or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\nOne or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\nOne or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\nOne or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\nOne or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\nOne or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\nOne or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\nOne or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\nOne or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\nOne or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\nOne or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\nOne or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\nOne or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\nOne or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\nOne or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\nOne or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\nOne or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\nOne or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\nOne or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\nOne or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\n\n\nUnit: milliseconds\n    expr      min       lq     mean   median       uq       max neval cld\n     csv 7.450479 8.018514 8.811865 8.410371 9.001222 15.026582   100 a  \n parquet 1.748691 1.976405 2.097041 2.054654 2.156395  4.799583   100  b \n feather 1.263825 1.468579 1.641316 1.561362 1.669643  4.158835   100   c"
  },
  {
    "objectID": "00-introduction_to_r-page.html#data-types",
    "href": "00-introduction_to_r-page.html#data-types",
    "title": "Introduction to R",
    "section": "",
    "text": "The most important types of data are:\n\n\n\n\n\n\n\nData type\nDescription\n\n\n\n\nNumeric\nApproximations of the real numbers, \\(\\normalsize\\mathbb{R}\\) (e.g., mileage a car gets: 23.6, 20.9, etc.)\n\n\nInteger\nWhole numbers, \\(\\normalsize\\mathbb{Z}\\) (e.g., number of sales: 7, 0, 120, 63, etc.)\n\n\nCharacter\nText data (strings, e.g., product names)\n\n\nFactor\nCategorical data for classification (e.g., product groups)\n\n\nLogical\nTRUE, FALSE\n\n\nDate\nDate variables (e.g., sales dates: 21-06-2015, 06-21-15, 21-Jun-2015, etc.)\n\n\n\nVariables can be converted from one type to another using the appropriate functions (e.g., as.numeric(), as.integer(), as.character(), as.factor(), as.logical(), as.Date())."
  },
  {
    "objectID": "00-introduction_to_r-page.html#lets-clean-up-the-penguins",
    "href": "00-introduction_to_r-page.html#lets-clean-up-the-penguins",
    "title": "Introduction to R",
    "section": "",
    "text": "str(penguins_raw)\n\ntibble [344 × 17] (S3: tbl_df/tbl/data.frame)\n $ studyName          : chr [1:344] \"PAL0708\" \"PAL0708\" \"PAL0708\" \"PAL0708\" ...\n $ Sample Number      : num [1:344] 1 2 3 4 5 6 7 8 9 10 ...\n $ Species            : chr [1:344] \"Adelie Penguin (Pygoscelis adeliae)\" \"Adelie Penguin (Pygoscelis adeliae)\" \"Adelie Penguin (Pygoscelis adeliae)\" \"Adelie Penguin (Pygoscelis adeliae)\" ...\n $ Region             : chr [1:344] \"Anvers\" \"Anvers\" \"Anvers\" \"Anvers\" ...\n $ Island             : chr [1:344] \"Torgersen\" \"Torgersen\" \"Torgersen\" \"Torgersen\" ...\n $ Stage              : chr [1:344] \"Adult, 1 Egg Stage\" \"Adult, 1 Egg Stage\" \"Adult, 1 Egg Stage\" \"Adult, 1 Egg Stage\" ...\n $ Individual ID      : chr [1:344] \"N1A1\" \"N1A2\" \"N2A1\" \"N2A2\" ...\n $ Clutch Completion  : chr [1:344] \"Yes\" \"Yes\" \"Yes\" \"Yes\" ...\n $ Date Egg           : Date[1:344], format: \"2007-11-11\" \"2007-11-11\" ...\n $ Culmen Length (mm) : num [1:344] 39.1 39.5 40.3 NA 36.7 39.3 38.9 39.2 34.1 42 ...\n $ Culmen Depth (mm)  : num [1:344] 18.7 17.4 18 NA 19.3 20.6 17.8 19.6 18.1 20.2 ...\n $ Flipper Length (mm): num [1:344] 181 186 195 NA 193 190 181 195 193 190 ...\n $ Body Mass (g)      : num [1:344] 3750 3800 3250 NA 3450 ...\n $ Sex                : chr [1:344] \"MALE\" \"FEMALE\" \"FEMALE\" NA ...\n $ Delta 15 N (o/oo)  : num [1:344] NA 8.95 8.37 NA 8.77 ...\n $ Delta 13 C (o/oo)  : num [1:344] NA -24.7 -25.3 NA -25.3 ...\n $ Comments           : chr [1:344] \"Not enough blood for isotopes.\" NA NA \"Adult not sampled.\" ...\n - attr(*, \"spec\")=\n  .. cols(\n  ..   studyName = col_character(),\n  ..   `Sample Number` = col_double(),\n  ..   Species = col_character(),\n  ..   Region = col_character(),\n  ..   Island = col_character(),\n  ..   Stage = col_character(),\n  ..   `Individual ID` = col_character(),\n  ..   `Clutch Completion` = col_character(),\n  ..   `Date Egg` = col_date(format = \"\"),\n  ..   `Culmen Length (mm)` = col_double(),\n  ..   `Culmen Depth (mm)` = col_double(),\n  ..   `Flipper Length (mm)` = col_double(),\n  ..   `Body Mass (g)` = col_double(),\n  ..   Sex = col_character(),\n  ..   `Delta 15 N (o/oo)` = col_double(),\n  ..   `Delta 13 C (o/oo)` = col_double(),\n  ..   Comments = col_character()\n  .. )\n\n\n\nClean the column names\n\n\npenguins &lt;- janitor::clean_names(penguins_raw)\nstr(penguins)\n\ntibble [344 × 17] (S3: tbl_df/tbl/data.frame)\n $ study_name       : chr [1:344] \"PAL0708\" \"PAL0708\" \"PAL0708\" \"PAL0708\" ...\n $ sample_number    : num [1:344] 1 2 3 4 5 6 7 8 9 10 ...\n $ species          : chr [1:344] \"Adelie Penguin (Pygoscelis adeliae)\" \"Adelie Penguin (Pygoscelis adeliae)\" \"Adelie Penguin (Pygoscelis adeliae)\" \"Adelie Penguin (Pygoscelis adeliae)\" ...\n $ region           : chr [1:344] \"Anvers\" \"Anvers\" \"Anvers\" \"Anvers\" ...\n $ island           : chr [1:344] \"Torgersen\" \"Torgersen\" \"Torgersen\" \"Torgersen\" ...\n $ stage            : chr [1:344] \"Adult, 1 Egg Stage\" \"Adult, 1 Egg Stage\" \"Adult, 1 Egg Stage\" \"Adult, 1 Egg Stage\" ...\n $ individual_id    : chr [1:344] \"N1A1\" \"N1A2\" \"N2A1\" \"N2A2\" ...\n $ clutch_completion: chr [1:344] \"Yes\" \"Yes\" \"Yes\" \"Yes\" ...\n $ date_egg         : Date[1:344], format: \"2007-11-11\" \"2007-11-11\" ...\n $ culmen_length_mm : num [1:344] 39.1 39.5 40.3 NA 36.7 39.3 38.9 39.2 34.1 42 ...\n $ culmen_depth_mm  : num [1:344] 18.7 17.4 18 NA 19.3 20.6 17.8 19.6 18.1 20.2 ...\n $ flipper_length_mm: num [1:344] 181 186 195 NA 193 190 181 195 193 190 ...\n $ body_mass_g      : num [1:344] 3750 3800 3250 NA 3450 ...\n $ sex              : chr [1:344] \"MALE\" \"FEMALE\" \"FEMALE\" NA ...\n $ delta_15_n_o_oo  : num [1:344] NA 8.95 8.37 NA 8.77 ...\n $ delta_13_c_o_oo  : num [1:344] NA -24.7 -25.3 NA -25.3 ...\n $ comments         : chr [1:344] \"Not enough blood for isotopes.\" NA NA \"Adult not sampled.\" ...\n - attr(*, \"spec\")=\n  .. cols(\n  ..   studyName = col_character(),\n  ..   `Sample Number` = col_double(),\n  ..   Species = col_character(),\n  ..   Region = col_character(),\n  ..   Island = col_character(),\n  ..   Stage = col_character(),\n  ..   `Individual ID` = col_character(),\n  ..   `Clutch Completion` = col_character(),\n  ..   `Date Egg` = col_date(format = \"\"),\n  ..   `Culmen Length (mm)` = col_double(),\n  ..   `Culmen Depth (mm)` = col_double(),\n  ..   `Flipper Length (mm)` = col_double(),\n  ..   `Body Mass (g)` = col_double(),\n  ..   Sex = col_character(),\n  ..   `Delta 15 N (o/oo)` = col_double(),\n  ..   `Delta 13 C (o/oo)` = col_double(),\n  ..   Comments = col_character()\n  .. )"
  },
  {
    "objectID": "00-introduction_to_r-page.html#data-preprocessing-syntax",
    "href": "00-introduction_to_r-page.html#data-preprocessing-syntax",
    "title": "Introduction to R",
    "section": "",
    "text": "|&gt; is the “pipe” operator\n\nIt takes the result of the left side and passes it to the right side as the first argument\nVery useful when “chaining” multiple operations\n\n\n\npenguins |&gt;\n  head(2)\n\n# A tibble: 2 × 17\n  study_name sample_number species             region island stage individual_id\n  &lt;chr&gt;              &lt;dbl&gt; &lt;chr&gt;               &lt;chr&gt;  &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt;        \n1 PAL0708                1 Adelie Penguin (Py… Anvers Torge… Adul… N1A1         \n2 PAL0708                2 Adelie Penguin (Py… Anvers Torge… Adul… N1A2         \n# ℹ 10 more variables: clutch_completion &lt;chr&gt;, date_egg &lt;date&gt;,\n#   culmen_length_mm &lt;dbl&gt;, culmen_depth_mm &lt;dbl&gt;, flipper_length_mm &lt;dbl&gt;,\n#   body_mass_g &lt;dbl&gt;, sex &lt;chr&gt;, delta_15_n_o_oo &lt;dbl&gt;, delta_13_c_o_oo &lt;dbl&gt;,\n#   comments &lt;chr&gt;\n\nhead(penguins, 2)\n\n# A tibble: 2 × 17\n  study_name sample_number species             region island stage individual_id\n  &lt;chr&gt;              &lt;dbl&gt; &lt;chr&gt;               &lt;chr&gt;  &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt;        \n1 PAL0708                1 Adelie Penguin (Py… Anvers Torge… Adul… N1A1         \n2 PAL0708                2 Adelie Penguin (Py… Anvers Torge… Adul… N1A2         \n# ℹ 10 more variables: clutch_completion &lt;chr&gt;, date_egg &lt;date&gt;,\n#   culmen_length_mm &lt;dbl&gt;, culmen_depth_mm &lt;dbl&gt;, flipper_length_mm &lt;dbl&gt;,\n#   body_mass_g &lt;dbl&gt;, sex &lt;chr&gt;, delta_15_n_o_oo &lt;dbl&gt;, delta_13_c_o_oo &lt;dbl&gt;,\n#   comments &lt;chr&gt;"
  },
  {
    "objectID": "00-introduction_to_r-page.html#data-preprocessing-mutation",
    "href": "00-introduction_to_r-page.html#data-preprocessing-mutation",
    "title": "Introduction to R",
    "section": "",
    "text": "Pkg: dplyr provides function for data.frame manipulation\nPkg: stringr provides functions to manipulate strings (characters)\nfn: mutate takes each row and applies a function to create a new (or overwrite a) column\nfn: select selects columns\n\n\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(stringr)\npenguins_subset &lt;- penguins |&gt;\n  mutate(\n    species = str_split(species, \" \", n = 2, simplify = TRUE)[,1],\n    is_adult = str_detect(str_to_lower(stage), \"adult\"),\n    is_female = str_detect(str_to_lower(sex), \"female\"),\n    sex = str_to_lower(sex)) |&gt;\n  select(species, island, sex, is_adult,  culmen_length_mm, culmen_depth_mm, is_female)\npenguins_subset |&gt; head(2)\n\n# A tibble: 2 × 7\n  species island    sex    is_adult culmen_length_mm culmen_depth_mm is_female\n  &lt;chr&gt;   &lt;chr&gt;     &lt;chr&gt;  &lt;lgl&gt;               &lt;dbl&gt;           &lt;dbl&gt; &lt;lgl&gt;    \n1 Adelie  Torgersen male   TRUE                 39.1            18.7 FALSE    \n2 Adelie  Torgersen female TRUE                 39.5            17.4 TRUE"
  },
  {
    "objectID": "00-introduction_to_r-page.html#data-preprocessing-multiple-columns",
    "href": "00-introduction_to_r-page.html#data-preprocessing-multiple-columns",
    "title": "Introduction to R",
    "section": "",
    "text": "#penguins_subset &lt;- \npenguins_subset &lt;- penguins_subset |&gt;\n  mutate(\n    across(starts_with('culmen'), \\(x) x / 10),\n    across(species:sex, as.factor),\n    across(c('is_adult', 'is_female'), as.numeric)\n    ) |&gt;\n  mutate_if(is.numeric,\n    list(scaled = \\(x) (x - mean(x, na.rm=TRUE)) / sd(x, na.rm=TRUE))\n  ) |&gt;\n  rename_with(\n    \\(name) str_replace(name, \"mm\", \"cm\"),\n    starts_with('culmen'))\npenguins_subset |&gt; select(-starts_with('is')) |&gt; str()\n\ntibble [344 × 6] (S3: tbl_df/tbl/data.frame)\n $ species                : Factor w/ 3 levels \"Adelie\",\"Chinstrap\",..: 1 1 1 1 1 1 1 1 1 1 ...\n $ sex                    : Factor w/ 2 levels \"female\",\"male\": 2 1 1 NA 1 2 1 2 NA NA ...\n $ culmen_length_cm       : num [1:344] 3.91 3.95 4.03 NA 3.67 3.93 3.89 3.92 3.41 4.2 ...\n $ culmen_depth_cm        : num [1:344] 1.87 1.74 1.8 NA 1.93 2.06 1.78 1.96 1.81 2.02 ...\n $ culmen_length_cm_scaled: num [1:344] -0.883 -0.81 -0.663 NA -1.323 ...\n $ culmen_depth_cm_scaled : num [1:344] 0.784 0.126 0.43 NA 1.088 ...\n - attr(*, \"spec\")=\n  .. cols(\n  ..   studyName = col_character(),\n  ..   `Sample Number` = col_double(),\n  ..   Species = col_character(),\n  ..   Region = col_character(),\n  ..   Island = col_character(),\n  ..   Stage = col_character(),\n  ..   `Individual ID` = col_character(),\n  ..   `Clutch Completion` = col_character(),\n  ..   `Date Egg` = col_date(format = \"\"),\n  ..   `Culmen Length (mm)` = col_double(),\n  ..   `Culmen Depth (mm)` = col_double(),\n  ..   `Flipper Length (mm)` = col_double(),\n  ..   `Body Mass (g)` = col_double(),\n  ..   Sex = col_character(),\n  ..   `Delta 15 N (o/oo)` = col_double(),\n  ..   `Delta 13 C (o/oo)` = col_double(),\n  ..   Comments = col_character()\n  .. )"
  },
  {
    "objectID": "00-introduction_to_r-page.html#hint-figuring-out-what-is-going-on",
    "href": "00-introduction_to_r-page.html#hint-figuring-out-what-is-going-on",
    "title": "Introduction to R",
    "section": "",
    "text": "Split the problem into smaller pieces\n\n\n\\(name) str_replace(name, \"mm\", \"cm\")\n\n\\(name) str_replace(name, \"mm\", \"cm\")\n\nstr_replace(\"ammm\", \"mm\", \"cm\")\n\n[1] \"acmm\"\n\n\n\nCheck help files\n\n\n?str_replace\n\n\nCheck typeof() and class()\n\n\ntypeof(\\(name) str_replace(name, \"mm\", \"cm\"))\n\n[1] \"closure\"\n\n\n\\(\\rightarrow\\) closures are functions\n\nSee if you can produce some outcome on the reduced problem\n\n\nmy_function &lt;- \\(name) str_replace(name, \"mm\", \"cm\")\nmy_function('here are some mms')\n\n[1] \"here are some cms\""
  },
  {
    "objectID": "00-introduction_to_r-page.html#hint-read-the-source-code",
    "href": "00-introduction_to_r-page.html#hint-read-the-source-code",
    "title": "Introduction to R",
    "section": "",
    "text": "This is only useful if a function is pure R code\n\n\nstr_replace\n\nfunction (string, pattern, replacement) \n{\n    if (!missing(replacement) && is_replacement_fun(replacement)) {\n        replacement &lt;- as_function(replacement)\n        return(str_transform(string, pattern, replacement))\n    }\n    check_lengths(string, pattern, replacement)\n    switch(type(pattern), empty = no_empty(), bound = no_boundary(), \n        fixed = stri_replace_first_fixed(string, pattern, replacement, \n            opts_fixed = opts(pattern)), coll = stri_replace_first_coll(string, \n            pattern, replacement, opts_collator = opts(pattern)), \n        regex = stri_replace_first_regex(string, pattern, fix_replacement(replacement), \n            opts_regex = opts(pattern)))\n}\n&lt;bytecode: 0x11ada4390&gt;\n&lt;environment: namespace:stringr&gt;"
  },
  {
    "objectID": "00-introduction_to_r-page.html#aside-functions-and-variable-names",
    "href": "00-introduction_to_r-page.html#aside-functions-and-variable-names",
    "title": "Introduction to R",
    "section": "",
    "text": "Common mistake that leads to cryptic error:\n\n\nmeans &lt;- c(4,5,6)\nmean[1]\n\nError in mean[1]: object of type 'closure' is not subsettable"
  },
  {
    "objectID": "00-introduction_to_r-page.html#reducing-rows-filtering",
    "href": "00-introduction_to_r-page.html#reducing-rows-filtering",
    "title": "Introduction to R",
    "section": "",
    "text": "Create different subsets of data\n“Filter in” (not out) \\(\\rightarrow\\) TRUE rows remain\n\n\nadelies &lt;- penguins_subset |&gt;\n  filter(species == \"Adelie\")\nunique(adelies$species)\n\n[1] Adelie\nLevels: Adelie Chinstrap Gentoo\n\nfemale_adelies &lt;- penguins_subset |&gt;\n  filter(species == \"Adelie\", is_female == 1)\nfemale_adelies |&gt; select(species, sex) |&gt; summary()\n\n      species       sex    \n Adelie   :73   female:73  \n Chinstrap: 0   male  : 0  \n Gentoo   : 0"
  },
  {
    "objectID": "00-introduction_to_r-page.html#reducing-rows-summarizing",
    "href": "00-introduction_to_r-page.html#reducing-rows-summarizing",
    "title": "Introduction to R",
    "section": "",
    "text": "Calculate any appropriate summary for a variable\n\n\nlibrary(tidyr)\npenguins |&gt;\n  drop_na(body_mass_g) |&gt;\n  summarize(avg_weight = mean(body_mass_g))\n\n# A tibble: 1 × 1\n  avg_weight\n       &lt;dbl&gt;\n1      4202.\n\n\n\nCalculate the summary for each group\n\n\npenguins_summary &lt;- penguins_subset |&gt;\n  drop_na(culmen_length_cm) |&gt;\n  group_by(species, sex) |&gt;\n  summarize(avg_clength = mean(culmen_length_cm))\n\n`summarise()` has grouped output by 'species'. You can override using the\n`.groups` argument.\n\npenguins_summary\n\n# A tibble: 8 × 3\n# Groups:   species [3]\n  species   sex    avg_clength\n  &lt;fct&gt;     &lt;fct&gt;        &lt;dbl&gt;\n1 Adelie    female        3.73\n2 Adelie    male          4.04\n3 Adelie    &lt;NA&gt;          3.78\n4 Chinstrap female        4.66\n5 Chinstrap male          5.11\n6 Gentoo    female        4.56\n7 Gentoo    male          4.95\n8 Gentoo    &lt;NA&gt;          4.56"
  },
  {
    "objectID": "00-introduction_to_r-page.html#pivot-tables",
    "href": "00-introduction_to_r-page.html#pivot-tables",
    "title": "Introduction to R",
    "section": "",
    "text": "penguins_summary |&gt;\n  pivot_wider(names_from = species, values_from = avg_clength) \n\n# A tibble: 3 × 4\n  sex    Adelie Chinstrap Gentoo\n  &lt;fct&gt;   &lt;dbl&gt;     &lt;dbl&gt;  &lt;dbl&gt;\n1 female   3.73      4.66   4.56\n2 male     4.04      5.11   4.95\n3 &lt;NA&gt;     3.78     NA      4.56\n\npenguins_wide &lt;- penguins_subset |&gt;\n  drop_na(culmen_length_cm) |&gt;\n  select(culmen_length_cm, species, sex) |&gt;\n  pivot_wider(values_from = culmen_length_cm, names_from = species, values_fn = mean) |&gt;\n  arrange(sex) |&gt;\n  select(sex, Adelie, Chinstrap, Gentoo)\npenguins_wide\n\n# A tibble: 3 × 4\n  sex    Adelie Chinstrap Gentoo\n  &lt;fct&gt;   &lt;dbl&gt;     &lt;dbl&gt;  &lt;dbl&gt;\n1 female   3.73      4.66   4.56\n2 male     4.04      5.11   4.95\n3 &lt;NA&gt;     3.78     NA      4.56\n\npivot_longer(penguins_wide, cols = -sex, names_to = \"species\", values_to = \"avg_clength\")\n\n# A tibble: 9 × 3\n  sex    species   avg_clength\n  &lt;fct&gt;  &lt;chr&gt;           &lt;dbl&gt;\n1 female Adelie           3.73\n2 female Chinstrap        4.66\n3 female Gentoo           4.56\n4 male   Adelie           4.04\n5 male   Chinstrap        5.11\n6 male   Gentoo           4.95\n7 &lt;NA&gt;   Adelie           3.78\n8 &lt;NA&gt;   Chinstrap       NA   \n9 &lt;NA&gt;   Gentoo           4.56"
  },
  {
    "objectID": "00-introduction_to_r-page.html#exercise-2",
    "href": "00-introduction_to_r-page.html#exercise-2",
    "title": "Introduction to R",
    "section": "",
    "text": "Become the Ornithologist\n\n\n\n\nRead the penguins_raw.feather file\nRemove all whitespace and special characters from the column names\nCalculate the body mass for each penguin in kg\nCreate a pivot-table with the median (?median) body mass for each species on each island\n\nthe island names should be in the first column\nthe species names should be the remaining columns\n\nRepeat the analysis but only for female penguins\n\n\n\n\n\n\n\n\n\nBecome the music manager\n\n\n\n\nRead the top10_charts.csv in chart_data\nWhat is the range of dates in this dataset? (Hint: ?min, ?max)\nWhat is the top region in terms of streams overall? (Hint: ?slice_max)\nCreate a pivot-table of the total streams (in this dataset) within a region on a given day (1st column day, remaining columns region names, values total streams)"
  },
  {
    "objectID": "00-introduction_to_r-page.html#merging-data-i",
    "href": "00-introduction_to_r-page.html#merging-data-i",
    "title": "Introduction to R",
    "section": "",
    "text": "Often we have two separate datasets with corresponding groups of rows\n\nStreams, trackID in top10_charts.csv and Song metadata, trackID in top10_meta.csv\npurchaseid, customerid in noahs-orders.csv and productid, purchaseid in noahs-orders_items.csv and customerid, customer metadata in noahs-customers.csv\n\nCombine data using joins\n\n\ncharts &lt;- readr::read_csv(\"data/chart_data/top10_charts.csv\")\n\nRows: 7320 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (3): trackID, region, isrc\ndbl  (3): rank, streams, dayNumber\ndate (1): day\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nsongs &lt;- readr::read_csv(\"data/chart_data/top10_meta.csv\")\n\nRows: 347 Columns: 29\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (12): trackID, trackName, artistName, artistIds, isrc, primary_artistNa...\ndbl  (16): explicit, trackPopularity, n_available_markets, danceability, ene...\ndate  (1): releaseDate\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nstr(charts, give.attr=FALSE)\n\nspc_tbl_ [7,320 × 7] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n $ trackID  : chr [1:7320] \"012iHyRvQQquWQGUTYvDxy\" \"017PF4Q3l4DBUiWoXk4OWT\" \"017PF4Q3l4DBUiWoXk4OWT\" \"017PF4Q3l4DBUiWoXk4OWT\" ...\n $ rank     : num [1:7320] 7 6 7 7 7 8 9 9 10 10 ...\n $ streams  : num [1:7320] 26234 4276985 3688979 3255639 3478044 ...\n $ day      : Date[1:7320], format: \"2020-08-14\" \"2020-03-27\" ...\n $ dayNumber: num [1:7320] 1318 1178 1179 1180 1181 ...\n $ region   : chr [1:7320] \"at\" \"global\" \"global\" \"global\" ...\n $ isrc     : chr [1:7320] \"DEUM72004523\" \"GBAHT1901303\" \"GBAHT1901303\" \"GBAHT1901303\" ...\n\nstr(songs, give.attr=FALSE)\n\nspc_tbl_ [347 × 29] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n $ trackID              : chr [1:347] \"012iHyRvQQquWQGUTYvDxy\" \"017PF4Q3l4DBUiWoXk4OWT\" \"01I9AEz658sQnQzCL3K3QG\" \"033if6Adj8fwBYsQzHOfQ8\" ...\n $ trackName            : chr [1:347] \"Fall Auf\" \"Break My Heart\" \"HOES UP G'S DOWN\" \"100k Cash\" ...\n $ artistName           : chr [1:347] \"Cro feat. badchieff\" \"Dua Lipa\" \"Shirin David\" \"Capital Bra feat. Samra\" ...\n $ artistIds            : chr [1:347] \"3utZ2yeQk0Z3BCOBWP7Vlu,6GoNVmYCl0yUm4pEp80vn6\" \"6M2wZ9GZgrQXHCFfjv46we\" \"0JBdTCGs111JKKYfLqOEBa\" \"4WZGDpNwrC0vNQyl9QzF7d,6h1s4i4XKIYv4ErDelLDN0\" ...\n $ isrc                 : chr [1:347] \"DEUM72004523\" \"GBAHT1901303\" \"DECE72000379\" \"DECE72000176\" ...\n $ explicit             : num [1:347] 0 0 1 0 0 0 0 1 0 0 ...\n $ trackPopularity      : num [1:347] 64 83 75 71 69 82 70 74 89 79 ...\n $ primary_artistName   : chr [1:347] \"Cro\" \"Dua Lipa\" \"Shirin David\" \"Capital Bra\" ...\n $ primary_artistID     : chr [1:347] \"3utZ2yeQk0Z3BCOBWP7Vlu\" \"6M2wZ9GZgrQXHCFfjv46we\" \"0JBdTCGs111JKKYfLqOEBa\" \"4WZGDpNwrC0vNQyl9QzF7d\" ...\n $ artistIDs            : chr [1:347] \"3utZ2yeQk0Z3BCOBWP7Vlu,6GoNVmYCl0yUm4pEp80vn6\" \"6M2wZ9GZgrQXHCFfjv46we\" \"0JBdTCGs111JKKYfLqOEBa\" \"4WZGDpNwrC0vNQyl9QzF7d,6h1s4i4XKIYv4ErDelLDN0\" ...\n $ albumName            : chr [1:347] \"Fall Auf\" \"Future Nostalgia\" \"HOES UP G'S DOWN\" \"100k Cash\" ...\n $ albumID              : chr [1:347] \"1qdHQo41Vkkgs8HtMk5b96\" \"7fJJK56U9fHixgO0HQkhtI\" \"15Njx2PcwnNsI65fnbM7Pw\" \"5cqwoGrjFr3VKYZ9ZC0eL2\" ...\n $ available_markets    : chr [1:347] \"AD, AE, AL, AR, AT, AU, BA, BE, BG, BH, BO, BR, BY, CA, CH, CL, CO, CR, CY, CZ, DE, DK, DO, DZ, EC, EE, EG, ES,\"| __truncated__ \"AD, AE, AR, AU, BE, BG, BH, BO, BR, CA, CL, CO, CR, CY, CZ, DK, DO, DZ, EC, EE, EG, ES, FI, FR, GB, GR, GT, HK,\"| __truncated__ \"AD, AE, AR, AT, AU, BE, BG, BH, BO, BR, CA, CH, CL, CO, CR, CY, CZ, DE, DK, DO, DZ, EC, EE, EG, ES, FI, FR, GB,\"| __truncated__ \"AD, AE, AR, AT, AU, BE, BG, BH, BO, BR, CA, CH, CL, CO, CR, CY, CZ, DE, DK, DO, DZ, EC, EE, EG, ES, FI, FR, GB,\"| __truncated__ ...\n $ n_available_markets  : num [1:347] 92 76 79 79 87 79 3 79 92 92 ...\n $ releaseDate          : Date[1:347], format: \"2020-08-13\" \"2020-03-27\" ...\n $ releaseDate_precision: chr [1:347] \"day\" \"day\" \"day\" \"day\" ...\n $ danceability         : num [1:347] 0.5 0.73 0.73 0.701 0.84 0.795 0.814 0.774 0.641 0.571 ...\n $ energy               : num [1:347] 0.743 0.729 0.777 0.714 0.648 0.607 0.794 0.805 0.324 0.693 ...\n $ key                  : num [1:347] 2 4 1 10 10 7 7 11 11 6 ...\n $ loudness             : num [1:347] -6.65 -3.43 -6.38 -5.91 -5.54 ...\n $ mode                 : num [1:347] 1 0 0 1 0 1 1 0 1 0 ...\n $ speechiness          : num [1:347] 0.0373 0.0886 0.29 0.524 0.0489 0.23 0.0887 0.302 0.0299 0.0545 ...\n $ acousticness         : num [1:347] 0.307 0.167 0.0455 0.289 0.101 0.128 0.119 0.0509 0.698 0.0054 ...\n $ instrumentalness     : num [1:347] 0.00 1.39e-06 1.10e-03 0.00 1.00e-04 1.90e-01 9.00e-04 0.00 0.00 0.00 ...\n $ liveness             : num [1:347] 0.133 0.349 0.0759 0.0883 0.0996 0.111 0.348 0.149 0.328 0.173 ...\n $ valence              : num [1:347] 0.332 0.467 0.578 0.604 0.431 0.25 0.647 0.261 0.273 0.393 ...\n $ tempo                : num [1:347] 166.3 113 177.9 86.9 103 ...\n $ duration_ms          : num [1:347] 191827 221820 130307 173353 124690 ...\n $ time_signature       : num [1:347] 4 4 4 4 4 4 4 4 4 4 ..."
  },
  {
    "objectID": "00-introduction_to_r-page.html#merging-data-ii",
    "href": "00-introduction_to_r-page.html#merging-data-ii",
    "title": "Introduction to R",
    "section": "",
    "text": "The name of the join determines which “ids” are kept\nleft_join keeps all rows that have an id in the left dataset\ninner_join only keeps rows with ids in both datasets\n\n\ndata1 &lt;- data.frame(group = c('a', 'a', 'b','c'), value = c(1,2,3,4)) # missing group 'd'\ndata2 &lt;- data.frame(group2 = c('a', 'c', 'd'), value2 = factor(c(\"abc\", \"def\", \"ghi\"))) # missing group 'b'\n\nleft_join(data1, data2, by = c(\"group\" = \"group2\"))\n\n  group value value2\n1     a     1    abc\n2     a     2    abc\n3     b     3   &lt;NA&gt;\n4     c     4    def\n\nright_join(data1, data2, by = c(\"group\" = \"group2\"))\n\n  group value value2\n1     a     1    abc\n2     a     2    abc\n3     c     4    def\n4     d    NA    ghi\n\ninner_join(data1, data2, by = c(\"group\" = \"group2\"))\n\n  group value value2\n1     a     1    abc\n2     a     2    abc\n3     c     4    def"
  },
  {
    "objectID": "00-introduction_to_r-page.html#special-joins",
    "href": "00-introduction_to_r-page.html#special-joins",
    "title": "Introduction to R",
    "section": "",
    "text": "full_join returns all rows from both datasets\nsemi_join returns only the columns of the left dataset and filters rows with id in the right dataset\nanti_join keeps only rows that do not have an id in the right table\n\n\nfull_join(data1, data2, by = c(\"group\" = \"group2\"))\n\n  group value value2\n1     a     1    abc\n2     a     2    abc\n3     b     3   &lt;NA&gt;\n4     c     4    def\n5     d    NA    ghi\n\nsemi_join(data1, data2, by = c(\"group\" = \"group2\"))\n\n  group value\n1     a     1\n2     a     2\n3     c     4\n\nfilter(data1, group %in% data2$group2)\n\n  group value\n1     a     1\n2     a     2\n3     c     4\n\nanti_join(data1, data2, by = c(\"group\" = \"group2\"))\n\n  group value\n1     b     3"
  },
  {
    "objectID": "00-introduction_to_r-page.html#exercise-3",
    "href": "00-introduction_to_r-page.html#exercise-3",
    "title": "Introduction to R",
    "section": "",
    "text": "BE the music manager\n\n\n\n\nWho are the top 10 artists in terms of total global streams?\nWhat is their most succesful song?\nFor how many songs are do we not have meta data?\nHow many songs are there in the data? (Hint: ?n_distinct, or ?length, ?unique)\nSave the combined data as top10_all.parquet"
  },
  {
    "objectID": "00-introduction_to_r-page.html#references",
    "href": "00-introduction_to_r-page.html#references",
    "title": "Introduction to R",
    "section": "",
    "text": "Links\n\nR Logo\nNoah’s Database\n\nBibliography\n\n\nHorst, Allison Marie, Alison Presmanes Hill, and Kristen B Gorman. 2020. Palmerpenguins: Palmer Archipelago (Antarctica) Penguin Data. https://doi.org/10.5281/zenodo.3960218."
  },
  {
    "objectID": "00-introduction_to_r-page.html#footnotes",
    "href": "00-introduction_to_r-page.html#footnotes",
    "title": "Introduction to R",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nhttps://aws.amazon.com/what-is/object-storage/↩︎"
  },
  {
    "objectID": "01-introduction_to_r.html#why-r",
    "href": "01-introduction_to_r.html#why-r",
    "title": "Introduction to R",
    "section": "Why R?",
    "text": "Why R?\n\nWell established in business and scientific computing\nVery powerful language\n\nExpress any operation in terms of\nOften complex functions are already implemented\n\n\nVery good package manager and ecosystem\n\nWe will use many tools created by companies, universities, and other R community members\n\n\nVery good for reproducibility\n\nCode documents the process\nShould run the same on my and your machine\nShould be easily adaptable to changing data\n\n\nOpen source\n\nAll packages can be inspected\nFree to install and use on any computer\n\n\nDeveloped (partly) and hosted at WU 😋"
  },
  {
    "objectID": "01-introduction_to_r.html#what-do-we-need",
    "href": "01-introduction_to_r.html#what-do-we-need",
    "title": "Introduction to R",
    "section": "What do we need?",
    "text": "What do we need?\n\n\n\nThe R interpreter\n\nThe program that “interprets” R code and runs it\nVery bare-bones, essentially just a text field\nDoes not store code files for reproducibility\n\n\n\n\nprint(\"Hello, WU!\")\n\n\n\n[1] \"Hello, WU!\"\n\npaste0(\"One plus two is: \", 1 + 2)\n\n[1] \"One plus two is: 3\"\n\nc &lt;- data.frame(p = seq(0, 2 * pi, by = 0.001))\nc$h_x &lt;- 16 * sin(c$p)^3\nc$h_y &lt;- 13 * cos(c$p) - 5 * cos(2 * c$p) - 2 * cos(3 * c$p) - cos(4 * c$p)\nplot(c$h_x, c$h_y, type = \"l\", main = \"I &lt;3 R\", frame = F, xlab = NA, ylab = NA)\n\n\n\n\n\n\n\n\n\nAn Integrated Development Environment (IDE)\n\nMakes writing and storing R code easier (more fun!)\nThree options compatible with this course:\n\n\nR Studio Desktop (Recommended)\n\nFocused on R\nEasiest option\n\n\n\nVS Code\n\nRecommended if you (plan to) use other languages (Python, C++, Julia, etc.)\nNeeds extension for R but works well\n\n\n\nJupyterLab\n\n“Notebooks” for R, Python, and Julia\nOutput generated directly under code “cells”"
  },
  {
    "objectID": "01-introduction_to_r.html#if-you-already-know-r",
    "href": "01-introduction_to_r.html#if-you-already-know-r",
    "title": "Introduction to R",
    "section": "If you already know R",
    "text": "If you already know R\n\n\n\nMy favorite R package\n\n\n\nDownload the presentation template my_favorite_r_package.qmd and the bibliography file data_literacy.bib from Canvas\nSelect a package that was useful to you in the past\nPrepare a short presentation about the package\n\nInclude examples of how to use the package\nShow in which situations that is useful"
  },
  {
    "objectID": "01-introduction_to_r.html#basic-workflow-r-studio",
    "href": "01-introduction_to_r.html#basic-workflow-r-studio",
    "title": "Introduction to R",
    "section": "Basic Workflow (R Studio)",
    "text": "Basic Workflow (R Studio)\n\n\nCtrl + Enter to run current line of code (any cursor position)"
  },
  {
    "objectID": "01-introduction_to_r.html#basic-workflow-vs-code",
    "href": "01-introduction_to_r.html#basic-workflow-vs-code",
    "title": "Introduction to R",
    "section": "Basic Workflow (VS Code)",
    "text": "Basic Workflow (VS Code)\n\n\nCtrl + Enter to run current line of code (any cursor position)"
  },
  {
    "objectID": "01-introduction_to_r.html#r-syntax-comments-assignment",
    "href": "01-introduction_to_r.html#r-syntax-comments-assignment",
    "title": "Introduction to R",
    "section": "R Syntax: comments, assignment",
    "text": "R Syntax: comments, assignment\n\n# This is a comment\nprint(\"Hi\") # also a comment\n\n[1] \"Hi\"\n\n## Assignment of varibale names\nx &lt;- 1\nx\n\n[1] 1\n\n## Missing values\nNA\n\n[1] NA\n\n## Vectors\ny &lt;- c(1, 2, 3, NA)\ny\n\n[1]  1  2  3 NA"
  },
  {
    "objectID": "01-introduction_to_r.html#functions",
    "href": "01-introduction_to_r.html#functions",
    "title": "Introduction to R",
    "section": "Functions",
    "text": "Functions\n\n## built-in\nsum(y)\n\n[1] NA\n\nsum(y, na.rm = FALSE)\n\n[1] NA\n\nsum(y, na.rm = TRUE)\n\n[1] 6\n\n## User functions\na_plus_b &lt;- function(a, b = 1) {\n    return(a + b)\n}\na_plus_b(y)\n\n[1]  2  3  4 NA\n\na_plus_b(y, 2)\n\n[1]  3  4  5 NA\n\na_plus_b(b = 2, a = y)\n\n[1]  3  4  5 NA\n\n## Functions provided by packages\n## Installation\n#install.packages(\"ineq\")\nineq::Gini(y)\n\n[1] 0.2222222\n\n## or\nlibrary(ineq)\nGini(y)\n\n[1] 0.2222222\n\n## Help \n?Gini"
  },
  {
    "objectID": "01-introduction_to_r.html#r-syntax-indexing-logic",
    "href": "01-introduction_to_r.html#r-syntax-indexing-logic",
    "title": "Introduction to R",
    "section": "R Syntax: indexing, logic",
    "text": "R Syntax: indexing, logic\n\ny[1]\n\n[1] 1\n\ny[-1]\n\n[1]  2  3 NA\n\ny[2:3]\n\n[1] 2 3\n\ny[c(1, 3, 4)]\n\n[1]  1  3 NA\n\nset.seed(1)\nx &lt;- y / 2 + rnorm(length(y))\ncbind(y, x)\n\n      y          x\n[1,]  1 -0.1264538\n[2,]  2  1.1836433\n[3,]  3  0.6643714\n[4,] NA         NA\n\ny &gt; 2\n\n[1] FALSE FALSE  TRUE    NA\n\ny &gt; 2 & x &gt; 0\n\n[1] FALSE FALSE  TRUE    NA\n\ny &gt; 2 | x &gt; 0\n\n[1] FALSE  TRUE  TRUE    NA\n\ny[y &gt; 2 | x &gt; 0]\n\n[1]  2  3 NA"
  },
  {
    "objectID": "01-introduction_to_r.html#r-syntax-loops-ranges",
    "href": "01-introduction_to_r.html#r-syntax-loops-ranges",
    "title": "Introduction to R",
    "section": "R Syntax: loops, ranges",
    "text": "R Syntax: loops, ranges\n\n## 'elem' is a temporary variable\nfor (elem in y) {\n    print(paste(\"Current y value is:\", elem))\n}\n\n[1] \"Current y value is: 1\"\n[1] \"Current y value is: 2\"\n[1] \"Current y value is: 3\"\n[1] \"Current y value is: NA\"\n\n## 'seq_along' returns a vector which indexes the argument\nfor (i in seq_along(y)) {\n    print(paste(\"Current y value is:\", y[i]))\n}\n\n[1] \"Current y value is: 1\"\n[1] \"Current y value is: 2\"\n[1] \"Current y value is: 3\"\n[1] \"Current y value is: NA\"\n\n## set.seed guarantees the same random numbers every time\nset.seed(1)\ntotal &lt;- 0\nwhile (total &lt; 1) {\n    ## runif generates random numbers between 0 and 1\n    total &lt;- total + runif(1)\n    print(paste(\"Current total value is:\", total))\n}\n\n[1] \"Current total value is: 0.2655086631421\"\n[1] \"Current total value is: 0.63763256277889\"\n[1] \"Current total value is: 1.21048592613079\"\n\n## ranges\n1:3\n\n[1] 1 2 3\n\n10:3\n\n[1] 10  9  8  7  6  5  4  3\n\nseq(3, 11, by = 2)\n\n[1]  3  5  7  9 11"
  },
  {
    "objectID": "01-introduction_to_r.html#r-syntax-conditional-logic",
    "href": "01-introduction_to_r.html#r-syntax-conditional-logic",
    "title": "Introduction to R",
    "section": "R Syntax: conditional logic",
    "text": "R Syntax: conditional logic\n\nz &lt;- -2:3\nfor (x in z) {\n  print(paste(\"x =\", x))\n    if (x &gt; 0) {\n        print(\"x is positive\")\n    } else if (x &gt; 2) {\n        print(\"x is greater than 2\")\n    } else if (x &lt; 0) {\n        print(\"x is negative\")\n    } else if (x == 0) {\n        print(\"x is zero\")\n    }\n}\n\n[1] \"x = -2\"\n[1] \"x is negative\"\n[1] \"x = -1\"\n[1] \"x is negative\"\n[1] \"x = 0\"\n[1] \"x is zero\"\n[1] \"x = 1\"\n[1] \"x is positive\"\n[1] \"x = 2\"\n[1] \"x is positive\"\n[1] \"x = 3\"\n[1] \"x is positive\"\n\nz[z &lt;= 0]\n\n[1] -2 -1  0\n\nz[z &gt;= 0]\n\n[1] 0 1 2 3\n\nz[z != 0]\n\n[1] -2 -1  1  2  3\n\nz[! z &lt; 0]\n\n[1] 0 1 2 3"
  },
  {
    "objectID": "01-introduction_to_r.html#exercise",
    "href": "01-introduction_to_r.html#exercise",
    "title": "Introduction to R",
    "section": "Exercise",
    "text": "Exercise\n\n\n\nWrite your own function\n\n\n\nThe function should take two arguments a and b\n\nFirst, check if a and b have the same number of elements (see ?length)\n\nIf they have a different number of elements, return NA\n\n\n\nIterate over the elements of a and b and check which vector’s element is larger (or if they are equal)\nIf they are equal print the index of the element and “equal”\nIf the element in a is larger print the index of the elemnt and “a larger”\nIf the element in b is larger print the index of the elemnt and “b larger”\n\n\n\n\nExample 1\n\n\na is: 1 2 3 \n\n\nb is: 1 2 3 4 \n\n\nResult:\n\n\n[1] NA\n\n\nExample 2\n\n\na is: 1 2 3 \n\n\nb is: 0 2 4 \n\n\nResult:\n\n\n[1] \"1 a larger\"\n\n\n[1] \"2 equal\"\n\n\n[1] \"3 b larger\""
  },
  {
    "objectID": "01-introduction_to_r.html#rectangular-data-frames-creation-and-access",
    "href": "01-introduction_to_r.html#rectangular-data-frames-creation-and-access",
    "title": "Introduction to R",
    "section": "Rectangular data frames: creation and access",
    "text": "Rectangular data frames: creation and access\n\ndata &lt;- data.frame(x = -1:1, y = 3:1, z = c(\"a\", \"b\", NA))\ndata\n\n   x y    z\n1 -1 3    a\n2  0 2    b\n3  1 1 &lt;NA&gt;\n\nclass(data)\n\n[1] \"data.frame\"\n\n## Variable access\ndata$x\n\n[1] -1  0  1\n\ndata$x + data$y\n\n[1] 2 2 2\n\nrow_summaries &lt;- with(data, \n  data.frame(\n    rsum = x + y,\n    rdiff = x - y\n  ))\nrow_summaries\n\n  rsum rdiff\n1    2    -4\n2    2    -2\n3    2     0"
  },
  {
    "objectID": "01-introduction_to_r.html#rectangular-data-frames-overview",
    "href": "01-introduction_to_r.html#rectangular-data-frames-overview",
    "title": "Introduction to R",
    "section": "Rectangular data frames: overview",
    "text": "Rectangular data frames: overview\n\nstr(data)\n\n'data.frame':   3 obs. of  3 variables:\n $ x: int  -1 0 1\n $ y: int  3 2 1\n $ z: chr  \"a\" \"b\" NA\n\nsummary(data)\n\n       x              y            z            \n Min.   :-1.0   Min.   :1.0   Length:3          \n 1st Qu.:-0.5   1st Qu.:1.5   Class :character  \n Median : 0.0   Median :2.0   Mode  :character  \n Mean   : 0.0   Mean   :2.0                     \n 3rd Qu.: 0.5   3rd Qu.:2.5                     \n Max.   : 1.0   Max.   :3.0                     \n\nhead(data)\n\n   x y    z\n1 -1 3    a\n2  0 2    b\n3  1 1 &lt;NA&gt;"
  },
  {
    "objectID": "01-introduction_to_r.html#rectangular-data-frames-indexing",
    "href": "01-introduction_to_r.html#rectangular-data-frames-indexing",
    "title": "Introduction to R",
    "section": "Rectangular data frames: Indexing",
    "text": "Rectangular data frames: Indexing\n\n## 2D structure of data\n## Empty argument means \"all\"#| \ndata[, c(\"x\", \"y\")]\n\n   x y\n1 -1 3\n2  0 2\n3  1 1\n\ndata[1:3, c(\"x\", \"y\")]\n\n   x y\n1 -1 3\n2  0 2\n3  1 1\n\ndata[1, ]\n\n   x y z\n1 -1 3 a\n\ndata[c(1, 3), c(\"x\", \"z\")]\n\n   x    z\n1 -1    a\n3  1 &lt;NA&gt;\n\ndata[data$x &lt; 3,]\n\n   x y    z\n1 -1 3    a\n2  0 2    b\n3  1 1 &lt;NA&gt;"
  },
  {
    "objectID": "01-introduction_to_r.html#rectangular-data-adding-and-removing-variables",
    "href": "01-introduction_to_r.html#rectangular-data-adding-and-removing-variables",
    "title": "Introduction to R",
    "section": "Rectangular data: adding and removing variables",
    "text": "Rectangular data: adding and removing variables\n\n## new data has to have the same number of elements\ndata$a &lt;- 2 * data$x\ndata\n\n   x y    z  a\n1 -1 3    a -2\n2  0 2    b  0\n3  1 1 &lt;NA&gt;  2\n\ndata$b &lt;- c(\"one\", \"two\", \"three\")\ndata\n\n   x y    z  a     b\n1 -1 3    a -2   one\n2  0 2    b  0   two\n3  1 1 &lt;NA&gt;  2 three\n\ndata$x &lt;- NULL\ndata\n\n  y    z  a     b\n1 3    a -2   one\n2 2    b  0   two\n3 1 &lt;NA&gt;  2 three\n\ndata$a &lt;- log(data$a)\ndata\n\n  y    z         a     b\n1 3    a       NaN   one\n2 2    b      -Inf   two\n3 1 &lt;NA&gt; 0.6931472 three\n\ndata$b[data$b == \"two\"] &lt;- \"TWO!\"\ndata$z[is.na(data$z)] &lt;- \"c\"\ndata$a[is.nan(data$a)] &lt;- 0\ndata\n\n  y z         a     b\n1 3 a 0.0000000   one\n2 2 b      -Inf  TWO!\n3 1 c 0.6931472 three"
  },
  {
    "objectID": "01-introduction_to_r.html#exercise-1",
    "href": "01-introduction_to_r.html#exercise-1",
    "title": "Introduction to R",
    "section": "Exercise",
    "text": "Exercise\n\n\n\nGenerate your own data\n\n\n\nLook at the helpfiles of rnorm, runif, and ifelse\n\nCreate a data.frame with 10 rows and variables x, generated using runif and y, generated using rnorm\n\nAdd variable z which takes the value 1 if x is larger than y and 0 otherwise\nCreate a second data.frame that holds the rows of the original one for which z == 1 is TRUE.\nRemove column z from the second data.frame\n\nWhat happens if you try to create a data.frame when x and y have a differnent number of elements?\nWhat happens if you run the code you wrote for this exercise again (and again)?\nHow can you ensure that each run yields the same results?"
  },
  {
    "objectID": "01-introduction_to_r.html#reading-data",
    "href": "01-introduction_to_r.html#reading-data",
    "title": "Introduction to R",
    "section": "Reading data",
    "text": "Reading data\n\nPlease download & unzip the folder found in “data” in Canvas\nWe will first use the “penguins” folder which includes the penguins_raw data set in multiple file formats\n\n\n## CSV\npenguins_raw &lt;- readr::read_csv(\"data/penguins/penguins_raw.csv\")\nhead(penguins_raw, 2)\n\n# A tibble: 2 × 18\n  ...1     studyName `Sample Number` Species Region Island Stage `Individual ID`\n  &lt;chr&gt;    &lt;chr&gt;               &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;  &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt;          \n1 # this … &lt;NA&gt;                   NA &lt;NA&gt;    &lt;NA&gt;   &lt;NA&gt;   &lt;NA&gt;  &lt;NA&gt;           \n2 1        PAL0708                 1 Adelie… Anvers Torge… Adul… N1A1           \n# ℹ 10 more variables: `Clutch Completion` &lt;chr&gt;, `Date Egg` &lt;date&gt;,\n#   `Culmen Length (mm)` &lt;dbl&gt;, `Culmen Depth (mm)` &lt;dbl&gt;,\n#   `Flipper Length (mm)` &lt;dbl&gt;, `Body Mass (g)` &lt;dbl&gt;, Sex &lt;chr&gt;,\n#   `Delta 15 N (o/oo)` &lt;dbl&gt;, `Delta 13 C (o/oo)` &lt;dbl&gt;, Comments &lt;chr&gt;\n\n\n\n\npenguins_raw[1,1]\n\n# A tibble: 1 × 1\n  ...1                                              \n  &lt;chr&gt;                                             \n1 # this is a comment making the data harder to read\n\n\n\n\n\nFix the data\n\n\n\nThe second row (after the column names) in the penguins_raw.csv file is a comment\nLook at the help file for the readr::read_csv function (?readr::read_csv)\nHow can we ignore the comment row?"
  },
  {
    "objectID": "01-introduction_to_r.html#reading-data-solution",
    "href": "01-introduction_to_r.html#reading-data-solution",
    "title": "Introduction to R",
    "section": "Reading data: solution",
    "text": "Reading data: solution\n\n## CSV\npenguins_raw &lt;- readr::read_csv(\n  \"data/penguins/penguins_raw.csv\",\n  comment = \"#\")\nhead(penguins_raw, 2)\n\n# A tibble: 2 × 18\n   ...1 studyName `Sample Number` Species    Region Island Stage `Individual ID`\n  &lt;dbl&gt; &lt;chr&gt;               &lt;dbl&gt; &lt;chr&gt;      &lt;chr&gt;  &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt;          \n1     1 PAL0708                 1 Adelie Pe… Anvers Torge… Adul… N1A1           \n2     2 PAL0708                 2 Adelie Pe… Anvers Torge… Adul… N1A2           \n# ℹ 10 more variables: `Clutch Completion` &lt;chr&gt;, `Date Egg` &lt;date&gt;,\n#   `Culmen Length (mm)` &lt;dbl&gt;, `Culmen Depth (mm)` &lt;dbl&gt;,\n#   `Flipper Length (mm)` &lt;dbl&gt;, `Body Mass (g)` &lt;dbl&gt;, Sex &lt;chr&gt;,\n#   `Delta 15 N (o/oo)` &lt;dbl&gt;, `Delta 13 C (o/oo)` &lt;dbl&gt;, Comments &lt;chr&gt;\n\npenguins_raw[1,1]\n\n# A tibble: 1 × 1\n   ...1\n  &lt;dbl&gt;\n1     1\n\nstr(penguins_raw)\n\nspc_tbl_ [344 × 18] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n $ ...1               : num [1:344] 1 2 3 4 5 6 7 8 9 10 ...\n $ studyName          : chr [1:344] \"PAL0708\" \"PAL0708\" \"PAL0708\" \"PAL0708\" ...\n $ Sample Number      : num [1:344] 1 2 3 4 5 6 7 8 9 10 ...\n $ Species            : chr [1:344] \"Adelie Penguin (Pygoscelis adeliae)\" \"Adelie Penguin (Pygoscelis adeliae)\" \"Adelie Penguin (Pygoscelis adeliae)\" \"Adelie Penguin (Pygoscelis adeliae)\" ...\n $ Region             : chr [1:344] \"Anvers\" \"Anvers\" \"Anvers\" \"Anvers\" ...\n $ Island             : chr [1:344] \"Torgersen\" \"Torgersen\" \"Torgersen\" \"Torgersen\" ...\n $ Stage              : chr [1:344] \"Adult, 1 Egg Stage\" \"Adult, 1 Egg Stage\" \"Adult, 1 Egg Stage\" \"Adult, 1 Egg Stage\" ...\n $ Individual ID      : chr [1:344] \"N1A1\" \"N1A2\" \"N2A1\" \"N2A2\" ...\n $ Clutch Completion  : chr [1:344] \"Yes\" \"Yes\" \"Yes\" \"Yes\" ...\n $ Date Egg           : Date[1:344], format: \"2007-11-11\" \"2007-11-11\" ...\n $ Culmen Length (mm) : num [1:344] 39.1 39.5 40.3 NA 36.7 39.3 38.9 39.2 34.1 42 ...\n $ Culmen Depth (mm)  : num [1:344] 18.7 17.4 18 NA 19.3 20.6 17.8 19.6 18.1 20.2 ...\n $ Flipper Length (mm): num [1:344] 181 186 195 NA 193 190 181 195 193 190 ...\n $ Body Mass (g)      : num [1:344] 3750 3800 3250 NA 3450 ...\n $ Sex                : chr [1:344] \"MALE\" \"FEMALE\" \"FEMALE\" NA ...\n $ Delta 15 N (o/oo)  : num [1:344] NA 8.95 8.37 NA 8.77 ...\n $ Delta 13 C (o/oo)  : num [1:344] NA -24.7 -25.3 NA -25.3 ...\n $ Comments           : chr [1:344] \"Not enough blood for isotopes.\" NA NA \"Adult not sampled.\" ...\n - attr(*, \"spec\")=\n  .. cols(\n  ..   ...1 = col_double(),\n  ..   studyName = col_character(),\n  ..   `Sample Number` = col_double(),\n  ..   Species = col_character(),\n  ..   Region = col_character(),\n  ..   Island = col_character(),\n  ..   Stage = col_character(),\n  ..   `Individual ID` = col_character(),\n  ..   `Clutch Completion` = col_character(),\n  ..   `Date Egg` = col_date(format = \"\"),\n  ..   `Culmen Length (mm)` = col_double(),\n  ..   `Culmen Depth (mm)` = col_double(),\n  ..   `Flipper Length (mm)` = col_double(),\n  ..   `Body Mass (g)` = col_double(),\n  ..   Sex = col_character(),\n  ..   `Delta 15 N (o/oo)` = col_double(),\n  ..   `Delta 13 C (o/oo)` = col_double(),\n  ..   Comments = col_character()\n  .. )\n - attr(*, \"problems\")=&lt;externalptr&gt;"
  },
  {
    "objectID": "01-introduction_to_r.html#reading-data-other-file-formats",
    "href": "01-introduction_to_r.html#reading-data-other-file-formats",
    "title": "Introduction to R",
    "section": "Reading data: other file formats",
    "text": "Reading data: other file formats\n\nThe readxl package provides functions for reading Excel files\n\n\npenguins_raw &lt;- readxl::read_excel(\"data/penguins/penguins_raw.xlsx\")\nhead(penguins_raw, 2)\n\n# A tibble: 2 × 18\n  ...1  studyName `Sample Number` Species    Region Island Stage `Individual ID`\n  &lt;chr&gt; &lt;chr&gt;               &lt;dbl&gt; &lt;chr&gt;      &lt;chr&gt;  &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt;          \n1 1     PAL0708                 1 Adelie Pe… Anvers Torge… Adul… N1A1           \n2 2     PAL0708                 2 Adelie Pe… Anvers Torge… Adul… N1A2           \n# ℹ 10 more variables: `Clutch Completion` &lt;chr&gt;, `Date Egg` &lt;dttm&gt;,\n#   `Culmen Length (mm)` &lt;dbl&gt;, `Culmen Depth (mm)` &lt;dbl&gt;,\n#   `Flipper Length (mm)` &lt;dbl&gt;, `Body Mass (g)` &lt;dbl&gt;, Sex &lt;chr&gt;,\n#   `Delta 15 N (o/oo)` &lt;dbl&gt;, `Delta 13 C (o/oo)` &lt;dbl&gt;, Comments &lt;chr&gt;\n\n## Read a subset \npenguins_subset &lt;- readxl::read_excel(\"data/penguins/penguins_raw.xlsx\", sheet = \"Sheet1\", range = \"B1:O345\")\nhead(penguins_subset, 2)\n\n# A tibble: 2 × 14\n  studyName `Sample Number` Species          Region Island Stage `Individual ID`\n  &lt;chr&gt;               &lt;dbl&gt; &lt;chr&gt;            &lt;chr&gt;  &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt;          \n1 PAL0708                 1 Adelie Penguin … Anvers Torge… Adul… N1A1           \n2 PAL0708                 2 Adelie Penguin … Anvers Torge… Adul… N1A2           \n# ℹ 7 more variables: `Clutch Completion` &lt;chr&gt;, `Date Egg` &lt;dttm&gt;,\n#   `Culmen Length (mm)` &lt;dbl&gt;, `Culmen Depth (mm)` &lt;dbl&gt;,\n#   `Flipper Length (mm)` &lt;dbl&gt;, `Body Mass (g)` &lt;dbl&gt;, Sex &lt;chr&gt;"
  },
  {
    "objectID": "01-introduction_to_r.html#reading-data-other-file-formats-1",
    "href": "01-introduction_to_r.html#reading-data-other-file-formats-1",
    "title": "Introduction to R",
    "section": "Reading data: other file formats",
    "text": "Reading data: other file formats\n\nThe haven package provides functions for reading SPSS, Stata, and SAS files\nIt looks like SPSS does not support spaces in column names so this is slightly different\n\n\npenguins_raw &lt;- haven::read_sav(\"data/penguins/penguins_raw.sav\")\nhead(penguins_raw, 2)\n\n# A tibble: 2 × 17\n  study_name sample_number species             region island stage individual_id\n  &lt;chr&gt;              &lt;dbl&gt; &lt;chr&gt;               &lt;chr&gt;  &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt;        \n1 PAL0708                1 Adelie Penguin (Py… Anvers Torge… Adul… N1A1         \n2 PAL0708                2 Adelie Penguin (Py… Anvers Torge… Adul… N1A2         \n# ℹ 10 more variables: clutch_completion &lt;chr&gt;, date_egg &lt;date&gt;,\n#   culmen_length_mm &lt;dbl&gt;, culmen_depth_mm &lt;dbl&gt;, flipper_length_mm &lt;dbl&gt;,\n#   body_mass_g &lt;dbl&gt;, sex &lt;chr&gt;, delta_15_n_o_oo &lt;dbl&gt;, delta_13_c_o_oo &lt;dbl&gt;,\n#   comments &lt;chr&gt;"
  },
  {
    "objectID": "01-introduction_to_r.html#reading-big-data-the-arrow-package",
    "href": "01-introduction_to_r.html#reading-big-data-the-arrow-package",
    "title": "Introduction to R",
    "section": "Reading big data: the arrow package",
    "text": "Reading big data: the arrow package\n\nThe arrow package provides functions for reading Parquet and Feather files\nOptimized formats used in many data science projects\nProvides facility to read from “object storage” (e.g., Amazon S3)\n\n\nThe major benefits of object storage are the virtually unlimited scalability and the lower cost of storing large volumes of data for use cases such as data lakes, cloud native applications, analytics, log files, and machine learning (ML). 1\n\n\nRule of thumb:\n\nuse parquet for large files and long term storage\n\noptimized file size\n\n\nuse feather for optimized reading and short term storage\n\nmemory layout the same as in the process\n\n\n\n\nhttps://aws.amazon.com/what-is/object-storage/"
  },
  {
    "objectID": "01-introduction_to_r.html#reading-big-data-the-arrow-package-1",
    "href": "01-introduction_to_r.html#reading-big-data-the-arrow-package-1",
    "title": "Introduction to R",
    "section": "Reading big data: the arrow package",
    "text": "Reading big data: the arrow package\n\npenguins_raw &lt;- arrow::read_parquet(\"data/penguins/penguins_raw.parquet\")\npenguins_raw &lt;- arrow::read_feather(\"data/penguins/penguins_raw.feather\")\nhead(penguins_raw, 2)\n\n# A tibble: 2 × 17\n  studyName `Sample Number` Species          Region Island Stage `Individual ID`\n  &lt;chr&gt;               &lt;dbl&gt; &lt;chr&gt;            &lt;chr&gt;  &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt;          \n1 PAL0708                 1 Adelie Penguin … Anvers Torge… Adul… N1A1           \n2 PAL0708                 2 Adelie Penguin … Anvers Torge… Adul… N1A2           \n# ℹ 10 more variables: `Clutch Completion` &lt;chr&gt;, `Date Egg` &lt;date&gt;,\n#   `Culmen Length (mm)` &lt;dbl&gt;, `Culmen Depth (mm)` &lt;dbl&gt;,\n#   `Flipper Length (mm)` &lt;dbl&gt;, `Body Mass (g)` &lt;dbl&gt;, Sex &lt;chr&gt;,\n#   `Delta 15 N (o/oo)` &lt;dbl&gt;, `Delta 13 C (o/oo)` &lt;dbl&gt;, Comments &lt;chr&gt;\n\n\n\nSupport for complex data structures\n\n\npenguin_species_island &lt;- arrow::read_parquet('data/penguins/penguin_species_nested.parquet')\nhead(penguin_species_island, 2)\n\n# A tibble: 2 × 2\n  Island                                 data\n  &lt;chr&gt;     &lt;list&lt;tbl_df&lt;Species:character&gt;&gt;&gt;\n1 Torgersen                          [52 × 1]\n2 Biscoe                            [168 × 1]\n\nhead(tidyr::unnest(penguin_species_island), 2)\n\n# A tibble: 2 × 2\n  Island    Species                            \n  &lt;chr&gt;     &lt;chr&gt;                              \n1 Torgersen Adelie Penguin (Pygoscelis adeliae)\n2 Torgersen Adelie Penguin (Pygoscelis adeliae)"
  },
  {
    "objectID": "01-introduction_to_r.html#benchmarks",
    "href": "01-introduction_to_r.html#benchmarks",
    "title": "Introduction to R",
    "section": "Benchmarks",
    "text": "Benchmarks\n\nlibrary(microbenchmark)\nmicrobenchmark(\n  csv = readr::read_csv(\"data/penguins/penguins_raw.csv\", \n   show_col_types = FALSE, name_repair = 'minimal'),\n  parquet = arrow::read_parquet(\"data/penguins/penguins_raw.parquet\"),\n  feather = arrow::read_feather(\"data/penguins/penguins_raw.feather\")\n) \n\nUnit: milliseconds\n    expr      min       lq     mean   median       uq       max neval cld\n     csv 7.774953 8.164555 8.585466 8.349117 8.586773 11.624443   100 a  \n parquet 1.783049 1.985671 2.090328 2.074333 2.151618  4.407172   100  b \n feather 1.347547 1.463064 1.639503 1.536208 1.606196  4.417750   100   c"
  },
  {
    "objectID": "01-introduction_to_r.html#data-types",
    "href": "01-introduction_to_r.html#data-types",
    "title": "Introduction to R",
    "section": "Data types",
    "text": "Data types\nThe most important types of data are:\n\n\n\n\n\n\nData type\nDescription\n\n\n\nNumeric\nApproximations of the real numbers, \\(\\normalsize\\mathbb{R}\\) (e.g., mileage a car gets: 23.6, 20.9, etc.)\n\n\nInteger\nWhole numbers, \\(\\normalsize\\mathbb{Z}\\) (e.g., number of sales: 7, 0, 120, 63, etc.)\n\n\nCharacter\nText data (strings, e.g., product names)\n\n\nFactor\nCategorical data for classification (e.g., product groups)\n\n\nLogical\nTRUE, FALSE\n\n\nDate\nDate variables (e.g., sales dates: 21-06-2015, 06-21-15, 21-Jun-2015, etc.)\n\n\n\nVariables can be converted from one type to another using the appropriate functions (e.g., as.numeric(), as.integer(), as.character(), as.factor(), as.logical(), as.Date())."
  },
  {
    "objectID": "01-introduction_to_r.html#lets-clean-up-the-penguins",
    "href": "01-introduction_to_r.html#lets-clean-up-the-penguins",
    "title": "Introduction to R",
    "section": "Let’s clean up the penguins!",
    "text": "Let’s clean up the penguins!\n\nstr(penguins_raw)\n\ntibble [344 × 17] (S3: tbl_df/tbl/data.frame)\n $ studyName          : chr [1:344] \"PAL0708\" \"PAL0708\" \"PAL0708\" \"PAL0708\" ...\n $ Sample Number      : num [1:344] 1 2 3 4 5 6 7 8 9 10 ...\n $ Species            : chr [1:344] \"Adelie Penguin (Pygoscelis adeliae)\" \"Adelie Penguin (Pygoscelis adeliae)\" \"Adelie Penguin (Pygoscelis adeliae)\" \"Adelie Penguin (Pygoscelis adeliae)\" ...\n $ Region             : chr [1:344] \"Anvers\" \"Anvers\" \"Anvers\" \"Anvers\" ...\n $ Island             : chr [1:344] \"Torgersen\" \"Torgersen\" \"Torgersen\" \"Torgersen\" ...\n $ Stage              : chr [1:344] \"Adult, 1 Egg Stage\" \"Adult, 1 Egg Stage\" \"Adult, 1 Egg Stage\" \"Adult, 1 Egg Stage\" ...\n $ Individual ID      : chr [1:344] \"N1A1\" \"N1A2\" \"N2A1\" \"N2A2\" ...\n $ Clutch Completion  : chr [1:344] \"Yes\" \"Yes\" \"Yes\" \"Yes\" ...\n $ Date Egg           : Date[1:344], format: \"2007-11-11\" \"2007-11-11\" ...\n $ Culmen Length (mm) : num [1:344] 39.1 39.5 40.3 NA 36.7 39.3 38.9 39.2 34.1 42 ...\n $ Culmen Depth (mm)  : num [1:344] 18.7 17.4 18 NA 19.3 20.6 17.8 19.6 18.1 20.2 ...\n $ Flipper Length (mm): num [1:344] 181 186 195 NA 193 190 181 195 193 190 ...\n $ Body Mass (g)      : num [1:344] 3750 3800 3250 NA 3450 ...\n $ Sex                : chr [1:344] \"MALE\" \"FEMALE\" \"FEMALE\" NA ...\n $ Delta 15 N (o/oo)  : num [1:344] NA 8.95 8.37 NA 8.77 ...\n $ Delta 13 C (o/oo)  : num [1:344] NA -24.7 -25.3 NA -25.3 ...\n $ Comments           : chr [1:344] \"Not enough blood for isotopes.\" NA NA \"Adult not sampled.\" ...\n - attr(*, \"spec\")=\n  .. cols(\n  ..   studyName = col_character(),\n  ..   `Sample Number` = col_double(),\n  ..   Species = col_character(),\n  ..   Region = col_character(),\n  ..   Island = col_character(),\n  ..   Stage = col_character(),\n  ..   `Individual ID` = col_character(),\n  ..   `Clutch Completion` = col_character(),\n  ..   `Date Egg` = col_date(format = \"\"),\n  ..   `Culmen Length (mm)` = col_double(),\n  ..   `Culmen Depth (mm)` = col_double(),\n  ..   `Flipper Length (mm)` = col_double(),\n  ..   `Body Mass (g)` = col_double(),\n  ..   Sex = col_character(),\n  ..   `Delta 15 N (o/oo)` = col_double(),\n  ..   `Delta 13 C (o/oo)` = col_double(),\n  ..   Comments = col_character()\n  .. )\n\n\n\nClean the column names\n\n\npenguins &lt;- janitor::clean_names(penguins_raw)\nstr(penguins)\n\ntibble [344 × 17] (S3: tbl_df/tbl/data.frame)\n $ study_name       : chr [1:344] \"PAL0708\" \"PAL0708\" \"PAL0708\" \"PAL0708\" ...\n $ sample_number    : num [1:344] 1 2 3 4 5 6 7 8 9 10 ...\n $ species          : chr [1:344] \"Adelie Penguin (Pygoscelis adeliae)\" \"Adelie Penguin (Pygoscelis adeliae)\" \"Adelie Penguin (Pygoscelis adeliae)\" \"Adelie Penguin (Pygoscelis adeliae)\" ...\n $ region           : chr [1:344] \"Anvers\" \"Anvers\" \"Anvers\" \"Anvers\" ...\n $ island           : chr [1:344] \"Torgersen\" \"Torgersen\" \"Torgersen\" \"Torgersen\" ...\n $ stage            : chr [1:344] \"Adult, 1 Egg Stage\" \"Adult, 1 Egg Stage\" \"Adult, 1 Egg Stage\" \"Adult, 1 Egg Stage\" ...\n $ individual_id    : chr [1:344] \"N1A1\" \"N1A2\" \"N2A1\" \"N2A2\" ...\n $ clutch_completion: chr [1:344] \"Yes\" \"Yes\" \"Yes\" \"Yes\" ...\n $ date_egg         : Date[1:344], format: \"2007-11-11\" \"2007-11-11\" ...\n $ culmen_length_mm : num [1:344] 39.1 39.5 40.3 NA 36.7 39.3 38.9 39.2 34.1 42 ...\n $ culmen_depth_mm  : num [1:344] 18.7 17.4 18 NA 19.3 20.6 17.8 19.6 18.1 20.2 ...\n $ flipper_length_mm: num [1:344] 181 186 195 NA 193 190 181 195 193 190 ...\n $ body_mass_g      : num [1:344] 3750 3800 3250 NA 3450 ...\n $ sex              : chr [1:344] \"MALE\" \"FEMALE\" \"FEMALE\" NA ...\n $ delta_15_n_o_oo  : num [1:344] NA 8.95 8.37 NA 8.77 ...\n $ delta_13_c_o_oo  : num [1:344] NA -24.7 -25.3 NA -25.3 ...\n $ comments         : chr [1:344] \"Not enough blood for isotopes.\" NA NA \"Adult not sampled.\" ...\n - attr(*, \"spec\")=\n  .. cols(\n  ..   studyName = col_character(),\n  ..   `Sample Number` = col_double(),\n  ..   Species = col_character(),\n  ..   Region = col_character(),\n  ..   Island = col_character(),\n  ..   Stage = col_character(),\n  ..   `Individual ID` = col_character(),\n  ..   `Clutch Completion` = col_character(),\n  ..   `Date Egg` = col_date(format = \"\"),\n  ..   `Culmen Length (mm)` = col_double(),\n  ..   `Culmen Depth (mm)` = col_double(),\n  ..   `Flipper Length (mm)` = col_double(),\n  ..   `Body Mass (g)` = col_double(),\n  ..   Sex = col_character(),\n  ..   `Delta 15 N (o/oo)` = col_double(),\n  ..   `Delta 13 C (o/oo)` = col_double(),\n  ..   Comments = col_character()\n  .. )"
  },
  {
    "objectID": "01-introduction_to_r.html#data-preprocessing-syntax",
    "href": "01-introduction_to_r.html#data-preprocessing-syntax",
    "title": "Introduction to R",
    "section": "Data-preprocessing: syntax",
    "text": "Data-preprocessing: syntax\n\n\n|&gt; is the “pipe” operator\n\nIt takes the result of the left side and passes it to the right side as the first argument\nVery useful when “chaining” multiple operations\n\n\n\n\npenguins |&gt;\n  head(2)\n\n# A tibble: 2 × 17\n  study_name sample_number species             region island stage individual_id\n  &lt;chr&gt;              &lt;dbl&gt; &lt;chr&gt;               &lt;chr&gt;  &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt;        \n1 PAL0708                1 Adelie Penguin (Py… Anvers Torge… Adul… N1A1         \n2 PAL0708                2 Adelie Penguin (Py… Anvers Torge… Adul… N1A2         \n# ℹ 10 more variables: clutch_completion &lt;chr&gt;, date_egg &lt;date&gt;,\n#   culmen_length_mm &lt;dbl&gt;, culmen_depth_mm &lt;dbl&gt;, flipper_length_mm &lt;dbl&gt;,\n#   body_mass_g &lt;dbl&gt;, sex &lt;chr&gt;, delta_15_n_o_oo &lt;dbl&gt;, delta_13_c_o_oo &lt;dbl&gt;,\n#   comments &lt;chr&gt;\n\nhead(penguins, 2)\n\n# A tibble: 2 × 17\n  study_name sample_number species             region island stage individual_id\n  &lt;chr&gt;              &lt;dbl&gt; &lt;chr&gt;               &lt;chr&gt;  &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt;        \n1 PAL0708                1 Adelie Penguin (Py… Anvers Torge… Adul… N1A1         \n2 PAL0708                2 Adelie Penguin (Py… Anvers Torge… Adul… N1A2         \n# ℹ 10 more variables: clutch_completion &lt;chr&gt;, date_egg &lt;date&gt;,\n#   culmen_length_mm &lt;dbl&gt;, culmen_depth_mm &lt;dbl&gt;, flipper_length_mm &lt;dbl&gt;,\n#   body_mass_g &lt;dbl&gt;, sex &lt;chr&gt;, delta_15_n_o_oo &lt;dbl&gt;, delta_13_c_o_oo &lt;dbl&gt;,\n#   comments &lt;chr&gt;"
  },
  {
    "objectID": "01-introduction_to_r.html#data-preprocessing-mutation",
    "href": "01-introduction_to_r.html#data-preprocessing-mutation",
    "title": "Introduction to R",
    "section": "Data preprocessing: mutation",
    "text": "Data preprocessing: mutation\n\nPkg: dplyr provides function for data.frame manipulation\nPkg: stringr provides functions to manipulate strings (characters)\nfn: mutate takes each row and applies a function to create a new (or overwrite a) column\n\nfn: select selects columns\n\n\nlibrary(dplyr)\nlibrary(stringr)\npenguins_subset &lt;- penguins |&gt;\n  mutate(\n    species = str_split(species, \" \", n = 2, simplify = TRUE)[,1],\n    is_adult = str_detect(str_to_lower(stage), \"adult\"),\n    is_female = str_detect(str_to_lower(sex), \"female\"),\n    sex = str_to_lower(sex)) |&gt;\n  select(species, island, sex, is_adult,  culmen_length_mm, culmen_depth_mm, is_female)\npenguins_subset |&gt; head(2)\n\n# A tibble: 2 × 7\n  species island    sex    is_adult culmen_length_mm culmen_depth_mm is_female\n  &lt;chr&gt;   &lt;chr&gt;     &lt;chr&gt;  &lt;lgl&gt;               &lt;dbl&gt;           &lt;dbl&gt; &lt;lgl&gt;    \n1 Adelie  Torgersen male   TRUE                 39.1            18.7 FALSE    \n2 Adelie  Torgersen female TRUE                 39.5            17.4 TRUE"
  },
  {
    "objectID": "01-introduction_to_r.html#data-preprocessing-multiple-columns",
    "href": "01-introduction_to_r.html#data-preprocessing-multiple-columns",
    "title": "Introduction to R",
    "section": "Data preprocessing: multiple columns",
    "text": "Data preprocessing: multiple columns\n\n#penguins_subset &lt;- \npenguins_subset &lt;- penguins_subset |&gt;\n  mutate(\n    across(starts_with('culmen'), \\(x) x / 10),\n    across(species:sex, as.factor),\n    across(c('is_adult', 'is_female'), as.numeric)\n    ) |&gt;\n  mutate_if(is.numeric,\n    list(scaled = \\(x) (x - mean(x, na.rm=TRUE)) / sd(x, na.rm=TRUE))\n  ) |&gt;\n  rename_with(\n    \\(name) str_replace(name, \"mm\", \"cm\"),\n    starts_with('culmen'))\npenguins_subset |&gt; select(-starts_with('is')) |&gt; str()\n\ntibble [344 × 6] (S3: tbl_df/tbl/data.frame)\n $ species                : Factor w/ 3 levels \"Adelie\",\"Chinstrap\",..: 1 1 1 1 1 1 1 1 1 1 ...\n $ sex                    : Factor w/ 2 levels \"female\",\"male\": 2 1 1 NA 1 2 1 2 NA NA ...\n $ culmen_length_cm       : num [1:344] 3.91 3.95 4.03 NA 3.67 3.93 3.89 3.92 3.41 4.2 ...\n $ culmen_depth_cm        : num [1:344] 1.87 1.74 1.8 NA 1.93 2.06 1.78 1.96 1.81 2.02 ...\n $ culmen_length_cm_scaled: num [1:344] -0.883 -0.81 -0.663 NA -1.323 ...\n $ culmen_depth_cm_scaled : num [1:344] 0.784 0.126 0.43 NA 1.088 ...\n - attr(*, \"spec\")=\n  .. cols(\n  ..   studyName = col_character(),\n  ..   `Sample Number` = col_double(),\n  ..   Species = col_character(),\n  ..   Region = col_character(),\n  ..   Island = col_character(),\n  ..   Stage = col_character(),\n  ..   `Individual ID` = col_character(),\n  ..   `Clutch Completion` = col_character(),\n  ..   `Date Egg` = col_date(format = \"\"),\n  ..   `Culmen Length (mm)` = col_double(),\n  ..   `Culmen Depth (mm)` = col_double(),\n  ..   `Flipper Length (mm)` = col_double(),\n  ..   `Body Mass (g)` = col_double(),\n  ..   Sex = col_character(),\n  ..   `Delta 15 N (o/oo)` = col_double(),\n  ..   `Delta 13 C (o/oo)` = col_double(),\n  ..   Comments = col_character()\n  .. )"
  },
  {
    "objectID": "01-introduction_to_r.html#hint-figuring-out-what-is-going-on",
    "href": "01-introduction_to_r.html#hint-figuring-out-what-is-going-on",
    "title": "Introduction to R",
    "section": "Hint: figuring out what is going on",
    "text": "Hint: figuring out what is going on\n\nSplit the problem into smaller pieces\n\n\n\\(name) str_replace(name, \"mm\", \"cm\")\n\n\\(name) str_replace(name, \"mm\", \"cm\")\n\nstr_replace(\"ammm\", \"mm\", \"cm\")\n\n[1] \"acmm\"\n\n\n\nCheck help files\n\n\n?str_replace\n\n\nCheck typeof() and class()\n\n\n\ntypeof(\\(name) str_replace(name, \"mm\", \"cm\"))\n\n[1] \"closure\"\n\n\n\\(\\rightarrow\\) closures are functions\n\nSee if you can produce some outcome on the reduced problem\n\n\nmy_function &lt;- \\(name) str_replace(name, \"mm\", \"cm\")\nmy_function('here are some mms')\n\n[1] \"here are some cms\""
  },
  {
    "objectID": "01-introduction_to_r.html#hint-read-the-source-code",
    "href": "01-introduction_to_r.html#hint-read-the-source-code",
    "title": "Introduction to R",
    "section": "Hint: read the source code",
    "text": "Hint: read the source code\n\nThis is only useful if a function is pure R code\n\n\nstr_replace\n\nfunction (string, pattern, replacement) \n{\n    if (!missing(replacement) && is_replacement_fun(replacement)) {\n        replacement &lt;- as_function(replacement)\n        return(str_transform(string, pattern, replacement))\n    }\n    check_lengths(string, pattern, replacement)\n    switch(type(pattern), empty = no_empty(), bound = no_boundary(), \n        fixed = stri_replace_first_fixed(string, pattern, replacement, \n            opts_fixed = opts(pattern)), coll = stri_replace_first_coll(string, \n            pattern, replacement, opts_collator = opts(pattern)), \n        regex = stri_replace_first_regex(string, pattern, fix_replacement(replacement), \n            opts_regex = opts(pattern)))\n}\n&lt;bytecode: 0x123d492b0&gt;\n&lt;environment: namespace:stringr&gt;"
  },
  {
    "objectID": "01-introduction_to_r.html#aside-functions-and-variable-names",
    "href": "01-introduction_to_r.html#aside-functions-and-variable-names",
    "title": "Introduction to R",
    "section": "Aside: functions and variable names",
    "text": "Aside: functions and variable names\n\nCommon mistake that leads to cryptic error:\n\n\nmeans &lt;- c(4,5,6)\nmean[1]\n\nError in mean[1]: object of type 'closure' is not subsettable"
  },
  {
    "objectID": "01-introduction_to_r.html#reducing-rows-filtering",
    "href": "01-introduction_to_r.html#reducing-rows-filtering",
    "title": "Introduction to R",
    "section": "Reducing rows: filtering",
    "text": "Reducing rows: filtering\n\nCreate different subsets of data\n“Filter in” (not out) \\(\\rightarrow\\) TRUE rows remain\n\n\nadelies &lt;- penguins_subset |&gt;\n  filter(species == \"Adelie\")\nunique(adelies$species)\n\n[1] Adelie\nLevels: Adelie Chinstrap Gentoo\n\nfemale_adelies &lt;- penguins_subset |&gt;\n  filter(species == \"Adelie\", is_female == 1)\nfemale_adelies |&gt; select(species, sex) |&gt; summary()\n\n      species       sex    \n Adelie   :73   female:73  \n Chinstrap: 0   male  : 0  \n Gentoo   : 0"
  },
  {
    "objectID": "01-introduction_to_r.html#reducing-rows-summarizing",
    "href": "01-introduction_to_r.html#reducing-rows-summarizing",
    "title": "Introduction to R",
    "section": "Reducing rows: summarizing",
    "text": "Reducing rows: summarizing\n\nCalculate any appropriate summary for a variable\n\n\nlibrary(tidyr)\npenguins |&gt;\n  drop_na(body_mass_g) |&gt;\n  summarize(avg_weight = mean(body_mass_g))\n\n# A tibble: 1 × 1\n  avg_weight\n       &lt;dbl&gt;\n1      4202.\n\n\n\nCalculate the summary for each group\n\n\npenguins_summary &lt;- penguins_subset |&gt;\n  drop_na(culmen_length_cm) |&gt;\n  group_by(species, sex) |&gt;\n  summarize(avg_clength = mean(culmen_length_cm))\npenguins_summary\n\n# A tibble: 8 × 3\n# Groups:   species [3]\n  species   sex    avg_clength\n  &lt;fct&gt;     &lt;fct&gt;        &lt;dbl&gt;\n1 Adelie    female        3.73\n2 Adelie    male          4.04\n3 Adelie    &lt;NA&gt;          3.78\n4 Chinstrap female        4.66\n5 Chinstrap male          5.11\n6 Gentoo    female        4.56\n7 Gentoo    male          4.95\n8 Gentoo    &lt;NA&gt;          4.56"
  },
  {
    "objectID": "01-introduction_to_r.html#pivot-tables",
    "href": "01-introduction_to_r.html#pivot-tables",
    "title": "Introduction to R",
    "section": "Pivot tables",
    "text": "Pivot tables\n\npenguins_summary |&gt;\n  pivot_wider(names_from = species, values_from = avg_clength) \n\n# A tibble: 3 × 4\n  sex    Adelie Chinstrap Gentoo\n  &lt;fct&gt;   &lt;dbl&gt;     &lt;dbl&gt;  &lt;dbl&gt;\n1 female   3.73      4.66   4.56\n2 male     4.04      5.11   4.95\n3 &lt;NA&gt;     3.78     NA      4.56\n\npenguins_wide &lt;- penguins_subset |&gt;\n  drop_na(culmen_length_cm) |&gt;\n  select(culmen_length_cm, species, sex) |&gt;\n  pivot_wider(values_from = culmen_length_cm, names_from = species, values_fn = mean) |&gt;\n  arrange(sex) |&gt;\n  select(sex, Adelie, Chinstrap, Gentoo)\npenguins_wide\n\n# A tibble: 3 × 4\n  sex    Adelie Chinstrap Gentoo\n  &lt;fct&gt;   &lt;dbl&gt;     &lt;dbl&gt;  &lt;dbl&gt;\n1 female   3.73      4.66   4.56\n2 male     4.04      5.11   4.95\n3 &lt;NA&gt;     3.78     NA      4.56\n\npivot_longer(penguins_wide, cols = -sex, names_to = \"species\", values_to = \"avg_clength\")\n\n# A tibble: 9 × 3\n  sex    species   avg_clength\n  &lt;fct&gt;  &lt;chr&gt;           &lt;dbl&gt;\n1 female Adelie           3.73\n2 female Chinstrap        4.66\n3 female Gentoo           4.56\n4 male   Adelie           4.04\n5 male   Chinstrap        5.11\n6 male   Gentoo           4.95\n7 &lt;NA&gt;   Adelie           3.78\n8 &lt;NA&gt;   Chinstrap       NA   \n9 &lt;NA&gt;   Gentoo           4.56"
  },
  {
    "objectID": "01-introduction_to_r.html#exercise-2",
    "href": "01-introduction_to_r.html#exercise-2",
    "title": "Introduction to R",
    "section": "Exercise",
    "text": "Exercise\n\n\n\nBecome the Ornithologist\n\n\n\nRead the penguins_raw.feather file\nRemove all whitespace and special characters from the column names\nCalculate the body mass for each penguin in kg\nCreate a pivot-table with the median (?median) body mass for each species on each island\n\nthe island names should be in the first column\nthe species names should be the remaining columns\n\n\nRepeat the analysis but only for female penguins\n\n\n\n\n\n\n\nBecome the music manager\n\n\n\nRead the top10_charts.csv in chart_data\n\nWhat is the range of dates in this dataset? (Hint: ?min, ?max)\nWhat is the top region in terms of streams overall? (Hint: ?slice_max)\nCreate a pivot-table of the total streams (in this dataset) within a region on a given day (1st column day, remaining columns region names, values total streams)"
  },
  {
    "objectID": "01-introduction_to_r.html#merging-data-i",
    "href": "01-introduction_to_r.html#merging-data-i",
    "title": "Introduction to R",
    "section": "Merging data I",
    "text": "Merging data I\n\nOften we have two separate datasets with corresponding groups of rows\n\nStreams, trackID in top10_charts.csv and Song metadata, trackID in top10_meta.csv\n\npurchaseid, customerid in noahs-orders.csv and productid, purchaseid in noahs-orders_items.csv and customerid, customer metadata in noahs-customers.csv\n\n\n\nCombine data using joins\n\n\ncharts &lt;- readr::read_csv(\"data/chart_data/top10_charts.csv\")\nsongs &lt;- readr::read_csv(\"data/chart_data/top10_meta.csv\")\nstr(charts, give.attr=FALSE)\n\nspc_tbl_ [7,320 × 7] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n $ trackID  : chr [1:7320] \"012iHyRvQQquWQGUTYvDxy\" \"017PF4Q3l4DBUiWoXk4OWT\" \"017PF4Q3l4DBUiWoXk4OWT\" \"017PF4Q3l4DBUiWoXk4OWT\" ...\n $ rank     : num [1:7320] 7 6 7 7 7 8 9 9 10 10 ...\n $ streams  : num [1:7320] 26234 4276985 3688979 3255639 3478044 ...\n $ day      : Date[1:7320], format: \"2020-08-14\" \"2020-03-27\" ...\n $ dayNumber: num [1:7320] 1318 1178 1179 1180 1181 ...\n $ region   : chr [1:7320] \"at\" \"global\" \"global\" \"global\" ...\n $ isrc     : chr [1:7320] \"DEUM72004523\" \"GBAHT1901303\" \"GBAHT1901303\" \"GBAHT1901303\" ...\n\nstr(songs, give.attr=FALSE)\n\nspc_tbl_ [347 × 29] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n $ trackID              : chr [1:347] \"012iHyRvQQquWQGUTYvDxy\" \"017PF4Q3l4DBUiWoXk4OWT\" \"01I9AEz658sQnQzCL3K3QG\" \"033if6Adj8fwBYsQzHOfQ8\" ...\n $ trackName            : chr [1:347] \"Fall Auf\" \"Break My Heart\" \"HOES UP G'S DOWN\" \"100k Cash\" ...\n $ artistName           : chr [1:347] \"Cro feat. badchieff\" \"Dua Lipa\" \"Shirin David\" \"Capital Bra feat. Samra\" ...\n $ artistIds            : chr [1:347] \"3utZ2yeQk0Z3BCOBWP7Vlu,6GoNVmYCl0yUm4pEp80vn6\" \"6M2wZ9GZgrQXHCFfjv46we\" \"0JBdTCGs111JKKYfLqOEBa\" \"4WZGDpNwrC0vNQyl9QzF7d,6h1s4i4XKIYv4ErDelLDN0\" ...\n $ isrc                 : chr [1:347] \"DEUM72004523\" \"GBAHT1901303\" \"DECE72000379\" \"DECE72000176\" ...\n $ explicit             : num [1:347] 0 0 1 0 0 0 0 1 0 0 ...\n $ trackPopularity      : num [1:347] 64 83 75 71 69 82 70 74 89 79 ...\n $ primary_artistName   : chr [1:347] \"Cro\" \"Dua Lipa\" \"Shirin David\" \"Capital Bra\" ...\n $ primary_artistID     : chr [1:347] \"3utZ2yeQk0Z3BCOBWP7Vlu\" \"6M2wZ9GZgrQXHCFfjv46we\" \"0JBdTCGs111JKKYfLqOEBa\" \"4WZGDpNwrC0vNQyl9QzF7d\" ...\n $ artistIDs            : chr [1:347] \"3utZ2yeQk0Z3BCOBWP7Vlu,6GoNVmYCl0yUm4pEp80vn6\" \"6M2wZ9GZgrQXHCFfjv46we\" \"0JBdTCGs111JKKYfLqOEBa\" \"4WZGDpNwrC0vNQyl9QzF7d,6h1s4i4XKIYv4ErDelLDN0\" ...\n $ albumName            : chr [1:347] \"Fall Auf\" \"Future Nostalgia\" \"HOES UP G'S DOWN\" \"100k Cash\" ...\n $ albumID              : chr [1:347] \"1qdHQo41Vkkgs8HtMk5b96\" \"7fJJK56U9fHixgO0HQkhtI\" \"15Njx2PcwnNsI65fnbM7Pw\" \"5cqwoGrjFr3VKYZ9ZC0eL2\" ...\n $ available_markets    : chr [1:347] \"AD, AE, AL, AR, AT, AU, BA, BE, BG, BH, BO, BR, BY, CA, CH, CL, CO, CR, CY, CZ, DE, DK, DO, DZ, EC, EE, EG, ES,\"| __truncated__ \"AD, AE, AR, AU, BE, BG, BH, BO, BR, CA, CL, CO, CR, CY, CZ, DK, DO, DZ, EC, EE, EG, ES, FI, FR, GB, GR, GT, HK,\"| __truncated__ \"AD, AE, AR, AT, AU, BE, BG, BH, BO, BR, CA, CH, CL, CO, CR, CY, CZ, DE, DK, DO, DZ, EC, EE, EG, ES, FI, FR, GB,\"| __truncated__ \"AD, AE, AR, AT, AU, BE, BG, BH, BO, BR, CA, CH, CL, CO, CR, CY, CZ, DE, DK, DO, DZ, EC, EE, EG, ES, FI, FR, GB,\"| __truncated__ ...\n $ n_available_markets  : num [1:347] 92 76 79 79 87 79 3 79 92 92 ...\n $ releaseDate          : Date[1:347], format: \"2020-08-13\" \"2020-03-27\" ...\n $ releaseDate_precision: chr [1:347] \"day\" \"day\" \"day\" \"day\" ...\n $ danceability         : num [1:347] 0.5 0.73 0.73 0.701 0.84 0.795 0.814 0.774 0.641 0.571 ...\n $ energy               : num [1:347] 0.743 0.729 0.777 0.714 0.648 0.607 0.794 0.805 0.324 0.693 ...\n $ key                  : num [1:347] 2 4 1 10 10 7 7 11 11 6 ...\n $ loudness             : num [1:347] -6.65 -3.43 -6.38 -5.91 -5.54 ...\n $ mode                 : num [1:347] 1 0 0 1 0 1 1 0 1 0 ...\n $ speechiness          : num [1:347] 0.0373 0.0886 0.29 0.524 0.0489 0.23 0.0887 0.302 0.0299 0.0545 ...\n $ acousticness         : num [1:347] 0.307 0.167 0.0455 0.289 0.101 0.128 0.119 0.0509 0.698 0.0054 ...\n $ instrumentalness     : num [1:347] 0.00 1.39e-06 1.10e-03 0.00 1.00e-04 1.90e-01 9.00e-04 0.00 0.00 0.00 ...\n $ liveness             : num [1:347] 0.133 0.349 0.0759 0.0883 0.0996 0.111 0.348 0.149 0.328 0.173 ...\n $ valence              : num [1:347] 0.332 0.467 0.578 0.604 0.431 0.25 0.647 0.261 0.273 0.393 ...\n $ tempo                : num [1:347] 166.3 113 177.9 86.9 103 ...\n $ duration_ms          : num [1:347] 191827 221820 130307 173353 124690 ...\n $ time_signature       : num [1:347] 4 4 4 4 4 4 4 4 4 4 ..."
  },
  {
    "objectID": "01-introduction_to_r.html#merging-data-ii",
    "href": "01-introduction_to_r.html#merging-data-ii",
    "title": "Introduction to R",
    "section": "Merging data II",
    "text": "Merging data II\n\nThe name of the join determines which “ids” are kept\n\nleft_join keeps all rows that have an id in the left dataset\n\ninner_join only keeps rows with ids in both datasets\n\n\ndata1 &lt;- data.frame(group = c('a', 'a', 'b','c'), value = c(1,2,3,4)) # missing group 'd'\ndata2 &lt;- data.frame(group2 = c('a', 'c', 'd'), value2 = factor(c(\"abc\", \"def\", \"ghi\"))) # missing group 'b'\n\nleft_join(data1, data2, by = c(\"group\" = \"group2\"))\n\n  group value value2\n1     a     1    abc\n2     a     2    abc\n3     b     3   &lt;NA&gt;\n4     c     4    def\n\nright_join(data1, data2, by = c(\"group\" = \"group2\"))\n\n  group value value2\n1     a     1    abc\n2     a     2    abc\n3     c     4    def\n4     d    NA    ghi\n\ninner_join(data1, data2, by = c(\"group\" = \"group2\"))\n\n  group value value2\n1     a     1    abc\n2     a     2    abc\n3     c     4    def"
  },
  {
    "objectID": "01-introduction_to_r.html#special-joins",
    "href": "01-introduction_to_r.html#special-joins",
    "title": "Introduction to R",
    "section": "Special joins",
    "text": "Special joins\n\n\nfull_join returns all rows from both datasets\n\nsemi_join returns only the columns of the left dataset and filters rows with id in the right dataset\n\nanti_join keeps only rows that do not have an id in the right table\n\n\nfull_join(data1, data2, by = c(\"group\" = \"group2\"))\n\n  group value value2\n1     a     1    abc\n2     a     2    abc\n3     b     3   &lt;NA&gt;\n4     c     4    def\n5     d    NA    ghi\n\nsemi_join(data1, data2, by = c(\"group\" = \"group2\"))\n\n  group value\n1     a     1\n2     a     2\n3     c     4\n\nfilter(data1, group %in% data2$group2)\n\n  group value\n1     a     1\n2     a     2\n3     c     4\n\nanti_join(data1, data2, by = c(\"group\" = \"group2\"))\n\n  group value\n1     b     3"
  },
  {
    "objectID": "01-introduction_to_r.html#exercise-3",
    "href": "01-introduction_to_r.html#exercise-3",
    "title": "Introduction to R",
    "section": "Exercise",
    "text": "Exercise\n\n\n\nBE the music manager\n\n\n\nWho are the top 10 artists in terms of total global streams?\nWhat is their most succesful song?\nFor how many songs are do we not have meta data?\nHow many songs are there in the data? (Hint: ?n_distinct, or ?length, ?unique)\nSave the combined data as top10_all.parquet"
  },
  {
    "objectID": "01-introduction_to_r.html#references",
    "href": "01-introduction_to_r.html#references",
    "title": "Introduction to R",
    "section": "References",
    "text": "References\nLinks\n\nR Logo\nNoah’s Database\n\nBibliography\n\n\nHorst, Allison Marie, Alison Presmanes Hill, and Kristen B Gorman. 2020. Palmerpenguins: Palmer Archipelago (Antarctica) Penguin Data. https://doi.org/10.5281/zenodo.3960218.\n\n\n\n\n\n\nData Literacy"
  },
  {
    "objectID": "07-predictive_modeling-page.html",
    "href": "07-predictive_modeling-page.html",
    "title": "Predictive Modeling",
    "section": "",
    "text": "Not concerned with causal relationship\n\ncausal model typically worse in terms of prediction\n\nAllows flexible model structure\nGoal: extrapolate well (small error) to unknown outcome given new observed input\nDefinition of “error” (loss) depends on the outcome variable and problem  (e.g., binary \\(\\rightarrow\\) sensitivity/specificity, continuous \\(\\rightarrow\\) squared/absolute error)\nFundamental issue: overfitting\n\nEach observed outcome contains signal and noise\nsignal: part that is associated with inputs\nnoise: additional variation e.g., measurement error, unobserved factors, random nature of outcome\n\nwill be different in new data\n\noverfitting: in addition to the signal the model also picks up on the noise of the data used to “fit” (train) the parameters"
  },
  {
    "objectID": "07-predictive_modeling-page.html#predictive-modeling",
    "href": "07-predictive_modeling-page.html#predictive-modeling",
    "title": "Predictive Modeling",
    "section": "",
    "text": "Not concerned with causal relationship\n\ncausal model typically worse in terms of prediction\n\nAllows flexible model structure\nGoal: extrapolate well (small error) to unknown outcome given new observed input\nDefinition of “error” (loss) depends on the outcome variable and problem  (e.g., binary \\(\\rightarrow\\) sensitivity/specificity, continuous \\(\\rightarrow\\) squared/absolute error)\nFundamental issue: overfitting\n\nEach observed outcome contains signal and noise\nsignal: part that is associated with inputs\nnoise: additional variation e.g., measurement error, unobserved factors, random nature of outcome\n\nwill be different in new data\n\noverfitting: in addition to the signal the model also picks up on the noise of the data used to “fit” (train) the parameters"
  },
  {
    "objectID": "07-predictive_modeling-page.html#bias-variance-tradeoff",
    "href": "07-predictive_modeling-page.html#bias-variance-tradeoff",
    "title": "Predictive Modeling",
    "section": "Bias-variance tradeoff",
    "text": "Bias-variance tradeoff\n source"
  },
  {
    "objectID": "07-predictive_modeling-page.html#a-first-example",
    "href": "07-predictive_modeling-page.html#a-first-example",
    "title": "Predictive Modeling",
    "section": "A first example",
    "text": "A first example\n\nlibrary(modelsummary)\nlibrary(Metrics)\n\nset.seed(42)\nx &lt;- runif(1000, -100, 100)\ny &lt;- 12.5 + 7 * x + rnorm(\n    length(x), mean = 0, sd = 1000\n    )\nmodel_data &lt;- data.frame(x,y)\nmod.ols &lt;- lm(y~x, data = model_data)\nmodelsummary(list(OLS = mod.ols), output=\"markdown\")\n\n\n\n\nOLS\n\n\n\n\n(Intercept)\n-17.447\n\n\n\n(31.640)\n\n\nx\n7.676\n\n\n\n(0.543)\n\n\nNum.Obs.\n1000\n\n\nR2\n0.167\n\n\nR2 Adj.\n0.166\n\n\nAIC\n16656.8\n\n\nBIC\n16671.6\n\n\nLog.Lik.\n-8325.414\n\n\nF\n200.071\n\n\nRMSE\n998.72"
  },
  {
    "objectID": "07-predictive_modeling-page.html#check-for-overfitting-data-prep",
    "href": "07-predictive_modeling-page.html#check-for-overfitting-data-prep",
    "title": "Predictive Modeling",
    "section": "Check for overfitting: data prep",
    "text": "Check for overfitting: data prep\n\nTrain/Test split\n\nUse e.g., 80% of the sample to fit the model and 20% to test its performance on new data\n\nIn real life: do this many times with different splits to see patterns\n\n\nlibrary(rsample)\nsplit_xy &lt;- initial_split(model_data, prop = 0.8)\ntraining_xy &lt;- training(split_xy)\ntesting_xy &lt;- testing(split_xy)\nprint(\"Signal vs. Noise\")\n\n[1] \"Signal vs. Noise\"\n\nsummary(training_xy)\n\n       x                 y           \n Min.   :-99.919   Min.   :-3495.10  \n 1st Qu.:-53.554   1st Qu.: -786.51  \n Median : -3.720   Median :  -60.38  \n Mean   : -1.075   Mean   :  -49.86  \n 3rd Qu.: 51.472   3rd Qu.:  722.85  \n Max.   : 99.698   Max.   : 3155.77  \n\nsummary(testing_xy)\n\n       x                 y           \n Min.   :-99.952   Min.   :-3410.78  \n 1st Qu.:-55.411   1st Qu.: -546.54  \n Median : -5.878   Median :   58.90  \n Mean   : -7.446   Mean   :   22.05  \n 3rd Qu.: 42.628   3rd Qu.:  702.45  \n Max.   : 98.159   Max.   : 3910.81"
  },
  {
    "objectID": "07-predictive_modeling-page.html#check-for-overfitting",
    "href": "07-predictive_modeling-page.html#check-for-overfitting",
    "title": "Predictive Modeling",
    "section": "Check for overfitting",
    "text": "Check for overfitting\n\nCheck for differences in model performance in the training and test samples\nRMSE: Root Mean Squared Error \\(\\sqrt{\\frac{1}{n}\\sum_{i=1}^n (y - \\hat y)^2}\\)\n\n\nmod.ols.train &lt;- lm(y ~ x, data =  training_xy)\nmodelsummary(mod.ols.train, gof_omit = \"R2|IC|Log|F\")\n\n\n\n\n\n (1)\n\n\n\n\n(Intercept)\n−41.424\n\n\n\n(35.892)\n\n\nx\n7.849\n\n\n\n(0.612)\n\n\nNum.Obs.\n800\n\n\nRMSE\n1013.74\n\n\n\n\n\n\nMetrics::rmse(training_xy$y, predict(mod.ols.train))\n\n[1] 1013.745\n\nMetrics::rmse(testing_xy$y, predict(mod.ols.train, testing_xy))\n\n[1] 938.0764"
  },
  {
    "objectID": "07-predictive_modeling-page.html#check-for-overfitting-k-fold-cross-validation",
    "href": "07-predictive_modeling-page.html#check-for-overfitting-k-fold-cross-validation",
    "title": "Predictive Modeling",
    "section": "Check for overfitting: \\(k\\)-fold Cross-Validation",
    "text": "Check for overfitting: \\(k\\)-fold Cross-Validation\n\nShuffle the data\n\nVery flexible models may learn the data ordering\n\nCreate \\(k\\) equally sized non-overlapping test splits\nrun the model \\(k\\) times using a different split as the test set in each run\nSize of each split \\(n/k\\)\n\n source"
  },
  {
    "objectID": "07-predictive_modeling-page.html#lets-overfit",
    "href": "07-predictive_modeling-page.html#lets-overfit",
    "title": "Predictive Modeling",
    "section": "Let’s overfit",
    "text": "Let’s overfit\n\nModel that includes 25 powers of x (de-correlated)\nNow RMSE is worse in the test set: the model learned noise of the training data\n\n\nmod.powers.train &lt;- lm(y ~ poly(x, degrees = 25), data =  training_xy)\n\nMetrics::rmse(training_xy$y, predict(mod.powers.train))\n\n[1] 987.8615\n\nMetrics::rmse(testing_xy$y, predict(mod.powers.train, testing_xy))\n\n[1] 1002.229"
  },
  {
    "objectID": "07-predictive_modeling-page.html#real-example-gradient-boosting",
    "href": "07-predictive_modeling-page.html#real-example-gradient-boosting",
    "title": "Predictive Modeling",
    "section": "Real example: Gradient boosting",
    "text": "Real example: Gradient boosting\nXGBoost\n\nFlexible non-parametric model\nRegularization (i.e., shrinkage) of parameters -&gt; variable selection\nRegularization of model -&gt; prevent overfitting\nScalable algorithm\n\n\n\n\n\n source"
  },
  {
    "objectID": "07-predictive_modeling-page.html#avoid-overfitting",
    "href": "07-predictive_modeling-page.html#avoid-overfitting",
    "title": "Predictive Modeling",
    "section": "Avoid Overfitting",
    "text": "Avoid Overfitting\n\n\n\nWhich paramters does the model have that “restrict” the training?\nProblem:\n\nToo restrictive: underfitting\nToo flexible: overfitting\n\nTune parameters to find the reasonable middle"
  },
  {
    "objectID": "07-predictive_modeling-page.html#model-setup",
    "href": "07-predictive_modeling-page.html#model-setup",
    "title": "Predictive Modeling",
    "section": "Model setup",
    "text": "Model setup\n\nMultiple ways (e.g., library(xgboost))\nHere: use library(tidymodels)\n\nSame interface to many different models\n\n\n\nlibrary(tidymodels)\n\n── Attaching packages ────────────────────────────────────── tidymodels 1.1.1 ──\n\n\n✔ broom        1.0.5     ✔ recipes      1.0.9\n✔ dials        1.2.1     ✔ tibble       3.2.1\n✔ dplyr        1.1.4     ✔ tidyr        1.3.1\n✔ ggplot2      3.4.4     ✔ tune         1.1.2\n✔ infer        1.0.6     ✔ workflows    1.1.4\n✔ modeldata    1.3.0     ✔ workflowsets 1.0.1\n✔ parsnip      1.2.0     ✔ yardstick    1.3.0\n✔ purrr        1.0.2     \n\n\n── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──\n✖ yardstick::accuracy()  masks Metrics::accuracy()\n✖ purrr::discard()       masks scales::discard()\n✖ dplyr::filter()        masks stats::filter()\n✖ dplyr::lag()           masks stats::lag()\n✖ yardstick::mae()       masks Metrics::mae()\n✖ yardstick::mape()      masks Metrics::mape()\n✖ yardstick::mase()      masks Metrics::mase()\n✖ yardstick::precision() masks Metrics::precision()\n✖ yardstick::recall()    masks Metrics::recall()\n✖ yardstick::rmse()      masks Metrics::rmse()\n✖ yardstick::smape()     masks Metrics::smape()\n✖ recipes::step()        masks stats::step()\n• Use suppressPackageStartupMessages() to eliminate package startup messages\n\nlibrary(palmerpenguins)\n\n\nAttaching package: 'palmerpenguins'\n\n\nThe following object is masked from 'package:modeldata':\n\n    penguins\n\nmod.boost &lt;- boost_tree(\n    mode   = \"classification\",\n    engine = \"xgboost\",\n    learn_rate = tune()\n)\nmod.boost\n\nBoosted Tree Model Specification (classification)\n\nMain Arguments:\n  learn_rate = tune()\n\nComputational engine: xgboost"
  },
  {
    "objectID": "07-predictive_modeling-page.html#hyperparamter-tuning-setup",
    "href": "07-predictive_modeling-page.html#hyperparamter-tuning-setup",
    "title": "Predictive Modeling",
    "section": "Hyperparamter tuning setup",
    "text": "Hyperparamter tuning setup\n\nRun the model multiple times using different values for the learning rate\nSelect the one that performs best\n\n\nset.seed(1)\nrandom_lr &lt;- grid_random(\n    extract_parameter_set_dials(mod.boost), \n    size = 10)\nrandom_lr\n\n# A tibble: 10 × 1\n   learn_rate\n        &lt;dbl&gt;\n 1    0.00461\n 2    0.00852\n 3    0.0270 \n 4    0.186  \n 5    0.00319\n 6    0.176  \n 7    0.230  \n 8    0.0449 \n 9    0.0374 \n10    0.00143"
  },
  {
    "objectID": "07-predictive_modeling-page.html#data-setup",
    "href": "07-predictive_modeling-page.html#data-setup",
    "title": "Predictive Modeling",
    "section": "Data setup",
    "text": "Data setup\n\nPredict the penguin species based on the observed data\nNumeric features can be used as they are\nCategorical features have to be encoded into numeric features\n\nmost common: one-hot encoding (indicator function)\nin this case: island, sex\n\n\n\npenguins &lt;- drop_na(penguins)\npenguin_dummies &lt;- recipe(species ~ ., penguins) |&gt;\n    step_dummy(all_nominal_predictors(), one_hot = TRUE)\n# see ?step_dummy for other encoding options\nhead(penguins)\n\n# A tibble: 6 × 8\n  species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n  &lt;fct&gt;   &lt;fct&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n1 Adelie  Torgersen           39.1          18.7               181        3750\n2 Adelie  Torgersen           39.5          17.4               186        3800\n3 Adelie  Torgersen           40.3          18                 195        3250\n4 Adelie  Torgersen           36.7          19.3               193        3450\n5 Adelie  Torgersen           39.3          20.6               190        3650\n6 Adelie  Torgersen           38.9          17.8               181        3625\n# ℹ 2 more variables: sex &lt;fct&gt;, year &lt;int&gt;"
  },
  {
    "objectID": "07-predictive_modeling-page.html#putting-the-setup-together",
    "href": "07-predictive_modeling-page.html#putting-the-setup-together",
    "title": "Predictive Modeling",
    "section": "Putting the setup together",
    "text": "Putting the setup together\n\nCreate a workflow that combines model and data preprocessing\nSet up \\(k\\)-fold cross-validation\n\nHere \\(v\\)-fold for whatever reason but just think \\(k = v\\)\n\nTune the learning rate\n\n\n## Model & data preparation\nspecies_pred_wf &lt;- workflow() |&gt;\n    add_model(mod.boost) |&gt;\n    add_recipe(penguin_dummies)\n## Cross-validation\nspecied_pred_cv &lt;- vfold_cv(penguins, v = 5)\n## Learning rate tuning\nlr_tuning &lt;- tune_grid(\n    species_pred_wf,\n    resamples = specied_pred_cv,\n    grid = random_lr,\n    metrics = metric_set(bal_accuracy),\n    control = control_grid(verbose = FALSE)\n)\nlr_tuning\n\n# Tuning results\n# 5-fold cross-validation \n# A tibble: 5 × 4\n  splits           id    .metrics          .notes          \n  &lt;list&gt;           &lt;chr&gt; &lt;list&gt;            &lt;list&gt;          \n1 &lt;split [266/67]&gt; Fold1 &lt;tibble [10 × 5]&gt; &lt;tibble [0 × 3]&gt;\n2 &lt;split [266/67]&gt; Fold2 &lt;tibble [10 × 5]&gt; &lt;tibble [0 × 3]&gt;\n3 &lt;split [266/67]&gt; Fold3 &lt;tibble [10 × 5]&gt; &lt;tibble [0 × 3]&gt;\n4 &lt;split [267/66]&gt; Fold4 &lt;tibble [10 × 5]&gt; &lt;tibble [0 × 3]&gt;\n5 &lt;split [267/66]&gt; Fold5 &lt;tibble [10 × 5]&gt; &lt;tibble [0 × 3]&gt;"
  },
  {
    "objectID": "07-predictive_modeling-page.html#choosing-the-best-parameter-value",
    "href": "07-predictive_modeling-page.html#choosing-the-best-parameter-value",
    "title": "Predictive Modeling",
    "section": "Choosing the best parameter value",
    "text": "Choosing the best parameter value\n\nCombine the metrics from all CV runs\nSelect the learning rate to use for model training\nUpdate the model & workflow\n\n\nlr_tuning |&gt;\n    collect_metrics() |&gt;\n    arrange(-mean) |&gt;\n    select(learn_rate, mean, std_err)\n\n# A tibble: 10 × 3\n   learn_rate  mean std_err\n        &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;\n 1    0.186   0.989 0.00420\n 2    0.176   0.989 0.00420\n 3    0.230   0.989 0.00420\n 4    0.0449  0.986 0.00510\n 5    0.00461 0.983 0.00504\n 6    0.00852 0.983 0.00504\n 7    0.00319 0.983 0.00504\n 8    0.00143 0.983 0.00504\n 9    0.0270  0.980 0.00494\n10    0.0374  0.980 0.00494\n\n## Select best learning rate\nbest_param &lt;- lr_tuning |&gt;\n    collect_metrics() |&gt;\n    slice_max(mean)\n## Set learning rate for xgboost model\nmod.boost.best1 &lt;- mod.boost |&gt;\n    set_args(learn_rate = best_param$learn_rate[1])\n## Update workflow with new model\nspecies_pred_wf_best1 &lt;- species_pred_wf |&gt;\n    update_model(mod.boost.best1)"
  },
  {
    "objectID": "07-predictive_modeling-page.html#fit-the-final-model",
    "href": "07-predictive_modeling-page.html#fit-the-final-model",
    "title": "Predictive Modeling",
    "section": "Fit the final model",
    "text": "Fit the final model\n\nFit the model and add predictions to the original data\nPlot the confusion matrix (true vs. predicted class counts)\n\n\nlibrary(colorspace)\nset.seed(1)\npenguins$pred &lt;- species_pred_wf_best1 |&gt;\n    fit(penguins) |&gt;\n    predict(penguins) |&gt;\n    pull(.pred_class)\npenguins |&gt;\n    mutate(pred = as.factor(pred)) |&gt;\n    conf_mat(species, pred) |&gt;\n    autoplot(type = 'heatmap') +\n    scale_fill_continuous_sequential(\"Greens\")\n\nScale for fill is already present.\nAdding another scale for fill, which will replace the existing scale."
  },
  {
    "objectID": "07-predictive_modeling-page.html#exercise",
    "href": "07-predictive_modeling-page.html#exercise",
    "title": "Predictive Modeling",
    "section": "Exercise",
    "text": "Exercise\n\n\n\n\n\n\nAvoid overfitting\n\n\n\n\nIn the previous example the same data was used for training and prediction\nImplement a strategy to show that we are not overfitting\nHint: read the Details section of ?initial_split"
  },
  {
    "objectID": "07-predictive_modeling-page.html#solution",
    "href": "07-predictive_modeling-page.html#solution",
    "title": "Predictive Modeling",
    "section": "Solution",
    "text": "Solution\n\nSet the seed to \\(1\\)\n\n\n\nScale for fill is already present.\nAdding another scale for fill, which will replace the existing scale."
  },
  {
    "objectID": "07-predictive_modeling.html#predictive-modeling",
    "href": "07-predictive_modeling.html#predictive-modeling",
    "title": "Predictive Modeling",
    "section": "Predictive modeling",
    "text": "Predictive modeling\n\nNot concerned with causal relationship\n\ncausal model typically worse in terms of prediction\n\n\nAllows flexible model structure\nGoal: extrapolate well (small error) to unknown outcome given new observed input\nDefinition of “error” (loss) depends on the outcome variable and problem  (e.g., binary \\(\\rightarrow\\) sensitivity/specificity, continuous \\(\\rightarrow\\) squared/absolute error)\nFundamental issue: overfitting\n\nEach observed outcome contains signal and noise\n\n\nsignal: part that is associated with inputs\n\nnoise: additional variation e.g., measurement error, unobserved factors, random nature of outcome\n\nwill be different in new data\n\n\n\noverfitting: in addition to the signal the model also picks up on the noise of the data used to “fit” (train) the parameters"
  },
  {
    "objectID": "07-predictive_modeling.html#bias-variance-tradeoff",
    "href": "07-predictive_modeling.html#bias-variance-tradeoff",
    "title": "Predictive Modeling",
    "section": "Bias-variance tradeoff",
    "text": "Bias-variance tradeoff\nsource"
  },
  {
    "objectID": "07-predictive_modeling.html#a-first-example",
    "href": "07-predictive_modeling.html#a-first-example",
    "title": "Predictive Modeling",
    "section": "A first example",
    "text": "A first example\n\n\nlibrary(modelsummary)\nlibrary(Metrics)\n\nset.seed(42)\nx &lt;- runif(1000, -100, 100)\ny &lt;- 12.5 + 7 * x + rnorm(\n    length(x), mean = 0, sd = 1000\n    )\nmodel_data &lt;- data.frame(x,y)\nmod.ols &lt;- lm(y~x, data = model_data)\nmodelsummary(list(OLS = mod.ols), output=\"markdown\")\n\n\n\n\nOLS\n\n\n\n(Intercept)\n-17.447\n\n\n\n(31.640)\n\n\nx\n7.676\n\n\n\n(0.543)\n\n\nNum.Obs.\n1000\n\n\nR2\n0.167\n\n\nR2 Adj.\n0.166\n\n\nAIC\n16656.8\n\n\nBIC\n16671.6\n\n\nLog.Lik.\n-8325.414\n\n\nF\n200.071\n\n\nRMSE\n998.72"
  },
  {
    "objectID": "07-predictive_modeling.html#check-for-overfitting-data-prep",
    "href": "07-predictive_modeling.html#check-for-overfitting-data-prep",
    "title": "Predictive Modeling",
    "section": "Check for overfitting: data prep",
    "text": "Check for overfitting: data prep\n\nTrain/Test split\n\nUse e.g., 80% of the sample to fit the model and 20% to test its performance on new data\n\n\nIn real life: do this many times with different splits to see patterns\n\n\n\nlibrary(rsample)\nsplit_xy &lt;- initial_split(model_data, prop = 0.8)\ntraining_xy &lt;- training(split_xy)\ntesting_xy &lt;- testing(split_xy)\nprint(\"Signal vs. Noise\")\n\n\n[1] \"Signal vs. Noise\"\n\nsummary(training_xy)\n\n       x                 y           \n Min.   :-99.919   Min.   :-3495.10  \n 1st Qu.:-53.554   1st Qu.: -786.51  \n Median : -3.720   Median :  -60.38  \n Mean   : -1.075   Mean   :  -49.86  \n 3rd Qu.: 51.472   3rd Qu.:  722.85  \n Max.   : 99.698   Max.   : 3155.77  \n\nsummary(testing_xy)\n\n       x                 y           \n Min.   :-99.952   Min.   :-3410.78  \n 1st Qu.:-55.411   1st Qu.: -546.54  \n Median : -5.878   Median :   58.90  \n Mean   : -7.446   Mean   :   22.05  \n 3rd Qu.: 42.628   3rd Qu.:  702.45  \n Max.   : 98.159   Max.   : 3910.81"
  },
  {
    "objectID": "07-predictive_modeling.html#check-for-overfitting",
    "href": "07-predictive_modeling.html#check-for-overfitting",
    "title": "Predictive Modeling",
    "section": "Check for overfitting",
    "text": "Check for overfitting\n\nCheck for differences in model performance in the training and test samples\nRMSE: Root Mean Squared Error \\(\\sqrt{\\frac{1}{n}\\sum_{i=1}^n (y - \\hat y)^2}\\)\n\n\n\n\nmod.ols.train &lt;- lm(y ~ x, data =  training_xy)\nmodelsummary(mod.ols.train, gof_omit = \"R2|IC|Log|F\")\n\n\n\n\n\n (1)\n\n\n\n(Intercept)\n−41.424\n\n\n\n(35.892)\n\n\nx\n7.849\n\n\n\n(0.612)\n\n\nNum.Obs.\n800\n\n\nRMSE\n1013.74\n\n\n\n\nMetrics::rmse(training_xy$y, predict(mod.ols.train))\n\n[1] 1013.745\n\nMetrics::rmse(testing_xy$y, predict(mod.ols.train, testing_xy))\n\n[1] 938.0764"
  },
  {
    "objectID": "07-predictive_modeling.html#check-for-overfitting-k-fold-cross-validation",
    "href": "07-predictive_modeling.html#check-for-overfitting-k-fold-cross-validation",
    "title": "Predictive Modeling",
    "section": "Check for overfitting: \\(k\\)-fold Cross-Validation",
    "text": "Check for overfitting: \\(k\\)-fold Cross-Validation\n\nShuffle the data\n\nVery flexible models may learn the data ordering\n\n\nCreate \\(k\\) equally sized non-overlapping test splits\nrun the model \\(k\\) times using a different split as the test set in each run\nSize of each split \\(n/k\\)\n\n\nsource"
  },
  {
    "objectID": "07-predictive_modeling.html#lets-overfit",
    "href": "07-predictive_modeling.html#lets-overfit",
    "title": "Predictive Modeling",
    "section": "Let’s overfit",
    "text": "Let’s overfit\n\nModel that includes 25 powers of x (de-correlated)\nNow RMSE is worse in the test set: the model learned noise of the training data\n\n\nmod.powers.train &lt;- lm(y ~ poly(x, degrees = 25), data =  training_xy)\n\nMetrics::rmse(training_xy$y, predict(mod.powers.train))\n\n[1] 987.8615\n\nMetrics::rmse(testing_xy$y, predict(mod.powers.train, testing_xy))\n\n[1] 1002.229"
  },
  {
    "objectID": "07-predictive_modeling.html#real-example-gradient-boosting",
    "href": "07-predictive_modeling.html#real-example-gradient-boosting",
    "title": "Predictive Modeling",
    "section": "Real example: Gradient boosting",
    "text": "Real example: Gradient boosting\nXGBoost\n\nFlexible non-parametric model\nRegularization (i.e., shrinkage) of parameters -&gt; variable selection\nRegularization of model -&gt; prevent overfitting\nScalable algorithm\n\n\n\n\n\nsource"
  },
  {
    "objectID": "07-predictive_modeling.html#avoid-overfitting",
    "href": "07-predictive_modeling.html#avoid-overfitting",
    "title": "Predictive Modeling",
    "section": "Avoid Overfitting",
    "text": "Avoid Overfitting\n\n\n\nWhich paramters does the model have that “restrict” the training?\nProblem:\n\nToo restrictive: underfitting\nToo flexible: overfitting\n\n\nTune parameters to find the reasonable middle"
  },
  {
    "objectID": "07-predictive_modeling.html#model-setup",
    "href": "07-predictive_modeling.html#model-setup",
    "title": "Predictive Modeling",
    "section": "Model setup",
    "text": "Model setup\n\nMultiple ways (e.g., library(xgboost))\nHere: use library(tidymodels)\n\nSame interface to many different models\n\n\n\n\nlibrary(tidymodels)\nlibrary(palmerpenguins)\nmod.boost &lt;- boost_tree(\n    mode   = \"classification\",\n    engine = \"xgboost\",\n    learn_rate = tune()\n)\nmod.boost\n\nBoosted Tree Model Specification (classification)\n\nMain Arguments:\n  learn_rate = tune()\n\nComputational engine: xgboost"
  },
  {
    "objectID": "07-predictive_modeling.html#hyperparamter-tuning-setup",
    "href": "07-predictive_modeling.html#hyperparamter-tuning-setup",
    "title": "Predictive Modeling",
    "section": "Hyperparamter tuning setup",
    "text": "Hyperparamter tuning setup\n\nRun the model multiple times using different values for the learning rate\nSelect the one that performs best\n\n\n\nset.seed(1)\nrandom_lr &lt;- grid_random(\n    extract_parameter_set_dials(mod.boost), \n    size = 10)\nrandom_lr\n\n\n# A tibble: 10 × 1\n   learn_rate\n        &lt;dbl&gt;\n 1    0.00461\n 2    0.00852\n 3    0.0270 \n 4    0.186  \n 5    0.00319\n 6    0.176  \n 7    0.230  \n 8    0.0449 \n 9    0.0374 \n10    0.00143"
  },
  {
    "objectID": "07-predictive_modeling.html#data-setup",
    "href": "07-predictive_modeling.html#data-setup",
    "title": "Predictive Modeling",
    "section": "Data setup",
    "text": "Data setup\n\nPredict the penguin species based on the observed data\nNumeric features can be used as they are\nCategorical features have to be encoded into numeric features\n\nmost common: one-hot encoding (indicator function)\nin this case: island, sex\n\n\n\n\n\npenguins &lt;- drop_na(penguins)\npenguin_dummies &lt;- recipe(species ~ ., penguins) |&gt;\n    step_dummy(all_nominal_predictors(), one_hot = TRUE)\n# see ?step_dummy for other encoding options\nhead(penguins)\n\n# A tibble: 6 × 8\n  species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n  &lt;fct&gt;   &lt;fct&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n1 Adelie  Torgersen           39.1          18.7               181        3750\n2 Adelie  Torgersen           39.5          17.4               186        3800\n3 Adelie  Torgersen           40.3          18                 195        3250\n4 Adelie  Torgersen           36.7          19.3               193        3450\n5 Adelie  Torgersen           39.3          20.6               190        3650\n6 Adelie  Torgersen           38.9          17.8               181        3625\n# ℹ 2 more variables: sex &lt;fct&gt;, year &lt;int&gt;"
  },
  {
    "objectID": "07-predictive_modeling.html#putting-the-setup-together",
    "href": "07-predictive_modeling.html#putting-the-setup-together",
    "title": "Predictive Modeling",
    "section": "Putting the setup together",
    "text": "Putting the setup together\n\nCreate a workflow that combines model and data preprocessing\nSet up \\(k\\)-fold cross-validation\n\nHere \\(v\\)-fold for whatever reason but just think \\(k = v\\)\n\n\n\nTune the learning rate\n\n\n\n## Model & data preparation\nspecies_pred_wf &lt;- workflow() |&gt;\n    add_model(mod.boost) |&gt;\n    add_recipe(penguin_dummies)\n## Cross-validation\nspecied_pred_cv &lt;- vfold_cv(penguins, v = 5)\n## Learning rate tuning\nlr_tuning &lt;- tune_grid(\n    species_pred_wf,\n    resamples = specied_pred_cv,\n    grid = random_lr,\n    metrics = metric_set(bal_accuracy),\n    control = control_grid(verbose = FALSE)\n)\nlr_tuning\n\n\n# Tuning results\n# 5-fold cross-validation \n# A tibble: 5 × 4\n  splits           id    .metrics          .notes          \n  &lt;list&gt;           &lt;chr&gt; &lt;list&gt;            &lt;list&gt;          \n1 &lt;split [266/67]&gt; Fold1 &lt;tibble [10 × 5]&gt; &lt;tibble [0 × 3]&gt;\n2 &lt;split [266/67]&gt; Fold2 &lt;tibble [10 × 5]&gt; &lt;tibble [0 × 3]&gt;\n3 &lt;split [266/67]&gt; Fold3 &lt;tibble [10 × 5]&gt; &lt;tibble [0 × 3]&gt;\n4 &lt;split [267/66]&gt; Fold4 &lt;tibble [10 × 5]&gt; &lt;tibble [0 × 3]&gt;\n5 &lt;split [267/66]&gt; Fold5 &lt;tibble [10 × 5]&gt; &lt;tibble [0 × 3]&gt;"
  },
  {
    "objectID": "07-predictive_modeling.html#choosing-the-best-parameter-value",
    "href": "07-predictive_modeling.html#choosing-the-best-parameter-value",
    "title": "Predictive Modeling",
    "section": "Choosing the best parameter value",
    "text": "Choosing the best parameter value\n\nCombine the metrics from all CV runs\nSelect the learning rate to use for model training\nUpdate the model & workflow\n\n\n\nlr_tuning |&gt;\n    collect_metrics() |&gt;\n    arrange(-mean) |&gt;\n    select(learn_rate, mean, std_err)\n\n\n# A tibble: 10 × 3\n   learn_rate  mean std_err\n        &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;\n 1    0.186   0.989 0.00420\n 2    0.176   0.989 0.00420\n 3    0.230   0.989 0.00420\n 4    0.0449  0.986 0.00510\n 5    0.00461 0.983 0.00504\n 6    0.00852 0.983 0.00504\n 7    0.00319 0.983 0.00504\n 8    0.00143 0.983 0.00504\n 9    0.0270  0.980 0.00494\n10    0.0374  0.980 0.00494\n\n## Select best learning rate\nbest_param &lt;- lr_tuning |&gt;\n    collect_metrics() |&gt;\n    slice_max(mean)\n## Set learning rate for xgboost model\nmod.boost.best1 &lt;- mod.boost |&gt;\n    set_args(learn_rate = best_param$learn_rate[1])\n## Update workflow with new model\nspecies_pred_wf_best1 &lt;- species_pred_wf |&gt;\n    update_model(mod.boost.best1)"
  },
  {
    "objectID": "07-predictive_modeling.html#fit-the-final-model",
    "href": "07-predictive_modeling.html#fit-the-final-model",
    "title": "Predictive Modeling",
    "section": "Fit the final model",
    "text": "Fit the final model\n\nFit the model and add predictions to the original data\nPlot the confusion matrix (true vs. predicted class counts)\n\n\n\nlibrary(colorspace)\nset.seed(1)\npenguins$pred &lt;- species_pred_wf_best1 |&gt;\n    fit(penguins) |&gt;\n    predict(penguins) |&gt;\n    pull(.pred_class)\npenguins |&gt;\n    mutate(pred = as.factor(pred)) |&gt;\n    conf_mat(species, pred) |&gt;\n    autoplot(type = 'heatmap') +\n    scale_fill_continuous_sequential(\"Greens\")"
  },
  {
    "objectID": "07-predictive_modeling.html#exercise",
    "href": "07-predictive_modeling.html#exercise",
    "title": "Predictive Modeling",
    "section": "Exercise",
    "text": "Exercise\n\n\n\nAvoid overfitting\n\n\n\nIn the previous example the same data was used for training and prediction\nImplement a strategy to show that we are not overfitting\nHint: read the Details section of ?initial_split"
  },
  {
    "objectID": "07-predictive_modeling.html#solution",
    "href": "07-predictive_modeling.html#solution",
    "title": "Predictive Modeling",
    "section": "Solution",
    "text": "Solution\n\nSet the seed to \\(1\\)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nData Literacy"
  },
  {
    "objectID": "canvas/my_favorite_r_package.html#some-hints-citing",
    "href": "canvas/my_favorite_r_package.html#some-hints-citing",
    "title": "PACKAGENAME TITLE",
    "section": "Some Hints: Citing",
    "text": "Some Hints: Citing\n\nIn order to cite a package you can use the BibTex format. A sample file is provided together with this file. You can get a bibtex entry for an R package using\n\n\nprint(citation(\"PACKAGENAME\"), bibtex=TRUE)\n\ne.g.,\n\nprint(citation(\"shrinkDSM\"), bibtex=TRUE)\n\nTo cite package 'shrinkDSM' in publications use:\n\n  Winkler D, Knaus P (2022). _shrinkDSM: Efficient Bayesian Inference\n  for Dynamic Survival Models with Shrinkage_. R package version 0.2.0,\n  &lt;https://CRAN.R-project.org/package=shrinkDSM&gt;.\n\nA BibTeX entry for LaTeX users is\n\n  @Manual{,\n    title = {shrinkDSM: Efficient Bayesian Inference for Dynamic Survival Models with\nShrinkage},\n    author = {Daniel Winkler and Peter Knaus},\n    year = {2022},\n    note = {R package version 0.2.0},\n    url = {https://CRAN.R-project.org/package=shrinkDSM},\n  }\n\n\n\nTypically you have to specify the citation key (before the first ,). E.g.,\n\n@Manual{winkler2022shrinkDSM,\n    title = {shrinkDSM: Efficient Bayesian Inference for Dynamic Survival Models with Shrinkage},\n    ...\n}\n\nYou can cite in Quarto using @citationkey\n\n\n@zeileis2008partykit found… \\(\\rightarrow\\) Zeileis, Hothorn, and Hornik (2008) found…\n… has been shown [@wickham2019tidyverse]\\(\\rightarrow\\) … has been shown (Wickham et al. 2019)\n\n… found in multiple studies [@wickham2019tidyverse; @zeileis2008partykit] \\(\\rightarrow\\) … found in multiple studies (Wickham et al. 2019; Zeileis, Hothorn, and Hornik 2008)\n\n… also in their earlier study [-@wickham2019tidyverse] \\(\\rightarrow\\) … also in their earlier study (2019)\n\n\n[see @wickham2019tidyverse, p. 23] \\(\\rightarrow\\) (see Wickham et al. 2019, 23)\n\n\n@wickham2019tidyverse [p. 23] \\(\\rightarrow\\) Wickham et al. (2019, 23)"
  },
  {
    "objectID": "canvas/my_favorite_r_package.html#some-hints-document-options",
    "href": "canvas/my_favorite_r_package.html#some-hints-document-options",
    "title": "PACKAGENAME TITLE",
    "section": "Some hints: document options",
    "text": "Some hints: document options\n\nThe code on top of this file surrounded by --- is called a yaml-header\n\nThere you can specify the title, subtitle, author, etc.\nIt also defines the format of the presentation: revealJS\n\nAnd links to files used to render the presentation (logo, bibliography)\nFeel free to play around with those options (e.g., change some false to true)\nChange the theme if you want to"
  },
  {
    "objectID": "canvas/my_favorite_r_package.html#adding-figures",
    "href": "canvas/my_favorite_r_package.html#adding-figures",
    "title": "PACKAGENAME TITLE",
    "section": "Adding figures",
    "text": "Adding figures\n\nA figure\nnext\nto\na\nlist"
  },
  {
    "objectID": "canvas/my_favorite_r_package.html#multiple-columns",
    "href": "canvas/my_favorite_r_package.html#multiple-columns",
    "title": "PACKAGENAME TITLE",
    "section": "Multiple Columns",
    "text": "Multiple Columns\n\n\n\nColumn 1 that is wider than columns 2. Here is some more text to force a line break\n\n\n\nColumn 2 that is much narrower"
  },
  {
    "objectID": "canvas/my_favorite_r_package.html#references",
    "href": "canvas/my_favorite_r_package.html#references",
    "title": "PACKAGENAME TITLE",
    "section": "References",
    "text": "References\n\nautomatically printed on the last slide\n\n{.scrollable} after the slide header makes the slide scrollable. E.g.,\n\n## References {.scrollable}\nThe References\n\n\n\n\nPACKAGENAME FOOTER\n\n\n\n\nWickham, Hadley, Mara Averick, Jennifer Bryan, Winston Chang, Lucy D’Agostino McGowan, Romain François, Garrett Grolemund, et al. 2019. “Welcome to the tidyverse.” Journal of Open Source Software 4 (43): 1686. https://doi.org/10.21105/joss.01686.\n\n\nZeileis, Achim, Torsten Hothorn, and Kurt Hornik. 2008. “Model-Based Recursive Partitioning.” Journal of Computational and Graphical Statistics 17 (2): 492–514. https://doi.org/10.1198/106186008X319331."
  },
  {
    "objectID": "05-causal_modeling.html",
    "href": "05-causal_modeling.html",
    "title": "The Causal Pitchfork",
    "section": "",
    "text": "This document deals with a fundamental question of causal inference: Which variables should be included in a causal model? (see Cinelli, Forney, and Pearl 2020) To answer this question two points need to be clear:\n\nIn general each causal model only investigates the causal effect of a single independent variable, \\(x_k\\), on the dependent variable \\(y\\). The coefficients associated with all other variables, \\(x_{j\\neq k}\\), cannot (automatically) be interpreted as causal relationships. As regression coefficients are commonly presented in a single table, it is often unclear to the reader which coefficients can be interpreted as causal (see Westreich and Greenland 2013).\nStatistical significance (or any other statistical test) does not give us any idea about the causal model. To illustrate this, the following figure shows three statistically significant relationships between the variables \\(x\\) and \\(y\\) (all t-stats \\(&gt; 9\\)). However, by construction there is no causal relationship between them in two of these examples. Even more concerning: In one case the exclusion of a control variable leads to spurious correlation (leftmost plot) while in the other the inclusion of the control variable does the same (rightmost plot).\n\n\n\nCode\nlibrary(tidyverse)\nlibrary(patchwork)\nset.seed(11)\n## Fork\n# n ... number of observations\nn &lt;- 500\n# d ... binary confounder\nd &lt;- rbinom(n, 1, 0.5)\nx &lt;- 1.5 * d + rnorm(n)\ny &lt;- 0.4 + 2 * d + rnorm(n)\ndata_fork &lt;- data.frame(x, y, d = factor(d, levels = c(0, 1), labels = c(\"Yes\", \"No\")))\nplt_fork &lt;- ggplot(data_fork, aes(x, y)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = FALSE) +\n  theme_minimal() +\n  ggtitle(\"Relation due to omitted confounder\")\n## Pipe\nset.seed(11)\nx &lt;- 1 * rnorm(n)\nz &lt;- rbinom(n, 1, boot::inv.logit(2 * x + rnorm(n)))\ny &lt;- 2 * z + rnorm(n)\ndata_pipe &lt;- data.frame(x, z = factor(z, levels = c(0, 1), labels = c(\"Yes\", \"No\")), y)\nplt_pipe &lt;- ggplot(data_pipe, aes(x, y)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = FALSE) +\n  theme_minimal() +\n  ggtitle(\"Relation through mediator\")\n## Collider\nset.seed(11)\nx &lt;- rnorm(n)\ny &lt;- rnorm(n)\na &lt;- rbinom(n, 1, boot::inv.logit(9 * x - 9 * y + rnorm(n)))\ndata_collider &lt;- data.frame(x, y, a = factor(a, levels = c(0, 1), labels = c(\"No\", \"Yes\")))\ndata_collider$x_a &lt;- resid(lm(x ~ 0 + a))\ndata_collider$y_a &lt;- resid(lm(y ~ 0 + a))\nplt_collider &lt;- ggplot(data_collider, aes(x_a, y_a)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = FALSE) +\n  theme_minimal() +\n  labs(x = \"x\", y = \"y\") +\n  theme(legend.position = \"top\") +\n  ggtitle(\"Relation due to included collider\")\nplt_fork + plt_pipe + plt_collider"
  },
  {
    "objectID": "05-causal_modeling.html#omitted-variable-bias-ovb",
    "href": "05-causal_modeling.html#omitted-variable-bias-ovb",
    "title": "The Causal Pitchfork",
    "section": "Omitted Variable Bias (OVB)",
    "text": "Omitted Variable Bias (OVB)\nRecall that variables that influence both the outcome and other independent variables will bias the coefficients of those other independent variables if left out of a model. This bias is referred to as “Omitted Variable Bias” (short OVB) since it occurs due to the omission of a crucial variable. OVB occurs whenever a confounder (see The Fork) is left out of the model. The magnitude of the bias depends on how strongly correlated the confounder is with the included variable \\(x\\). To illustrate this take a look at the equations representing the situation in The Fork:\n\\[\n\\begin{aligned}\nx &= \\alpha_0 + \\alpha_1 d + \\varepsilon_x \\\\\ny &= \\beta_0 + \\beta_1 d + \\varepsilon_y\n\\end{aligned}\n\\]\nHowever, we might be unaware of the confounder \\(d\\) but still be interested in the causal effect of \\(x\\) on \\(y\\). Therefore, we might be inclined to estimate the following (misspecified) model\n\\[\ny = \\gamma_0 + \\gamma_1 x + \\epsilon_y\n\\] We know (based on the equations above) that the true effect of \\(x\\) on \\(y\\) is \\(0\\) as it is entirely caused by \\(d\\). In order to investigate the magnitude of the OVB we mistakenly view \\(d\\) as a function of \\(x\\) (see Mediation analysis):\n\\[\nd = \\theta_0 + \\theta_1 x + \\varepsilon_d,\n\\]\nplug the incorrectly specified model for \\(d\\) into the correctly specified model for \\(y\\), and take the derivative with respect to \\(x\\):\n\\[\n\\begin{aligned}\ny &= \\tilde \\beta_0 + \\beta_1 (\\theta_0 + \\theta_1 x + \\varepsilon_d) + \\epsilon_y \\\\\n  &= \\tilde \\beta_0 + \\beta_1 \\theta_0 + \\beta_1 \\theta_1 x + \\beta_1 \\varepsilon_d + \\epsilon_y \\\\\n{\\delta \\over \\delta x}  &= \\beta_1 \\theta_1\n\\end{aligned}\n\\]\nNote that \\(\\gamma_1 = \\beta_1 \\theta_1\\).\n\nlibrary(stargazer)\nset.seed(11)\nd &lt;- 100 * rnorm(n)\nx &lt;- -4 + 0.5 * d + 10 * rnorm(n)\ny &lt;- 25 + 10 * d + 10 * rnorm(n)\nstargazer(\n  lm(y ~ d + x),\n  lm(y ~ x), ## gamma\n  lm(y ~ d), ## beta\n  lm(d ~ x), ## theta\n  type = 'html')\n\n\n\n\n\n\n\n\n\nDependent variable:\n\n\n\n\n\n\n\n\n\n\n\n\ny\n\n\nd\n\n\n\n\n\n\n(1)\n\n\n(2)\n\n\n(3)\n\n\n(4)\n\n\n\n\n\n\n\n\nd\n\n\n9.996***\n\n\n\n\n9.997***\n\n\n\n\n\n\n\n\n(0.023)\n\n\n\n\n(0.005)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nx\n\n\n0.003\n\n\n19.096***\n\n\n\n\n1.910***\n\n\n\n\n\n\n(0.046)\n\n\n(0.173)\n\n\n\n\n(0.017)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nConstant\n\n\n24.889***\n\n\n97.282***\n\n\n24.878***\n\n\n7.242***\n\n\n\n\n\n\n(0.488)\n\n\n(8.789)\n\n\n(0.456)\n\n\n(0.878)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nObservations\n\n\n500\n\n\n500\n\n\n500\n\n\n500\n\n\n\n\nR2\n\n\n1.000\n\n\n0.961\n\n\n1.000\n\n\n0.961\n\n\n\n\nAdjusted R2\n\n\n1.000\n\n\n0.961\n\n\n1.000\n\n\n0.961\n\n\n\n\nResidual Std. Error\n\n\n10.204 (df = 497)\n\n\n195.949 (df = 498)\n\n\n10.193 (df = 498)\n\n\n19.576 (df = 498)\n\n\n\n\nF Statistic\n\n\n2,343,560.000*** (df = 2; 497)\n\n\n12,212.740*** (df = 1; 498)\n\n\n4,696,511.000*** (df = 1; 498)\n\n\n12,242.150*** (df = 1; 498)\n\n\n\n\n\n\n\n\nNote:\n\n\np&lt;0.1; p&lt;0.05; p&lt;0.01\n\n\n\n## See coef of regression y ~ x\nbeta1 &lt;- coef(lm(y~d))['d']\ntheta1 &lt;- coef(lm(d~x))['x']\nbeta1 * theta1\n   d \n19.09598\n\nNotice that without theoretical knowledge about the data it is not clear which variable should be the “outcome” and which the “independent” variable since we could estimate either direction using OLS. In the example above we know (“from theory”) that \\(d\\) causes \\(x\\) and \\(y\\) but we estimate models where \\(x\\) is the explanatory variable. As one might guess there is a clear relationship between coefficients estimated with one or the other variable on the left hand side.\n\ntheta_1 &lt;- coef(lm(d~x))['x']\nalpha_1 &lt;- coef(lm(x~d))['d']\n\nTo be exact we have to adjust for the respective variances of the variables:\n\nalpha_1 * var(d)/var(x)\n\n       d \n1.910091 \n\ntheta_1\n\n       x \n1.910091"
  },
  {
    "objectID": "05-causal_modeling.html#mediation-analysis",
    "href": "05-causal_modeling.html#mediation-analysis",
    "title": "The Causal Pitchfork",
    "section": "Mediation analysis",
    "text": "Mediation analysis\nAs the total causal effect a variable \\(x\\) has on the outcome \\(y\\) can be (partly) mediated through another variable \\(m\\), we cannot just include \\(m\\) in the model. However, we can decompose the effect into a direct and mediated part. Either of part can be \\(0\\) but we can easily test whether that is the case. The decomposition has two parts: First, calculate the effect the variable of interest (\\(x\\)) has on the mediator (\\(m\\)):\n\\[\nm = \\alpha_0 + \\alpha_1 x + \\varepsilon_m\n\\]\nNote that we use “alpha” (\\(\\alpha\\)) for the regression coefficients to distinguish them from the parameters below. They can nonetheless be estimated using OLS.\nSecond, calculate the full model for the outcome (\\(y\\)) including both \\(x\\) and \\(m\\):\n\\[\ny = \\beta_0 + \\beta_1 x + \\beta_2 m + \\varepsilon_y\n\\]\nNow \\(\\beta_1\\) is the average direct effect (ADE) of \\(x\\) on \\(y\\). That is the part that is not mediated through \\(m\\). In The Pipe, \\(\\beta_1=0\\) since there is no direct connection from \\(x\\) to \\(y\\). The average causal mediation effect (ACME) can be calculated as \\(\\alpha_1 * \\beta_2\\). Intuitively, “how much would a unit increase in \\(x\\) change \\(m\\)” times “how much would an increase in \\(m\\) change \\(y\\)”. The total effect of \\(x\\) on \\(y\\) can be seen more clearly by plugging in the model for \\(m\\) in the second equation and taking the derivative with respect to \\(x\\):\n\\[\n\\begin{aligned}\ny &= \\beta_0 + \\beta_1 x + \\beta_2 m + \\varepsilon_y \\\\\n  &= \\beta_0 + \\beta_1 x + \\beta_2 (\\alpha_0 + \\alpha_1 x + \\varepsilon_m) + \\varepsilon_y \\\\\n  &= \\beta_0 + \\beta_1 x + \\beta_2 \\alpha_0 + \\beta_2 \\alpha_1 x + \\beta_2 \\varepsilon_m + \\varepsilon_y \\\\\n\\text{total effect} := \\frac{\\delta y}{\\delta x} &= \\underbrace{\\beta_1}_{\\text{ADE}} + \\underbrace{\\beta_2 \\alpha_1}_{\\text{ACME}}\n\\end{aligned}\n\\]\nNote that if we are only interested in the total effect we can omit the mediator \\(m\\) from the model and estimate:\n\\[\ny = \\gamma_0 + \\gamma_1 x + \\epsilon_y\n\\] where \\(\\gamma_1 = \\beta_1 + \\beta_2 \\alpha_1\\) (again: all these equations can be estimated using OLS). In that case we are using OVB in our favor: By omitting \\(m\\) its effect on \\(y\\) is picked up by \\(x\\) to exactly the degree that \\(x\\) and \\(m\\) are correlated. However, in contrast to the previous example that is exactly what we want since \\(m\\) is caused by \\(x\\) as well!\nNotable changes to The Pipe:\n\nWe have both direct and indirect effects of \\(x\\) on \\(y\\)\nThe mediator \\(m\\) is continuous instead of binary\n\n\n\nCode\nmed2 &lt;- dagify(m ~ x, y ~ m + x,\n  coords = list(x = c(x = 1, m = 1.5, y = 2), y = c(x = 1, y = 1, m = 1.5))\n) |&gt;\n  tidy_dagitty() |&gt;\n  mutate(fill = ifelse(name == \"m\", \"Mediator\", \"variables of interest\")) |&gt;\n  ggplot(aes(x = x, y = y, xend = xend, yend = yend)) +\n  geom_dag_point(size = 7, aes(color = fill)) +\n  geom_dag_edges(show.legend = FALSE) +\n  geom_dag_text() +\n  theme_dag() +\n  theme(\n    legend.title = element_blank(),\n    legend.position = \"top\"\n  )\nmed2\n\n\n\n\n\n\n\n\n\n\nset.seed(11)\nX &lt;- 100 * rnorm(n)\nM &lt;- 10 + 0.5 * X + 5 * rnorm(n)\nY &lt;- -25 + 4 * X + 3 * M + 10 * rnorm(n)\nX_on_M &lt;- lm(M ~ X)\navg_direct_effect &lt;- lm(Y ~ X + M)\ntotal_effect &lt;- lm(Y ~ X)\nstargazer(\n  X_on_M, \n  avg_direct_effect, \n  total_effect, \n  type = 'html')\n\n\n\n\n\n\n\n\n\nDependent variable:\n\n\n\n\n\n\n\n\n\n\n\n\nM\n\n\nY\n\n\n\n\n\n\n(1)\n\n\n(2)\n\n\n(3)\n\n\n\n\n\n\n\n\nX\n\n\n0.502***\n\n\n3.995***\n\n\n5.502***\n\n\n\n\n\n\n(0.002)\n\n\n(0.046)\n\n\n(0.008)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nM\n\n\n\n\n3.006***\n\n\n\n\n\n\n\n\n\n\n(0.091)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nConstant\n\n\n10.102***\n\n\n-25.181***\n\n\n5.182***\n\n\n\n\n\n\n(0.225)\n\n\n(1.026)\n\n\n(0.815)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nObservations\n\n\n500\n\n\n500\n\n\n500\n\n\n\n\nR2\n\n\n0.990\n\n\n1.000\n\n\n0.999\n\n\n\n\nAdjusted R2\n\n\n0.990\n\n\n1.000\n\n\n0.999\n\n\n\n\nResidual Std. Error\n\n\n5.023 (df = 498)\n\n\n10.204 (df = 497)\n\n\n18.218 (df = 498)\n\n\n\n\nF Statistic\n\n\n48,670.140*** (df = 1; 498)\n\n\n710,360.500*** (df = 2; 497)\n\n\n445,339.400*** (df = 1; 498)\n\n\n\n\n\n\n\n\nNote:\n\n\np&lt;0.1; p&lt;0.05; p&lt;0.01\n\n\n\n\n\navg_causal_mediation_effect &lt;- coef(X_on_M)['X'] * coef(avg_direct_effect)['M']\ntotal_effect_alternative &lt;- coef(avg_direct_effect)['X'] + avg_causal_mediation_effect\nproportion_mediated &lt;- avg_causal_mediation_effect / total_effect_alternative\n\n\n\nCode\nmediation_effects &lt;- tribble(\n        ~effect,                                  ~value,\n        \"Average Causal Mediation Effect (ACME):\", avg_causal_mediation_effect,\n        \"Average Direct Effect (ADE):\",            coef(avg_direct_effect)['X'],\n        \"Total Effect:\",                           coef(total_effect)['X'],\n        \"Total Effect (alternative):\",             total_effect_alternative,\n        \"Proportion Mediated:\",                    proportion_mediated)\n\ngt(mediation_effects, rowname_col = 'effect')  |&gt;\n  tab_options(column_labels.hidden = TRUE) |&gt;\n  fmt_number(columns = value, decimals = 3) |&gt;\n  tab_header(title = \"Causal Mediation Analysis\")\n\n\n\n\n\n\n\n\nCausal Mediation Analysis\n\n\n\n\nAverage Causal Mediation Effect (ACME):\n1.508\n\n\nAverage Direct Effect (ADE):\n3.995\n\n\nTotal Effect:\n5.502\n\n\nTotal Effect (alternative):\n5.502\n\n\nProportion Mediated:\n0.274\n\n\n\n\n\n\n\nAlternatively, the mediation analysis can be performed using the mediation package:\n\nlibrary(mediation)\nmediation_result &lt;- mediate(X_on_M, avg_direct_effect, \n                            treat = 'X', mediator = 'M',\n                            boot = TRUE, sims = 1000)\nsummary(mediation_result)\n\n\nCausal Mediation Analysis \n\nNonparametric Bootstrap Confidence Intervals with the Percentile Method\n\n               Estimate 95% CI Lower 95% CI Upper p-value    \nACME              1.508        1.421         1.60  &lt;2e-16 ***\nADE               3.995        3.901         4.08  &lt;2e-16 ***\nTotal Effect      5.502        5.486         5.52  &lt;2e-16 ***\nProp. Mediated    0.274        0.258         0.29  &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nSample Size Used: 500 \n\n\nSimulations: 1000 \n\n\n\nEstimation using Process\nIn research settings the PROCESS macro by Andrew Hayes is very popular. The following code should download and source the macro for you but will definitely break in the future (try changing the v42 part of the link to v43 or v44 etc. or obtain a new link from the website if it does):\n\ntemp &lt;- tempfile()\ndownload.file(\"https://www.afhayes.com/public/processv42.zip\",temp)\nfiles &lt;- unzip(temp, list = TRUE)\nfname &lt;- files$Name[endsWith(files$Name, \"process.R\")]\nsource(unz(temp, fname))\nunlink(temp)\n\nAlternatively download the program from here and source the process.R file manually.\nPROCESS model 4 (not run):\n\nprocess(data.frame(Y, X, M), y = 'Y', x = 'X', m = 'M', model = 4)"
  },
  {
    "objectID": "05-causal_modeling.html#the-fork",
    "href": "05-causal_modeling.html#the-fork",
    "title": "The Causal Pitchfork",
    "section": "The Fork",
    "text": "The Fork\n\n## Make code reproducible\nset.seed(11)\n## Number of observations\nn &lt;- 1500\n## Random draw from Bernoulli with p(1) = 0.5, p(0) = 0.5\nd &lt;- rbinom(n, 1, 0.5)\n## X is caused by d\nx &lt;- 2 * d + rnorm(n)\n## y is caused by d\ny &lt;- 0.4 + 2.5 * d + rnorm(n)\nfork &lt;- data.frame(x, y, d = factor(d,\n  levels = c(0, 1),\n  labels = c(\"No\", \"Yes\")\n))\nggplot(fork, aes(x, y, color = d)) +\n  geom_point() +\n  theme_minimal() +\n  theme(legend.position = \"top\")"
  },
  {
    "objectID": "05-causal_modeling.html#the-pipe",
    "href": "05-causal_modeling.html#the-pipe",
    "title": "The Causal Pitchfork",
    "section": "The Pipe",
    "text": "The Pipe\n\n\nCode\n## Generate random X\nx &lt;- rnorm(n)\n## inv.logit ensures that values are between 0 and 1\nggplot(data.frame()) +\n  stat_function(fun = boot::inv.logit, xlim = c(-10, 10)) +\n  theme_minimal() +\n  labs(title = \"Inverse Logit function\", x = \"x\", y = \"inv.logit(x)\")\n\n\n\n\n\n\n\n\n\n\n\nCode\n## z is caused by X\nz &lt;- rbinom(n, 1, boot::inv.logit(2 * x + rnorm(n)))\n## y is caused by z\ny &lt;- 2 * z + rnorm(n)\npipe &lt;- data.frame(x, y, z = factor(z,\n  levels = c(0, 1),\n  labels = c(\"Yes\", \"No\")\n))\nggplot(pipe, aes(x, y, color = z)) +\n  geom_point() +\n  theme_minimal() +\n  theme(legend.position = \"top\")"
  },
  {
    "objectID": "05-causal_modeling.html#the-collider",
    "href": "05-causal_modeling.html#the-collider",
    "title": "The Causal Pitchfork",
    "section": "The Collider",
    "text": "The Collider\n\n\nCode\n## Generate random x\nx &lt;- rnorm(n)\n## Generate random y\ny &lt;- rnorm(n)\n## a is caused by both X and y\na &lt;- rbinom(n, 1, boot::inv.logit(9 * x - 9 * y + rnorm(n)))\ncollider &lt;- data.frame(x, y, a = factor(a,\n  levels = c(0, 1),\n  labels = c(\"No\", \"Yes\")\n))\nggplot(collider, aes(x, y)) +\n  geom_point() +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\nIn order to get the partial correlation of \\(X\\) and \\(y\\) after accounting for \\(a\\) we first regress both \\(X\\) and \\(y\\) on \\(a\\) and use the unexplained part (residual) in the plot. This is equivalent to a regression that has both \\(X\\) and \\(a\\) as explanatory variables.\n\n\nCode\ncollider$x_a &lt;- residuals(lm(x ~ 0 + a))\ncollider$y_a &lt;- residuals(lm(y ~ 0 + a))\nggplot(collider, aes(x_a, y_a)) +\n  geom_point() +\n  theme_minimal() +\n  labs(x = \"x after accounting for a\", y = \"y after accounting for a\")"
  },
  {
    "objectID": "06-did-page.html",
    "href": "06-did-page.html",
    "title": "Potential Outcomes and DiD",
    "section": "",
    "text": "Two groups\n\nCountries\nCompanies\nIndividuals\netc.\n\nTwo periods\nGroup \\(g=2\\) receives treatment between period \\(1\\) and \\(2\\)\nGroup \\(g=\\infty\\) never receives the treatment (at least in the observation period)\nNo randomization but: “Quasi-Experiment”, “Natural Experiment”\n\n. . .\n\nGoal: identification of a causal average treatment effect on the treated (ATT)\nCore Assumption: parallel trends\n\n\n\n\n\n\nCode\nlibrary(dplyr)\n\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\n\nCode\ny_j &lt;- c(0.5, 1, 1.8)\ny_j_counter &lt;- c(0.5, 1, 1.5)\ny_k &lt;- c(0.2, 0.7, 1.2)\nx &lt;- c(1,2,3)\nplot(\n    x, y_k, \n    type = \"l\", \n    ylim = c(0, 2),\n    xaxt = \"n\", yaxt = \"n\",\n    ylab = \"Y\", xlab = \"Period\", \n    bty= \"n\"\n    )\naxis(side=2, labels = FALSE, at = NULL)\naxis(side=1, at=c(1,3), labels=c(\"1\",  \"2\"))\nlines(x, y_j)\nlines(x[2:3], y_j_counter[2:3], lty = 2, col = \"red\")\nlines(c(3, 3), c(1.5, 1.8), col = \"darkgreen\")\nabline(v = 2, lty = 4, col = \"gray30\")\ntext(\n    x = 1.5, y = 0.6, \n    labels = \"Parallel pre-treatment\", \n    cex=1.5, srt = 17\n    )\ntext(\n    x = 2.2, y = 1.7, \n    labels = \"Treatment\",\n    cex=1.5, col = \"gray30\"\n    )\ntext(\n    x = 2.5, y = 1.3, \n    labels = \"Counterfactual\",\n    col = \"red\", srt = 17\n    )\ntext(\n    x = 2.9, y = 1.6,\n    labels = \"+Effect\",\n    col = \"darkgreen\"\n    )\ngrid()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\(Y_{i,t}\\) … outcome of unit \\(i\\) at time \\(t\\)\n\n\n\n\n\n\\(Y_{i,t}(0)\\) … \\(Y_{i,t}\\) given \\(i\\) is not treated at \\(t\\)\n\\(Y_{i,t}(1)\\) … \\(Y_{i,t}\\) give \\(i\\) is treated at \\(t\\)\nObserved: \\(Y_{i,t} = \\mathbb{1}(treated_{i,t}) Y_{i,t}(1) + \\left[1 - \\mathbb{1}(treated_{i,t})\\right] Y_{i,t}(0)\\)\nIndividual treatment effect: \\(\\tau_{i,t} = Y_{i,t}(1) - Y_{i,t}(0)\\)\n\n\n\n\n\n\n\n\\(Y_{i,t}\\) … outcome of unit \\(i\\) at time \\(t\\)\n\n\n\n\n\\(Y_{i,t}(0)\\) … \\(Y_{i,t}\\) given \\(i\\) is not treated at \\(t\\)\n\\(Y_{i,t}(1)\\) … \\(Y_{i,t}\\) give \\(i\\) is treated at \\(t\\)\nObserved: \\(Y_{i,t} = \\mathbb{1}(treated_{i,t}) Y_{i,t}(1) + \\left[1 - \\mathbb{1}(treated_{i,t})\\right] Y_{i,t}(0)\\)\nIndividual treatment effect: \\(\\tau_{i,t} = Y_{i,t}(1) - Y_{i,t}(0)\\)\n\n\n\n\nGroup\nt = 1\nt = 2\n\n\n\n\n\\(g = 2\\)\n\\(Y_{i,1}(0)\\)\n\\(Y_{i, 2}(1)\\)\n\n\n\\(g = \\infty\\)\n\\(Y_{j,1}(0)\\)\n\\(Y_{j, 2}(0)\\)\n\n\n\n\n\n\n\n\n\\(\\bar Y_{g=k, t}\\)… average outcome of group \\(k\\) at time \\(t\\)\n\\(\\delta_{g=\\cdot}\\)… trend of the outcome for \\(g = \\cdot\\)\n\\(\\delta_{g=\\cdot} = \\delta\\) for \\(g = 2\\) and \\(g = \\infty\\) under parallel trends\n\n. . .\n\\[\n\\begin{aligned}\n\\bar Y_{g=2, 2} - \\bar Y_{g=2, 1} &= \\delta_{g=2} + \\tau_{g=2} \\\\\n\\bar Y_{g=2, 2} - \\bar Y_{g=2, 1} &=  \\bar Y_{g=\\infty, 2} - \\bar Y_{g=\\infty, 1} + \\tau_{g=2} \\\\\n\\left[\\bar Y_{g=2, 2} - \\bar Y_{g=2, 1}\\right] - \\left[\\bar Y_{g=\\infty, 2} - \\bar Y_{g=\\infty, 1}\\right] &= \\tau_{g=2}\n\\end{aligned}\n\\]\n\n\n\n\n\nCode\nset.seed(1)\nn_obs &lt;- 1000\nunits &lt;- rep(1:(n_obs/2), each = 2)\nunit_fe &lt;- runif(n_obs/2, 0, 20)\nperiod &lt;- rep(c(0,1), n_obs/2)\nperiod_fe &lt;- rep(c(20, 10), n_obs/2)\ntreatment &lt;- rbinom(n_obs/2, 1, 0.5)\ny &lt;- 5 * treatment[units] * period + # tau = 5\n    period_fe + # time fixed effect\n    unit_fe[units] - # unit fixed effect\n    15 * treatment[units] + # constant diff treated/untreated\n    rnorm(n_obs)\ndata &lt;- data.frame(\n    y = y, \n    treated = treatment[units], \n    period = period, \n    unit = as.factor(units))\ny_j &lt;- aggregate(y ~ period, data[data$treated == 1, ], mean)$y\ny_k &lt;- aggregate(y ~ period, data[data$treated == 0, ], mean)$y\ndelta_y_k &lt;- diff(y_k)\ny_k &lt;- c(\n    y_k[1],\n    y_k[1] + delta_y_k/2,\n    y_k[1] + delta_y_k)\ny_j &lt;- c(\n    y_j[1],\n    y_j[1] + delta_y_k/2, # assumed\n    y_j[2])\ny_j_counter &lt;- c(\n    y_j[1], \n    y_j[1] + delta_y_k/2,\n    y_j[1] + delta_y_k) # assumed\nboxplot(\n    y ~ \n    factor(\n        period, levels = c(0,1),\n        labels = c(\"t: 1\",\"t: 2\")\n        ) +\n    factor(\n        treated, levels = c(0,1), \n        labels = c(\"D\", \"A\")\n        ), \n    xlab = \"\", ylab = \"Y\",\n    frame.plot = F,\n    col = \"white\", sep = \" in \",\n    main = \"Household income\",\n    data)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nplot(\n    x, y_k, \n    type = \"l\", \n    ylim = c(0, 35),\n    xaxt = \"n\", #yaxt = \"n\",\n    ylab = \"Avg. availabe household income\", xlab = \"Period\", \n    bty= \"n\"\n    )\naxis(side=1, at=c(1,3), labels=c(\"1\",  \"2\"))\nlines(x, y_j)\nlines(x[2:3], y_j_counter[2:3], lty = 2, col = \"red\")\nlines(c(3, 3), c(y_j[3], y_j_counter[3]), col = \"darkgreen\")\nabline(v = 2, lty = 4, col = \"gray30\")\ntext(x = 1.1, y = 31, labels = \"D\", cex=1.5)\ntext(x = 1.1, y = 16, labels = \"A\", cex=1.5)\ntext(\n    x = 1.5, y = 20, \n    labels = \"Parallel pre-treatment\", \n    cex=1.5, srt = -10\n    )\ntext(\n    x = 2.25, y = 28, \n    labels = \"\\\"Klimabonus\\\"\",\n    cex=1.5, col = \"gray30\"\n    )\ntext(\n    x = 2.5, y = 6.8, \n    labels = \"Counterfactual\",\n    col = \"red\", srt = -10\n    )\ntext(\n    x = 2.90, y = 7.8,\n    labels = \"+Effect\",\n    col = \"darkgreen\"\n    )\ngrid()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\[\n\\begin{aligned}\ny_{i, t} &= \\tau_{did}\\ \\mathbb{1}(\\text{treated}_{i, t}) + \\gamma_t + \\alpha_i + \\epsilon_{i,t} \\\\\n\\mathbb{1}(\\text{treated}_{i,t}) &\\equiv \\mathbb{1}(i \\in \\text{A}) \\times \\mathbb{1}(t = 2)\n\\end{aligned}\n\\]\n\n\n\n\\[\ny_{i, t} = \\tau_{did} \\mathbb{1}(\\text{treated}_{i,t}) + \\beta_1 \\mathbb{1}(i \\in \\text{A}) + \\beta_2 \\mathbb{1}(t = 2) + \\alpha + \\varepsilon_{i,t}\n\\]\nTypically \\(\\sigma_{\\epsilon_{i,t}} &lt; \\sigma_{\\varepsilon_{i,t}}\\)\n\n\n\n\n\nCode\nlibrary(fixest)\nlibrary(pander)\n\netable(list(\n    `TWFE` = feols(y ~ treated:period | unit + period, data),\n    `Dummy` = feols(y ~ treated * period, data)),\n    postprocess.df = pandoc.table.return,\n    style = \"rmarkdown\")\n\n\n\n\n \nTWFE\nDummy\n\n\n\n\nDependent Var.:\ny\ny\n\n\n\n\n\n\n\ntreated x period\n5.064*** (0.1266)\n5.064*** (0.7296)\n\n\nConstant\n\n29.67*** (0.3648)\n\n\ntreated\n\n-14.56*** (0.5159)\n\n\nperiod\n\n-10.03*** (0.5159)\n\n\nFixed-Effects:\n—————–\n——————\n\n\nunit\nYes\nNo\n\n\nperiod\nYes\nNo\n\n\n________________\n_________________\n__________________\n\n\nS.E. type\nby: unit\nIID\n\n\nObservations\n1,000\n1,000\n\n\nR2\n0.99413\n0.61016\n\n\nWithin R2\n0.76267\n–\n\n\n\n\n\n\n\n\nCode\ndid_data_staggered &lt;- data.table::fread(\"https://raw.githubusercontent.com/WU-RDS/RMA2022/main/data/did_data_staggered.csv\")\ndid_data_staggered$song_id &lt;- as.character(did_data_staggered$song_id)\ndid_data_staggered$week &lt;- as.Date(did_data_staggered$week)\ndid_data_staggered$week_num &lt;- as.numeric(\n    factor(\n        did_data_staggered$week, \n        levels = sort(unique(did_data_staggered$week)), \n        labels = 1:length(unique(did_data_staggered$week))))\n# data preparation\ntreated_ids &lt;- unique(did_data_staggered[did_data_staggered$treated == 1, ]$song_id)\nuntreated_ids &lt;- unique(did_data_staggered[did_data_staggered$treated == 0, ]$song_id)\n\nlibrary(panelView)\n\n\n## See bit.ly/panelview4r for more info.\n## Report bugs -&gt; yiqingxu@stanford.edu.\n\n\nCode\n# inspect data\npanelview(\n    streams ~ treated_post, \n    data = did_data_staggered[\n        did_data_staggered$song_id %in% c(\n            sample(treated_ids,5), \n            sample(untreated_ids, 3)\n            ) &\n        did_data_staggered$week_num &gt; 10 & \n        did_data_staggered$week_num &lt;= 30\n    , ], \n    index = c(\"song_id\", \"week\"), \n    ylab = \"group\",\n    pre.post = TRUE,\n    by.timing = TRUE,\n    theme.bw = TRUE,\n    axis.adjust = TRUE) \n\n\n\n\n\n\n\n\n\n\n\n\n\\[\ny_{i, t} = \\tau_{did}\\ \\mathbb{1}(\\text{treated}_{i, t}) + \\gamma_t + \\alpha_i + \\epsilon_{i,t}\n\\]\n\nOk IF \\[\n\\tau_{g, t} = \\tau \\text{ for all }g \\text{ and } t\n\\]\nOtherwise: estimate separate \\(\\tau_{g, t}\\) for all \\(g\\) and \\(t\\) using only not (yet) treated units as controls\n\n\n\n\n\n\n\nGoodman-Bacon (2021)\n\n\n\n\n\n\nExisting methods for multiple time periods (e.g., Callaway and Sant’Anna 2021) work well if the number of treated units in each group \\(g\\) is “large” (&gt;5)\nFocus on selecting “control group” correctly\n\nLoop over groups and times and select not (yet) treated as controls (Callaway and Sant’Anna 2021)\nEstimate large matrix of indicators (Sun and Abraham 2021)\n\nResult: Group Time Average Treatment Effect \\(\\tau_{g,t}\\)\n\n\n\n\n\n\nCode\ndid_data_staggered$log_streams &lt;- log(did_data_staggered$streams+1)\n# add first period treated\ndid_data_staggered_G &lt;- did_data_staggered |&gt;\n  filter(treated == 1, week == treat_week) |&gt;\n  select(song_id, G = week_num)\ndid_data_staggered &lt;- left_join(did_data_staggered,\n                                did_data_staggered_G,\n                                by = \"song_id\")\ndid_data_staggered$G &lt;- coalesce(did_data_staggered$G, 0)\ndid_data_staggered$id &lt;- as.numeric(did_data_staggered$song_id)\n\nset.seed(123)\n#increase bootstrap for reliability!\nlibrary(did)\nmod.csa &lt;- att_gt(yname = \"log_streams\",\n       tname = \"week_num\",\n       idname = \"id\",\n       gname = \"G\",\n       biters = 2000,\n       data = did_data_staggered\n)\n\n\nWarning in pre_process_did(yname = yname, tname = tname, idname = idname, : Be aware that there are some small groups in your dataset.\n  Check groups: 15,16,17,18,19,20,22,24,25,26,27.\n\n\nWarning in att_gt(yname = \"log_streams\", tname = \"week_num\", idname = \"id\", :\nNot returning pre-test Wald statistic due to singular covariance matrix\n\n\nCode\nggdid(aggte(mod.csa, type = 'dynamic'))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nggdid(mod.csa, group = 17)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nlibrary(ggiplot)\n\n\nLoading required package: ggplot2\n\n\nCode\nmod.sunab &lt;- feols(log_streams ~ sunab(G, week_num) | id + week_num, data = did_data_staggered )\nggiplot(mod.sunab)"
  },
  {
    "objectID": "06-did-page.html#basic-setup",
    "href": "06-did-page.html#basic-setup",
    "title": "Potential Outcomes and DiD",
    "section": "",
    "text": "Two groups\n\nCountries\nCompanies\nIndividuals\netc.\n\nTwo periods\nGroup \\(g=2\\) receives treatment between period \\(1\\) and \\(2\\)\nGroup \\(g=\\infty\\) never receives the treatment (at least in the observation period)\nNo randomization but: “Quasi-Experiment”, “Natural Experiment”\n\n. . .\n\nGoal: identification of a causal average treatment effect on the treated (ATT)\nCore Assumption: parallel trends"
  },
  {
    "objectID": "06-did-page.html#basic-setup-1",
    "href": "06-did-page.html#basic-setup-1",
    "title": "Potential Outcomes and DiD",
    "section": "",
    "text": "Code\nlibrary(dplyr)\n\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\n\nCode\ny_j &lt;- c(0.5, 1, 1.8)\ny_j_counter &lt;- c(0.5, 1, 1.5)\ny_k &lt;- c(0.2, 0.7, 1.2)\nx &lt;- c(1,2,3)\nplot(\n    x, y_k, \n    type = \"l\", \n    ylim = c(0, 2),\n    xaxt = \"n\", yaxt = \"n\",\n    ylab = \"Y\", xlab = \"Period\", \n    bty= \"n\"\n    )\naxis(side=2, labels = FALSE, at = NULL)\naxis(side=1, at=c(1,3), labels=c(\"1\",  \"2\"))\nlines(x, y_j)\nlines(x[2:3], y_j_counter[2:3], lty = 2, col = \"red\")\nlines(c(3, 3), c(1.5, 1.8), col = \"darkgreen\")\nabline(v = 2, lty = 4, col = \"gray30\")\ntext(\n    x = 1.5, y = 0.6, \n    labels = \"Parallel pre-treatment\", \n    cex=1.5, srt = 17\n    )\ntext(\n    x = 2.2, y = 1.7, \n    labels = \"Treatment\",\n    cex=1.5, col = \"gray30\"\n    )\ntext(\n    x = 2.5, y = 1.3, \n    labels = \"Counterfactual\",\n    col = \"red\", srt = 17\n    )\ntext(\n    x = 2.9, y = 1.6,\n    labels = \"+Effect\",\n    col = \"darkgreen\"\n    )\ngrid()"
  },
  {
    "objectID": "06-did-page.html#treatment-effect",
    "href": "06-did-page.html#treatment-effect",
    "title": "Potential Outcomes and DiD",
    "section": "",
    "text": "\\(Y_{i,t}\\) … outcome of unit \\(i\\) at time \\(t\\)\n\n\n\n\n\n\\(Y_{i,t}(0)\\) … \\(Y_{i,t}\\) given \\(i\\) is not treated at \\(t\\)\n\\(Y_{i,t}(1)\\) … \\(Y_{i,t}\\) give \\(i\\) is treated at \\(t\\)\nObserved: \\(Y_{i,t} = \\mathbb{1}(treated_{i,t}) Y_{i,t}(1) + \\left[1 - \\mathbb{1}(treated_{i,t})\\right] Y_{i,t}(0)\\)\nIndividual treatment effect: \\(\\tau_{i,t} = Y_{i,t}(1) - Y_{i,t}(0)\\)"
  },
  {
    "objectID": "06-did-page.html#treatment-effect-1",
    "href": "06-did-page.html#treatment-effect-1",
    "title": "Potential Outcomes and DiD",
    "section": "",
    "text": "\\(Y_{i,t}\\) … outcome of unit \\(i\\) at time \\(t\\)\n\n\n\n\n\\(Y_{i,t}(0)\\) … \\(Y_{i,t}\\) given \\(i\\) is not treated at \\(t\\)\n\\(Y_{i,t}(1)\\) … \\(Y_{i,t}\\) give \\(i\\) is treated at \\(t\\)\nObserved: \\(Y_{i,t} = \\mathbb{1}(treated_{i,t}) Y_{i,t}(1) + \\left[1 - \\mathbb{1}(treated_{i,t})\\right] Y_{i,t}(0)\\)\nIndividual treatment effect: \\(\\tau_{i,t} = Y_{i,t}(1) - Y_{i,t}(0)\\)\n\n\n\n\nGroup\nt = 1\nt = 2\n\n\n\n\n\\(g = 2\\)\n\\(Y_{i,1}(0)\\)\n\\(Y_{i, 2}(1)\\)\n\n\n\\(g = \\infty\\)\n\\(Y_{j,1}(0)\\)\n\\(Y_{j, 2}(0)\\)"
  },
  {
    "objectID": "06-did-page.html#average-treatment-effect-on-the-treated-tau_g2",
    "href": "06-did-page.html#average-treatment-effect-on-the-treated-tau_g2",
    "title": "Potential Outcomes and DiD",
    "section": "",
    "text": "\\(\\bar Y_{g=k, t}\\)… average outcome of group \\(k\\) at time \\(t\\)\n\\(\\delta_{g=\\cdot}\\)… trend of the outcome for \\(g = \\cdot\\)\n\\(\\delta_{g=\\cdot} = \\delta\\) for \\(g = 2\\) and \\(g = \\infty\\) under parallel trends\n\n. . .\n\\[\n\\begin{aligned}\n\\bar Y_{g=2, 2} - \\bar Y_{g=2, 1} &= \\delta_{g=2} + \\tau_{g=2} \\\\\n\\bar Y_{g=2, 2} - \\bar Y_{g=2, 1} &=  \\bar Y_{g=\\infty, 2} - \\bar Y_{g=\\infty, 1} + \\tau_{g=2} \\\\\n\\left[\\bar Y_{g=2, 2} - \\bar Y_{g=2, 1}\\right] - \\left[\\bar Y_{g=\\infty, 2} - \\bar Y_{g=\\infty, 1}\\right] &= \\tau_{g=2}\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "06-did-page.html#introductory-example",
    "href": "06-did-page.html#introductory-example",
    "title": "Potential Outcomes and DiD",
    "section": "",
    "text": "Code\nset.seed(1)\nn_obs &lt;- 1000\nunits &lt;- rep(1:(n_obs/2), each = 2)\nunit_fe &lt;- runif(n_obs/2, 0, 20)\nperiod &lt;- rep(c(0,1), n_obs/2)\nperiod_fe &lt;- rep(c(20, 10), n_obs/2)\ntreatment &lt;- rbinom(n_obs/2, 1, 0.5)\ny &lt;- 5 * treatment[units] * period + # tau = 5\n    period_fe + # time fixed effect\n    unit_fe[units] - # unit fixed effect\n    15 * treatment[units] + # constant diff treated/untreated\n    rnorm(n_obs)\ndata &lt;- data.frame(\n    y = y, \n    treated = treatment[units], \n    period = period, \n    unit = as.factor(units))\ny_j &lt;- aggregate(y ~ period, data[data$treated == 1, ], mean)$y\ny_k &lt;- aggregate(y ~ period, data[data$treated == 0, ], mean)$y\ndelta_y_k &lt;- diff(y_k)\ny_k &lt;- c(\n    y_k[1],\n    y_k[1] + delta_y_k/2,\n    y_k[1] + delta_y_k)\ny_j &lt;- c(\n    y_j[1],\n    y_j[1] + delta_y_k/2, # assumed\n    y_j[2])\ny_j_counter &lt;- c(\n    y_j[1], \n    y_j[1] + delta_y_k/2,\n    y_j[1] + delta_y_k) # assumed\nboxplot(\n    y ~ \n    factor(\n        period, levels = c(0,1),\n        labels = c(\"t: 1\",\"t: 2\")\n        ) +\n    factor(\n        treated, levels = c(0,1), \n        labels = c(\"D\", \"A\")\n        ), \n    xlab = \"\", ylab = \"Y\",\n    frame.plot = F,\n    col = \"white\", sep = \" in \",\n    main = \"Household income\",\n    data)"
  },
  {
    "objectID": "06-did-page.html#introductory-example-1",
    "href": "06-did-page.html#introductory-example-1",
    "title": "Potential Outcomes and DiD",
    "section": "",
    "text": "Code\nplot(\n    x, y_k, \n    type = \"l\", \n    ylim = c(0, 35),\n    xaxt = \"n\", #yaxt = \"n\",\n    ylab = \"Avg. availabe household income\", xlab = \"Period\", \n    bty= \"n\"\n    )\naxis(side=1, at=c(1,3), labels=c(\"1\",  \"2\"))\nlines(x, y_j)\nlines(x[2:3], y_j_counter[2:3], lty = 2, col = \"red\")\nlines(c(3, 3), c(y_j[3], y_j_counter[3]), col = \"darkgreen\")\nabline(v = 2, lty = 4, col = \"gray30\")\ntext(x = 1.1, y = 31, labels = \"D\", cex=1.5)\ntext(x = 1.1, y = 16, labels = \"A\", cex=1.5)\ntext(\n    x = 1.5, y = 20, \n    labels = \"Parallel pre-treatment\", \n    cex=1.5, srt = -10\n    )\ntext(\n    x = 2.25, y = 28, \n    labels = \"\\\"Klimabonus\\\"\",\n    cex=1.5, col = \"gray30\"\n    )\ntext(\n    x = 2.5, y = 6.8, \n    labels = \"Counterfactual\",\n    col = \"red\", srt = -10\n    )\ntext(\n    x = 2.90, y = 7.8,\n    labels = \"+Effect\",\n    col = \"darkgreen\"\n    )\ngrid()"
  },
  {
    "objectID": "06-did-page.html#canonical-estimation",
    "href": "06-did-page.html#canonical-estimation",
    "title": "Potential Outcomes and DiD",
    "section": "",
    "text": "\\[\n\\begin{aligned}\ny_{i, t} &= \\tau_{did}\\ \\mathbb{1}(\\text{treated}_{i, t}) + \\gamma_t + \\alpha_i + \\epsilon_{i,t} \\\\\n\\mathbb{1}(\\text{treated}_{i,t}) &\\equiv \\mathbb{1}(i \\in \\text{A}) \\times \\mathbb{1}(t = 2)\n\\end{aligned}\n\\]\n\n\n\n\\[\ny_{i, t} = \\tau_{did} \\mathbb{1}(\\text{treated}_{i,t}) + \\beta_1 \\mathbb{1}(i \\in \\text{A}) + \\beta_2 \\mathbb{1}(t = 2) + \\alpha + \\varepsilon_{i,t}\n\\]\nTypically \\(\\sigma_{\\epsilon_{i,t}} &lt; \\sigma_{\\varepsilon_{i,t}}\\)"
  },
  {
    "objectID": "06-did-page.html#estimation-in-r",
    "href": "06-did-page.html#estimation-in-r",
    "title": "Potential Outcomes and DiD",
    "section": "",
    "text": "Code\nlibrary(fixest)\nlibrary(pander)\n\netable(list(\n    `TWFE` = feols(y ~ treated:period | unit + period, data),\n    `Dummy` = feols(y ~ treated * period, data)),\n    postprocess.df = pandoc.table.return,\n    style = \"rmarkdown\")\n\n\n\n\n \nTWFE\nDummy\n\n\n\n\nDependent Var.:\ny\ny\n\n\n\n\n\n\n\ntreated x period\n5.064*** (0.1266)\n5.064*** (0.7296)\n\n\nConstant\n\n29.67*** (0.3648)\n\n\ntreated\n\n-14.56*** (0.5159)\n\n\nperiod\n\n-10.03*** (0.5159)\n\n\nFixed-Effects:\n—————–\n——————\n\n\nunit\nYes\nNo\n\n\nperiod\nYes\nNo\n\n\n________________\n_________________\n__________________\n\n\nS.E. type\nby: unit\nIID\n\n\nObservations\n1,000\n1,000\n\n\nR2\n0.99413\n0.61016\n\n\nWithin R2\n0.76267\n–"
  },
  {
    "objectID": "06-did-page.html#extension-to-multiple-time-periods",
    "href": "06-did-page.html#extension-to-multiple-time-periods",
    "title": "Potential Outcomes and DiD",
    "section": "",
    "text": "Code\ndid_data_staggered &lt;- data.table::fread(\"https://raw.githubusercontent.com/WU-RDS/RMA2022/main/data/did_data_staggered.csv\")\ndid_data_staggered$song_id &lt;- as.character(did_data_staggered$song_id)\ndid_data_staggered$week &lt;- as.Date(did_data_staggered$week)\ndid_data_staggered$week_num &lt;- as.numeric(\n    factor(\n        did_data_staggered$week, \n        levels = sort(unique(did_data_staggered$week)), \n        labels = 1:length(unique(did_data_staggered$week))))\n# data preparation\ntreated_ids &lt;- unique(did_data_staggered[did_data_staggered$treated == 1, ]$song_id)\nuntreated_ids &lt;- unique(did_data_staggered[did_data_staggered$treated == 0, ]$song_id)\n\nlibrary(panelView)\n\n\n## See bit.ly/panelview4r for more info.\n## Report bugs -&gt; yiqingxu@stanford.edu.\n\n\nCode\n# inspect data\npanelview(\n    streams ~ treated_post, \n    data = did_data_staggered[\n        did_data_staggered$song_id %in% c(\n            sample(treated_ids,5), \n            sample(untreated_ids, 3)\n            ) &\n        did_data_staggered$week_num &gt; 10 & \n        did_data_staggered$week_num &lt;= 30\n    , ], \n    index = c(\"song_id\", \"week\"), \n    ylab = \"group\",\n    pre.post = TRUE,\n    by.timing = TRUE,\n    theme.bw = TRUE,\n    axis.adjust = TRUE)"
  },
  {
    "objectID": "06-did-page.html#two-way-fixed-effects-1",
    "href": "06-did-page.html#two-way-fixed-effects-1",
    "title": "Potential Outcomes and DiD",
    "section": "",
    "text": "\\[\ny_{i, t} = \\tau_{did}\\ \\mathbb{1}(\\text{treated}_{i, t}) + \\gamma_t + \\alpha_i + \\epsilon_{i,t}\n\\]\n\nOk IF \\[\n\\tau_{g, t} = \\tau \\text{ for all }g \\text{ and } t\n\\]\nOtherwise: estimate separate \\(\\tau_{g, t}\\) for all \\(g\\) and \\(t\\) using only not (yet) treated units as controls"
  },
  {
    "objectID": "06-did-page.html#intuition",
    "href": "06-did-page.html#intuition",
    "title": "Potential Outcomes and DiD",
    "section": "",
    "text": "Goodman-Bacon (2021)"
  },
  {
    "objectID": "06-did-page.html#existing-extensions",
    "href": "06-did-page.html#existing-extensions",
    "title": "Potential Outcomes and DiD",
    "section": "",
    "text": "Existing methods for multiple time periods (e.g., Callaway and Sant’Anna 2021) work well if the number of treated units in each group \\(g\\) is “large” (&gt;5)\nFocus on selecting “control group” correctly\n\nLoop over groups and times and select not (yet) treated as controls (Callaway and Sant’Anna 2021)\nEstimate large matrix of indicators (Sun and Abraham 2021)\n\nResult: Group Time Average Treatment Effect \\(\\tau_{g,t}\\)"
  },
  {
    "objectID": "06-did-page.html#implementation-in-r-callawaydifferenceindifferencesmultipletime2021a",
    "href": "06-did-page.html#implementation-in-r-callawaydifferenceindifferencesmultipletime2021a",
    "title": "Potential Outcomes and DiD",
    "section": "",
    "text": "Code\ndid_data_staggered$log_streams &lt;- log(did_data_staggered$streams+1)\n# add first period treated\ndid_data_staggered_G &lt;- did_data_staggered |&gt;\n  filter(treated == 1, week == treat_week) |&gt;\n  select(song_id, G = week_num)\ndid_data_staggered &lt;- left_join(did_data_staggered,\n                                did_data_staggered_G,\n                                by = \"song_id\")\ndid_data_staggered$G &lt;- coalesce(did_data_staggered$G, 0)\ndid_data_staggered$id &lt;- as.numeric(did_data_staggered$song_id)\n\nset.seed(123)\n#increase bootstrap for reliability!\nlibrary(did)\nmod.csa &lt;- att_gt(yname = \"log_streams\",\n       tname = \"week_num\",\n       idname = \"id\",\n       gname = \"G\",\n       biters = 2000,\n       data = did_data_staggered\n)\n\n\nWarning in pre_process_did(yname = yname, tname = tname, idname = idname, : Be aware that there are some small groups in your dataset.\n  Check groups: 15,16,17,18,19,20,22,24,25,26,27.\n\n\nWarning in att_gt(yname = \"log_streams\", tname = \"week_num\", idname = \"id\", :\nNot returning pre-test Wald statistic due to singular covariance matrix\n\n\nCode\nggdid(aggte(mod.csa, type = 'dynamic'))"
  },
  {
    "objectID": "06-did-page.html#implementation-in-r-callawaydifferenceindifferencesmultipletime2021a-1",
    "href": "06-did-page.html#implementation-in-r-callawaydifferenceindifferencesmultipletime2021a-1",
    "title": "Potential Outcomes and DiD",
    "section": "",
    "text": "Code\nggdid(mod.csa, group = 17)"
  },
  {
    "objectID": "06-did-page.html#implementation-in-r-sunestimatingdynamictreatment2021a",
    "href": "06-did-page.html#implementation-in-r-sunestimatingdynamictreatment2021a",
    "title": "Potential Outcomes and DiD",
    "section": "",
    "text": "Code\nlibrary(ggiplot)\n\n\nLoading required package: ggplot2\n\n\nCode\nmod.sunab &lt;- feols(log_streams ~ sunab(G, week_num) | id + week_num, data = did_data_staggered )\nggiplot(mod.sunab)"
  },
  {
    "objectID": "06-did.html#basic-setup",
    "href": "06-did.html#basic-setup",
    "title": "Potential Outcomes and DiD",
    "section": "Basic Setup",
    "text": "Basic Setup\n\nTwo groups\n\nCountries\nCompanies\nIndividuals\netc.\n\n\nTwo periods\nGroup \\(g=2\\) receives treatment between period \\(1\\) and \\(2\\)\n\nGroup \\(g=\\infty\\) never receives the treatment (at least in the observation period)\nNo randomization but: “Quasi-Experiment”, “Natural Experiment”\n\n\n\n\nGoal: identification of a causal average treatment effect on the treated (ATT)\n\nCore Assumption: parallel trends"
  },
  {
    "objectID": "06-did.html#basic-setup-1",
    "href": "06-did.html#basic-setup-1",
    "title": "Potential Outcomes and DiD",
    "section": "Basic Setup",
    "text": "Basic Setup\n\nCodelibrary(dplyr)\ny_j &lt;- c(0.5, 1, 1.8)\ny_j_counter &lt;- c(0.5, 1, 1.5)\ny_k &lt;- c(0.2, 0.7, 1.2)\nx &lt;- c(1,2,3)\nplot(\n    x, y_k, \n    type = \"l\", \n    ylim = c(0, 2),\n    xaxt = \"n\", yaxt = \"n\",\n    ylab = \"Y\", xlab = \"Period\", \n    bty= \"n\"\n    )\naxis(side=2, labels = FALSE, at = NULL)\naxis(side=1, at=c(1,3), labels=c(\"1\",  \"2\"))\nlines(x, y_j)\nlines(x[2:3], y_j_counter[2:3], lty = 2, col = \"red\")\nlines(c(3, 3), c(1.5, 1.8), col = \"darkgreen\")\nabline(v = 2, lty = 4, col = \"gray30\")\ntext(\n    x = 1.5, y = 0.6, \n    labels = \"Parallel pre-treatment\", \n    cex=1.5, srt = 17\n    )\ntext(\n    x = 2.2, y = 1.7, \n    labels = \"Treatment\",\n    cex=1.5, col = \"gray30\"\n    )\ntext(\n    x = 2.5, y = 1.3, \n    labels = \"Counterfactual\",\n    col = \"red\", srt = 17\n    )\ntext(\n    x = 2.9, y = 1.6,\n    labels = \"+Effect\",\n    col = \"darkgreen\"\n    )\ngrid()"
  },
  {
    "objectID": "06-did.html#treatment-effect",
    "href": "06-did.html#treatment-effect",
    "title": "Potential Outcomes and DiD",
    "section": "Treatment effect",
    "text": "Treatment effect\n\n\n\\(Y_{i,t}\\) … outcome of unit \\(i\\) at time \\(t\\)\n\n\nPotential outcomes (Rubin 2005)\n\n\n\n\n\\(Y_{i,t}(0)\\) … \\(Y_{i,t}\\) given \\(i\\) is not treated at \\(t\\)\n\n\n\\(Y_{i,t}(1)\\) … \\(Y_{i,t}\\) give \\(i\\) is treated at \\(t\\)\n\nObserved: \\(Y_{i,t} = \\mathbb{1}(treated_{i,t}) Y_{i,t}(1) + \\left[1 - \\mathbb{1}(treated_{i,t})\\right] Y_{i,t}(0)\\)\n\nIndividual treatment effect: \\(\\tau_{i,t} = Y_{i,t}(1) - Y_{i,t}(0)\\)"
  },
  {
    "objectID": "06-did.html#treatment-effect-1",
    "href": "06-did.html#treatment-effect-1",
    "title": "Potential Outcomes and DiD",
    "section": "Treatment effect",
    "text": "Treatment effect\n\n\n\\(Y_{i,t}\\) … outcome of unit \\(i\\) at time \\(t\\)\n\n\nPotential outcomes (Rubin 2005)\n\n\n\n\\(Y_{i,t}(0)\\) … \\(Y_{i,t}\\) given \\(i\\) is not treated at \\(t\\)\n\n\n\\(Y_{i,t}(1)\\) … \\(Y_{i,t}\\) give \\(i\\) is treated at \\(t\\)\n\nObserved: \\(Y_{i,t} = \\mathbb{1}(treated_{i,t}) Y_{i,t}(1) + \\left[1 - \\mathbb{1}(treated_{i,t})\\right] Y_{i,t}(0)\\)\n\nIndividual treatment effect: \\(\\tau_{i,t} = Y_{i,t}(1) - Y_{i,t}(0)\\)\n\n\n\n\nGroup\nt = 1\nt = 2\n\n\n\n\\(g = 2\\)\n\\(Y_{i,1}(0)\\)\n\\(Y_{i, 2}(1)\\)\n\n\n\\(g = \\infty\\)\n\\(Y_{j,1}(0)\\)\n\\(Y_{j, 2}(0)\\)"
  },
  {
    "objectID": "06-did.html#average-treatment-effect-on-the-treated-tau_g2",
    "href": "06-did.html#average-treatment-effect-on-the-treated-tau_g2",
    "title": "Potential Outcomes and DiD",
    "section": "Average Treatment Effect on the Treated (\\(\\tau_{g=2}\\))",
    "text": "Average Treatment Effect on the Treated (\\(\\tau_{g=2}\\))\n\n\n\\(\\bar Y_{g=k, t}\\)… average outcome of group \\(k\\) at time \\(t\\)\n\n\n\\(\\delta_{g=\\cdot}\\)… trend of the outcome for \\(g = \\cdot\\)\n\n\n\\(\\delta_{g=\\cdot} = \\delta\\) for \\(g = 2\\) and \\(g = \\infty\\) under parallel trends\n\n\n\\[\n\\begin{aligned}\n\\bar Y_{g=2, 2} - \\bar Y_{g=2, 1} &= \\delta_{g=2} + \\tau_{g=2} \\\\\n\\bar Y_{g=2, 2} - \\bar Y_{g=2, 1} &=  \\bar Y_{g=\\infty, 2} - \\bar Y_{g=\\infty, 1} + \\tau_{g=2} \\\\\n\\left[\\bar Y_{g=2, 2} - \\bar Y_{g=2, 1}\\right] - \\left[\\bar Y_{g=\\infty, 2} - \\bar Y_{g=\\infty, 1}\\right] &= \\tau_{g=2}\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "06-did.html#introductory-example",
    "href": "06-did.html#introductory-example",
    "title": "Potential Outcomes and DiD",
    "section": "Introductory example",
    "text": "Introductory example\n\nCodeset.seed(1)\nn_obs &lt;- 1000\nunits &lt;- rep(1:(n_obs/2), each = 2)\nunit_fe &lt;- runif(n_obs/2, 0, 20)\nperiod &lt;- rep(c(0,1), n_obs/2)\nperiod_fe &lt;- rep(c(20, 10), n_obs/2)\ntreatment &lt;- rbinom(n_obs/2, 1, 0.5)\ny &lt;- 5 * treatment[units] * period + # tau = 5\n    period_fe + # time fixed effect\n    unit_fe[units] - # unit fixed effect\n    15 * treatment[units] + # constant diff treated/untreated\n    rnorm(n_obs)\ndata &lt;- data.frame(\n    y = y, \n    treated = treatment[units], \n    period = period, \n    unit = as.factor(units))\ny_j &lt;- aggregate(y ~ period, data[data$treated == 1, ], mean)$y\ny_k &lt;- aggregate(y ~ period, data[data$treated == 0, ], mean)$y\ndelta_y_k &lt;- diff(y_k)\ny_k &lt;- c(\n    y_k[1],\n    y_k[1] + delta_y_k/2,\n    y_k[1] + delta_y_k)\ny_j &lt;- c(\n    y_j[1],\n    y_j[1] + delta_y_k/2, # assumed\n    y_j[2])\ny_j_counter &lt;- c(\n    y_j[1], \n    y_j[1] + delta_y_k/2,\n    y_j[1] + delta_y_k) # assumed\nboxplot(\n    y ~ \n    factor(\n        period, levels = c(0,1),\n        labels = c(\"t: 1\",\"t: 2\")\n        ) +\n    factor(\n        treated, levels = c(0,1), \n        labels = c(\"D\", \"A\")\n        ), \n    xlab = \"\", ylab = \"Y\",\n    frame.plot = F,\n    col = \"white\", sep = \" in \",\n    main = \"Household income\",\n    data)"
  },
  {
    "objectID": "06-did.html#introductory-example-1",
    "href": "06-did.html#introductory-example-1",
    "title": "Potential Outcomes and DiD",
    "section": "Introductory example",
    "text": "Introductory example\n\nCodeplot(\n    x, y_k, \n    type = \"l\", \n    ylim = c(0, 35),\n    xaxt = \"n\", #yaxt = \"n\",\n    ylab = \"Avg. availabe household income\", xlab = \"Period\", \n    bty= \"n\"\n    )\naxis(side=1, at=c(1,3), labels=c(\"1\",  \"2\"))\nlines(x, y_j)\nlines(x[2:3], y_j_counter[2:3], lty = 2, col = \"red\")\nlines(c(3, 3), c(y_j[3], y_j_counter[3]), col = \"darkgreen\")\nabline(v = 2, lty = 4, col = \"gray30\")\ntext(x = 1.1, y = 31, labels = \"D\", cex=1.5)\ntext(x = 1.1, y = 16, labels = \"A\", cex=1.5)\ntext(\n    x = 1.5, y = 20, \n    labels = \"Parallel pre-treatment\", \n    cex=1.5, srt = -10\n    )\ntext(\n    x = 2.25, y = 28, \n    labels = \"\\\"Klimabonus\\\"\",\n    cex=1.5, col = \"gray30\"\n    )\ntext(\n    x = 2.5, y = 6.8, \n    labels = \"Counterfactual\",\n    col = \"red\", srt = -10\n    )\ntext(\n    x = 2.90, y = 7.8,\n    labels = \"+Effect\",\n    col = \"darkgreen\"\n    )\ngrid()"
  },
  {
    "objectID": "06-did.html#canonical-estimation",
    "href": "06-did.html#canonical-estimation",
    "title": "Potential Outcomes and DiD",
    "section": "Canonical estimation",
    "text": "Canonical estimation\nTwo-Way Fixed Effects\n\\[\n\\begin{aligned}\ny_{i, t} &= \\tau_{did}\\ \\mathbb{1}(\\text{treated}_{i, t}) + \\gamma_t + \\alpha_i + \\epsilon_{i,t} \\\\\n\\mathbb{1}(\\text{treated}_{i,t}) &\\equiv \\mathbb{1}(i \\in \\text{A}) \\times \\mathbb{1}(t = 2)\n\\end{aligned}\n\\]\n“Dummy” Model\n\\[\ny_{i, t} = \\tau_{did} \\mathbb{1}(\\text{treated}_{i,t}) + \\beta_1 \\mathbb{1}(i \\in \\text{A}) + \\beta_2 \\mathbb{1}(t = 2) + \\alpha + \\varepsilon_{i,t}\n\\]\nTypically \\(\\sigma_{\\epsilon_{i,t}} &lt; \\sigma_{\\varepsilon_{i,t}}\\)"
  },
  {
    "objectID": "06-did.html#estimation-in-r",
    "href": "06-did.html#estimation-in-r",
    "title": "Potential Outcomes and DiD",
    "section": "Estimation in R",
    "text": "Estimation in R\nCodelibrary(fixest)\nlibrary(pander)\n\netable(list(\n    `TWFE` = feols(y ~ treated:period | unit + period, data),\n    `Dummy` = feols(y ~ treated * period, data)),\n    postprocess.df = pandoc.table.return,\n    style = \"rmarkdown\")\n\n\n \nTWFE\nDummy\n\n\n\nDependent Var.:\ny\ny\n\n\n\n\n\n\n\ntreated x period\n5.064*** (0.1266)\n5.064*** (0.7296)\n\n\nConstant\n\n29.67*** (0.3648)\n\n\ntreated\n\n-14.56*** (0.5159)\n\n\nperiod\n\n-10.03*** (0.5159)\n\n\nFixed-Effects:\n—————–\n——————\n\n\nunit\nYes\nNo\n\n\nperiod\nYes\nNo\n\n\n________________\n_________________\n__________________\n\n\nS.E. type\nby: unit\nIID\n\n\nObservations\n1,000\n1,000\n\n\nR2\n0.99413\n0.61016\n\n\nWithin R2\n0.76267\n–"
  },
  {
    "objectID": "06-did.html#extension-to-multiple-time-periods",
    "href": "06-did.html#extension-to-multiple-time-periods",
    "title": "Potential Outcomes and DiD",
    "section": "Extension to Multiple Time Periods",
    "text": "Extension to Multiple Time Periods\n\nCodedid_data_staggered &lt;- data.table::fread(\"https://raw.githubusercontent.com/WU-RDS/RMA2022/main/data/did_data_staggered.csv\")\ndid_data_staggered$song_id &lt;- as.character(did_data_staggered$song_id)\ndid_data_staggered$week &lt;- as.Date(did_data_staggered$week)\ndid_data_staggered$week_num &lt;- as.numeric(\n    factor(\n        did_data_staggered$week, \n        levels = sort(unique(did_data_staggered$week)), \n        labels = 1:length(unique(did_data_staggered$week))))\n# data preparation\ntreated_ids &lt;- unique(did_data_staggered[did_data_staggered$treated == 1, ]$song_id)\nuntreated_ids &lt;- unique(did_data_staggered[did_data_staggered$treated == 0, ]$song_id)\n\nlibrary(panelView)\n# inspect data\npanelview(\n    streams ~ treated_post, \n    data = did_data_staggered[\n        did_data_staggered$song_id %in% c(\n            sample(treated_ids,5), \n            sample(untreated_ids, 3)\n            ) &\n        did_data_staggered$week_num &gt; 10 & \n        did_data_staggered$week_num &lt;= 30\n    , ], \n    index = c(\"song_id\", \"week\"), \n    ylab = \"group\",\n    pre.post = TRUE,\n    by.timing = TRUE,\n    theme.bw = TRUE,\n    axis.adjust = TRUE)"
  },
  {
    "objectID": "06-did.html#two-way-fixed-effects-1",
    "href": "06-did.html#two-way-fixed-effects-1",
    "title": "Potential Outcomes and DiD",
    "section": "Two-Way Fixed Effects?",
    "text": "Two-Way Fixed Effects?\n\\[\ny_{i, t} = \\tau_{did}\\ \\mathbb{1}(\\text{treated}_{i, t}) + \\gamma_t + \\alpha_i + \\epsilon_{i,t}\n\\]\n\nOk IF \\[\n\\tau_{g, t} = \\tau \\text{ for all }g \\text{ and } t\n\\]\nOtherwise: estimate separate \\(\\tau_{g, t}\\) for all \\(g\\) and \\(t\\) using only not (yet) treated units as controls"
  },
  {
    "objectID": "06-did.html#intuition",
    "href": "06-did.html#intuition",
    "title": "Potential Outcomes and DiD",
    "section": "Intuition",
    "text": "Intuition\n\nGoodman-Bacon (2021)"
  },
  {
    "objectID": "06-did.html#existing-extensions",
    "href": "06-did.html#existing-extensions",
    "title": "Potential Outcomes and DiD",
    "section": "Existing Extensions",
    "text": "Existing Extensions\n\nExisting methods for multiple time periods (e.g., Callaway and Sant’Anna 2021) work well if the number of treated units in each group \\(g\\) is “large” (&gt;5)\nFocus on selecting “control group” correctly\n\nLoop over groups and times and select not (yet) treated as controls (Callaway and Sant’Anna 2021)\n\nEstimate large matrix of indicators (Sun and Abraham 2021)\n\n\n\nResult: Group Time Average Treatment Effect \\(\\tau_{g,t}\\)"
  },
  {
    "objectID": "06-did.html#implementation-in-r-callawaydifferenceindifferencesmultipletime2021a",
    "href": "06-did.html#implementation-in-r-callawaydifferenceindifferencesmultipletime2021a",
    "title": "Potential Outcomes and DiD",
    "section": "Implementation in R (Callaway and Sant’Anna 2021)\n",
    "text": "Implementation in R (Callaway and Sant’Anna 2021)\n\n\nCodedid_data_staggered$log_streams &lt;- log(did_data_staggered$streams+1)\n# add first period treated\ndid_data_staggered_G &lt;- did_data_staggered |&gt;\n  filter(treated == 1, week == treat_week) |&gt;\n  select(song_id, G = week_num)\ndid_data_staggered &lt;- left_join(did_data_staggered,\n                                did_data_staggered_G,\n                                by = \"song_id\")\ndid_data_staggered$G &lt;- coalesce(did_data_staggered$G, 0)\ndid_data_staggered$id &lt;- as.numeric(did_data_staggered$song_id)\n\nset.seed(123)\n#increase bootstrap for reliability!\nlibrary(did)\nmod.csa &lt;- att_gt(yname = \"log_streams\",\n       tname = \"week_num\",\n       idname = \"id\",\n       gname = \"G\",\n       biters = 2000,\n       data = did_data_staggered\n)\nggdid(aggte(mod.csa, type = 'dynamic'))"
  },
  {
    "objectID": "06-did.html#implementation-in-r-callawaydifferenceindifferencesmultipletime2021a-1",
    "href": "06-did.html#implementation-in-r-callawaydifferenceindifferencesmultipletime2021a-1",
    "title": "Potential Outcomes and DiD",
    "section": "Implementation in R (Callaway and Sant’Anna 2021)\n",
    "text": "Implementation in R (Callaway and Sant’Anna 2021)\n\n\nCodeggdid(mod.csa, group = 17)"
  },
  {
    "objectID": "06-did.html#implementation-in-r-sunestimatingdynamictreatment2021a",
    "href": "06-did.html#implementation-in-r-sunestimatingdynamictreatment2021a",
    "title": "Potential Outcomes and DiD",
    "section": "Implementation in R (Sun and Abraham 2021)\n",
    "text": "Implementation in R (Sun and Abraham 2021)\n\n\nCodelibrary(ggiplot)\nmod.sunab &lt;- feols(log_streams ~ sunab(G, week_num) | id + week_num, data = did_data_staggered )\nggiplot(mod.sunab)"
  },
  {
    "objectID": "06-did.html#references",
    "href": "06-did.html#references",
    "title": "Potential Outcomes and DiD",
    "section": "References",
    "text": "References\n\n\n\n\nData Literacy\n\n\n\n\nCallaway, Brantly, and Pedro H. C. Sant’Anna. 2021. “Difference-in-Differences with Multiple Time Periods.” Journal of Econometrics, Themed issue: Treatment effect 1, 225 (2): 200–230. https://doi.org/10.1016/j.jeconom.2020.12.001.\n\n\nGoodman-Bacon, Andrew. 2021. “Difference-in-Differences with Variation in Treatment Timing.” Journal of Econometrics, Themed issue: Treatment effect 1, 225 (2): 254–77. https://doi.org/10.1016/j.jeconom.2021.03.014.\n\n\nRubin, Donald B. 2005. “Causal Inference Using Potential Outcomes: Design, Modeling, Decisions.” Journal of the American Statistical Association 100 (469): 322–31. https://www.jstor.org/stable/27590541.\n\n\nSun, Liyang, and Sarah Abraham. 2021. “Estimating Dynamic Treatment Effects in Event Studies with Heterogeneous Treatment Effects.” Journal of Econometrics, Themed issue: Treatment effect 1, 225 (2): 175–99. https://doi.org/10.1016/j.jeconom.2020.09.006."
  }
]